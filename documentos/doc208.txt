Neutralidade Tecnológica Reconhecimento Facial e Racismo
Technologucal Neutrality:Facial Recognition And Racism
Alex Da ROsa, Sara De Araújo Pessoa, Fernanda Da Silva Lima

Resumo
Como efeito das  políticas de  isolamento social, a  atual  pandemia de  Covid-19acirrou desigualdades sociais e  intensificou o  uso  de  ferramentas digitais, desembocando em um efeito duplo: dispositivos eletrônicos servindo como objeto de lazer e/ou aparelhos de vigilância. Pensando na aceleração da virtualização dosprocessos gerada pela  pandemia,  o  presente artigo trata da  utilização dedispositivos tecnológicos por  instâncias formais de  controle, no  Brasil, quereproduzem racismo apesar de se colocarem neutros. A pesquisa problematiza ainstrumentalização de  uma política criminal racista, especificamente dedispositivos de reconhecimento facial com fins policiais em cinco estados do Brasil,conforme estudo do Instituto Igarapé. Orientando-se pelo método indutivo e pormeio  de  revisão bibliográfica, a  pesquisa explora a  diluição do  racismo viadispositivos digitais, levantando a  indagação quanto à  suposta neutralidadetecnológica. Para isso, realizou-se um breve levantamento do panorama nacionalde  políticas criminais de  reconhecimento facial, bem  como de  sua  aplicação.Identificaram-se, ainda, os  estados que  as  adotaram e  suas conclusõespreliminares. Não obstante, tratou-se de investigar como a instrumentalização dedispositivos tecnológicos configura e compõe uma política criminal atuarial capazde acentuar e multiplicar, em outros planos, o racismo que atravessa a sociedade.Palavras-chave: Racismo, Reconhecimento facial, Política criminal atuarial1 IntroduçãoEste texto foi planejado e escrito para a chamada “Nunca fomos tão digitais” da vigésima primeira edição darevista V!RUS. A chamada aponta para análises que se relacionam com a crise sanitária causada pelo novocoronavírus e os deslocamentos de formas de socialização para a internet, principalmente em decorrência doconfinamento, dentre outros impactos numa dimensão digital. Na emergência dessas transformações, torna-se imprescindível pensar nas respostas estatais à contenção da pandemia, assim como na complexidade dosproblemas sociais sucedidos do contexto. Além dos deslocamentos mencionados, que se operam de diferentesmaneiras em diferentes grupos sociais, essa crise global e nacional intensificou problemas estruturais noBrasil, como o racismo e outros marcadores de opressão – tais como classe, gênero e sexualidade – queconjunturalmente agravam a vida das pessoas no contexto pandêmico.Nossa intenção é refletir sobre o cruzamento de três questões que emergem e intensificam-se: dispositivostecnológicos, desigualdades raciais e  medidas adotadas pelo  Estado na  contenção da  pandemia. Naintersecção das duas primeiras, importantes trabalhos foram lançados recentemente, com destaque para olivro  “Comunidades, algorítimos e  ativismos digitais: olhares afrodiaspóricos”, de  organização de  TarcízioSilva, lançado em 2020. Se jamais fomos tão digitais, torna-se indispensável pensar as dinâmicas sociaisdentro desse contexto, sobretudo como se operam as desigualdades raciais e o racismo dentro das própriasredes, sem ignorar o abismo de diferenças entre pessoas que têm ou não direito ao distanciamento social eacesso às redes em épocas de confinamento:

Claramente, o isolamento como forma de segurança e proteção à saúde tem sidoexperimentado pelas classes médias e altas. Para esses segmentos sociais, apesardos inevitáveis inconvenientes, tem sido facultado o recolhimento dentro de suasresidências, com  a  possibilidade da  realização de  compras online, de  trabalhoremoto, do uso de máscaras apropriadas, do uso sistemático de álcool gel, dentretantas outras medidas necessárias para a preservação da saúde. Se, para essessegmentos, o isolamento tem sido traduzido como exercício de garantias, para amassa populacional das periferias negras, esse processo tem significado privação eviolência. A  precariedade das  habitações nas  periferias brasileiras,  a  falta  desaneamento básico e o difícil acesso à água são alguns dos fatores que contribuempara  que  a  prescrição do  isolamento e  da  higienização não  consigam sematerializar.” (FLAUZINA, PIRES, 2020, p. 71)

Num outro vértice, conectando a segunda e terceira questão, em recente artigo, Flauzina e Pires (2020)explicam que, para além de um marcador agudizado durante a pandemia, “[...] o racismo é a régua que medeo mundo e organiza os limites das políticas adotadas no enfrentamento da pandemia”. Igualmente, as açõesgovernamentais se  relacionam também com  a  questão racial: “Mesmo sendo nitidamente o  elo  maisvulnerável da pandemia, a realidade do povo negro empobrecido não é tomada como o ponto de partida parase pensarem as ações governamentais” (FLAUZINA, PIRES, 2020, p. 73).A partir disso, nos debruçamos sobre dispositivos de vigilância digital e especificamente sobre tecnologias dereconhecimento facial (amplamente utilizadas em alguns países asiáticos no enfrentamento da pandemia1)sem necessariamente traçar uma problemática temporalmente localizada na pandemia do coronavírus, porém
pensada desde tensionamentos possíveis no momento. Nosso objetivo é pensar as implicações na utilizaçãodesses dispositivos num país em que o racismo segue estruturando políticas de morte, de exclusão e decontrole social de corpos negros, que se agravam no contexto pandêmico. Nos detivemos especificamentesobre questões que envolvem o controle social exercido pelo Estado no âmbito tecnológico-penal. Assim, estapesquisa busca introduzir a discussão sobre a utilização de dispositivos tecnológicos de reconhecimento facialno  Brasil,  num  contexto de  importação de  políticas criminais atuariais com  especial efeito racializado.Trabalhando com o método indutivo, investigou-se a distribuição da punição por parte do Estado a partir deuma distinção que programa a máquina para automatizar a criminalização secundária, isto é, reconhecer eidentificar “quem são os criminosos”.As falhas na diferenciação das pessoas pelos dispositivos demonstram, antes de qualquer coisa, um programade governo e uma técnica utilizada. O acúmulo de informações sobre os indivíduos elevou a capacidade doEstado em vigiar, controlar, organizar, fiscalizar e punir por meio de dispositivos tecnológicos. Estas práticas,embora catalisadas pelas atuais metodologias, não constituem novidade, como destaca Ruha Benjamin (2019)ao apontar o controle da população negra nas esferas virtuais e por dispositivos tecnológicos, de maneiradiscriminatória e culminando em seu encarceramento, numa espécie de New Jean Code2, ou, nas palavras deMichelle Alexander, The  newest  Jim  Crow  (2018b).  A  multiplicação dos  dispositivos eletrônicos, aacessibilidade de ferramentas digitais, a expansão do mundo virtual e a integração/incorporação com o mundofísico (FLUSSER, 2007) expõem o sentimento e a constatação de que jamais fomos tão digitais. Todavia,apesar de decisivamente impactar a sociedade contemporânea, o desenvolvimento tecnológico, por si só, nãofoi capaz de modificar elementos centrais de nossa forma de existir, a respeito da manutenção do racismocomo elemento estruturante da conjuntura3 – intensificado pelos dispositivos virtuais.Pensando nestas questões, e em como o racismo atravessa a sociedade brasileira e escamoteia-se sob o mitoda cordialidade4, ao investigarmos os dispositivos de reconhecimento facial e sua interação com o racismo,esbarramos com uma questão anterior: a própria tecnologia, sobretudo sua programação e algoritmos. Assim,buscamos compreender por  meio  desta relação, reconhecimento facial  e  raça,  se  existe neutralidade natecnologia. Para isso, num primeiro tópico abordamos a relação entre raça e tecnologia na polissemia dotermo Black Software, principalmente com as contribuições de McIlwain (2020) sobre a revolução tecnológicanos Estados Unidos. Na sequência, recorremos a recente literatura de mulheres afro-americanas sobre ocomportamento das máquinas e algoritmos que cada vez mais compõe as instituições formais de controle. Porfim, cotejando com estudos similares nos Estados Unidos, investigamos no cenário nacional a importação depolíticas criminais que  têm  como principal instrumento o  reconhecimento facial, apresentando em  quaisestados foram implementadas e seus resultados preliminares.2 Raça e tecnologiaO  projeto  de  modernidade é  um  projeto colonizador que  tem  o  racismo como estrutura fundante emantenedora (ALMEIDA, 2018; QUIJANO, 2005; FOUCAULT, 2010; DUARTE et al., 2016). A noção de racismoprecede à  concepção do  que  se  entende por  raça.  Raça  é  um  conceito não  estático, mas  histórico5  erelacional6.  Racismo, portanto, “[...]  é  uma  forma sistemática de  discriminação que  tem  a  raça  comofundamento, e  que  se  manifesta por  meio  de  práticas conscientes  ou  inconscientes que  culminam emdesvantagens ou privilégios para indivíduos, a depender do grupo racial ao qual pertençam” (ALMEIDA, 2018,p. 25). É o racismo, compreendido como uma ferramenta de poder, de hierarquização e estratificação social,que  mantém a  população negra  nos  piores indicadores sociais, acirrando os  processos de  exclusão edesigualdades. Pensar a tecnologia e o mundo virtual a partir de uma problemática racial – inserida no eixocolonizador/modernizador –  pode  ser  organizado da  seguinte forma: como se  constituem os  dispositivostecnológicos, as máquinas, as empresas, as condições de acesso à tecnologia, ou seja, analisar historicamenteos processos de formação e desenvolvimento tanto das empresas que fabricam equipamentos quanto dosequipamentos em si (MCILWAIN, 2020).O desenvolvimento das tecnologias no século XX envolveu fundamentalmente a segregação em seu processode elaboração: pensando nos Estados Unidos, a própria criação de dispositivos, máquinas e aparelhos quecompõem a esfera digital tem como pré-condição a segregação da população negra e sua subordinação. Negaracesso a  empregos,  educação, saúde, moradia, foi  também –  além  da  segregação institucionalizada –ferramenta de exclusão que tornou o processo de elaboração das tecnologias separado dessa população,apesar dos esforços e lutas em resistir e constituir ativamente ferramentas, empresas, organizações e formasde compor a revolução digital (MCILWAIN, 2020). Ou seja, a revolução tecnológica do século XX foi pensadapor brancos e para brancos. E, como efeito do poder, numa perspectiva etnocentrada, não incluiu a populaçãonegra, a  não  ser  quando para  controlá-la, como apresenta Mcilwain na  polissemia do  conceito de BlackSoftware:A  população negra participa da  revolução tecnológica principalmente enquanto objeto de  controle, num
Para mim, o "software  negro" evoca as  inúmeras maneiras de  mobilizarmos atecnologia dos  computadores. Black Software  se  refere ao  programa quedesejamos e programamos os computadores para execução. Refere-se a quemcria o programa, para quais propósitos e o que ou quem torna-se seus objetos emdados. Refere-se a como, e quão bem, o computador executa a tarefa para a qualfoi programado. (MCILWAIN, 2020, p. 7, tradução nossa)mecanismo que alia empresas, governos e dispositivos. A expansão do controle formal (penal) sobre estegrupo é  exemplificada não  só  pelo  programa de  reconhecimento facial abordado nesta pesquisa7  –historicamente essa tecnologia consiste em mais uma das ferramentas de controle. Como todo dispositivo dedominação, a tecnologia busca seu véu de legitimação: os elementos-chave de controle social (como raça,gênero e classe) geralmente acompanham um discurso de justificação, que o torne aceitável, lógico, atémesmo inevitável ou natural. No caso dos dispositivos tecnológicos, a legitimação se dá por uma supostaneutralidade tecnológica. Essa  arguição acompanha a  incorporação da  tecnologia ao  sistema penal. Este,como esfera privilegiada de controle social, buscou refúgio em diferentes ancoradouros. Se, em sua fundação,legitimou-se sob discursos de violação do pacto social e – posteriormente, mas sem abandonar essa premissa– na patologização do crime (DUARTE, 2016), hoje busca sua razão por meio de uma neutralidade tecnológicaque  busca  isentar  seus  operadores de  intencionalidade e  discriminação. Sempre justificativas que  elidemprocessos conscientes de decisão que criminalizam (controlam) segmentos específicos da população (DIETER,2012).Sendo assim, relembrando o prision fix proposto por Ruth Gilmore (2007) como política norte americana deconstrução de presídios e incremento do aprisionamento como solução unidimensional para as multiplicidadesdos conflitos sociais, podemos aproximar nos estudos de Ruha Benjamin (2019) a polissemia do tech fix comosolução aos problemas da contemporaneidade. Não só a solução e harmonização dos conflitos sociais viaprisão, mas via objetividade da tecnologia. A reparação pela tecnologia, o uso do termo fix, designa tambémpara a autora a capacidade de estabilizar, identificar e marcar a população negra para assim distribuí-la emanter intocadas as estruturas de dominação. Inclui também o processo de acumulação de informação porparte de empresas específicas8 e o potencial dos dados como novas formas de controle racializado.3Robôs podem ser racistas?Estudos sobre a interação raça e tecnologia no Brasil ainda são relativamente escassos, dentre os quais sedestaca a  obra  recém lançada ‘Comunidades, algorítimos e  ativismos digitais: olhares afrodiaspóricos’,organizado por Tarcízio Silva. Todavia, internacionalmente, face à atualidade da problemática, cada vez maisautoras dedicam-se a pensar e desconstruir a neutralidade dos algoritmos (O’NEIL, 2016), sua composição(CHUN, 2011) e como retomam um projeto de vigilância e controle da população negra (BROWN, 2015). Seriaa  tecnologia, enquanto exclusão  total  da  subjetividade pela  automação, isenta da  possibilidade dediscriminação? Na defesa dos dispositivos virtuais e maquínicos, estão os argumentos de que, inexistindointenção humana, possuiriam um “grau zero” de objetividade, que impossibilitaria discriminação e injustiça:pura ciência. Ruha Benjamin (2019) relembra alguns acontecimentos que põem em xeque essa premissa: aclassificação virtual, por parte da ferramenta de pesquisa Google, de pessoas negras como gorilas; aplicativopara telefone que classifica usuários em escala estética – dos cinquenta primeiros classificados, seis pessoaseram negras; a empresa HP, que não reconheceu rostos negros em seus equipamentos de tecnologia, emrazão da “baixa luminosidade”; a Kodak, que, no processo de revelação de fotos, tornava visíveis apenas osolhos e sorrisos de pessoas negras, entre outros fatos que geralmente são tratados como excepcionalidade àobjetividade tecnológica.Questionamos: poderiam os robôs serem racistas? A questão é preliminarmente rejeitada pelos modernos quearguem a ausência de subjetividade da máquina. Todavia, a resposta é muito clara e afirmativa: os robôspodem sim ser racistas. São assim pela programação que os configura, pelo programador que organiza seuscódigos e pela empresa que desenvolve um objeto pensado para um determinado fim (BENJAMIN, 2019). Osreiterados casos de racismo na esfera virtual não constituem falhas, erros, desvios do sistema; ao contrário,refletem a  perspectiva daqueles que  constroem os  códigos e  elegem  seus  interesses acima dos  demais,espelhada na execução de programas como forma de assegurar a dominação em outras esferas (BENJAMIN,2019). Os dispositivos de reconhecimento facial funcionam por meio de algoritmos, que, por sua vez, atuamcomo linhas de programação, compondo um modelo que servirá de referência à máquina. Programar umamáquina é inserir dados bases que ordenam o funcionamento do conjunto. São modelos baseados no passadoque têm sua capacidade de projeção limitada a parâmetros inseridos por dados precedentes (O’NEIL, 2016, p.40).Para aperfeiçoar qualquer sistema automatizado, os algoritmos devem continuamente receber feedback sobreo que desenvolvem. Isto é, uma resposta sobre a precisão do que calculam, aperfeiçoando o modelo pré-existente para que se atualize com a diferença do devir. Sem retorno, o sistema continua girando em falso
sem aprender com seus erros (O’NEIL, 2016). Todavia, esse retorno não garante a aprendizagem do sistemae  os  dados inseridos inicialmente  podem desembocar num  efeito looping.  Esse  efeito retroalimenta aprogramação inicial sem que o sistema seja capaz de corrigir falhas, ao contrário, aperfeiçoa-se em criar umarealidade, girando em falso e reproduzindo a programação inicial indefinidamente.O problema que é pertinente a qualquer modelo algorítmico tem efeitos especialmente nefastos enquantoferramenta de controle social. Modelos de policiamento funcionam por cálculo de registros policiais baseadosem  acontecimentos passados (cidade, hora, local, tipo  de  crime), criando zonas de  risco  criminal, paraidentificar chances de repetição e tornar o policiamento mais eficiente (O’NEIL, 2016, p. 75). Seria assim,caso a questão criminal fosse a priori neutra. Os números inicialmente inseridos nesses programas são, naverdade, fruto primeiro de uma decisão política sobre quais condutas são criminalizáveis e quais indivíduosserão alvo maior de ação policial. Uma polícia guiada pela “guerra às drogas” e focada em crimes contra opatrimônio irá  centrar sua  atividade em  determinados territórios, já  vulnerabilizados e  alvos  de  atuaçãopolicial (ALEXANDER, 2018; BATISTA, 2011; ANDRADE, 2012; LEAL, 2017).Com um maior policiamento, novos crimes serão captados. O’ Neil (2016) expõe a prática norte-americana deabordagem de indivíduos suspeitos. De acordo com sua pesquisa, na última década essa prática aumentou600%, sendo 85%  dos  indivíduos abordados negros ou  latinos. Dessas abordagens, apenas 0,1% dosabordados estava ligado a algum crime violento. Essa eficiência já não importa. Se esses dados compõem eordenam sucessivamente a intensificação do policiamento em regiões já policiadas, geram um looping nosistema. Como espécie de  exercício criativo, imagine-se o  mesmo  mapa de  zonas de  risco, mas  agoraalimentado por outros dados: dados vinculados a crimes de sonegação fiscal. O dispositivo alertaria cuidadoao entrar em bairros específicos, sob risco de algum crime fiscal (BENJAMIN, 2019). Consequentemente,aumentaria o policiamento dessas regiões, captando cada vez mais e mais condutas criminosas, intensificandoas ações policiais, entre outras situações. Talvez assim se imagine a SWAT entrando nos bairros nobres deChicago (O’NEIL, 2016), ou talvez, no Brasil, o BOPE invadindo violentamente bairros prestigiosos de SãoPaulo.4 Reconhecimento facial no BrasilSobre o  uso  do  reconhecimento facial  no  Brasil, o  estudo “Regulação do  reconhecimento facial  no  setorpúblico”, lançado em junho de 2020 pelo Instituto Igarapé e Data Privacy Brasil (FRANCISCO et al., 2020)baliza aspectos fundamentais da discussão, comparando a legislação referente ao tema na Inglaterra, Françae Estados Unidos. Nestes três países, respectivamente, observa-se: a incorporação das políticas de proteçãode dados à legislação vigente; legislações que exigem anuência expressa do usuário sobre os possíveis usosdas informações que fornecem, e legislações que vedam o uso de dados obtidos virtualmente por parte deempresas e Estado. Em outro estudo do Instituto Igarapé, levantou-se que, até 2019, 16 estados do Brasilcontavam com o uso de tecnologia de reconhecimento facial, distribuindo-se em 30 municípios diferentes(INSTITUTO IGARAPÉ, 2019). Tratam-se de  48  iniciativas público-privadas distribuídas em  áreas comotransporte (21), segurança pública (13), educação (5), controle de fronteiras (4) e outras (4) (INSTITUTOIGARAPÉ, 2019).  No  campo do  transporte, busca-se reduzir o  número de  fraudes quanto ao  transportegratuito; na educação controla-se frequência e ausência dos alunos; enquanto no campo da segurança públicatrata-se da identificação e procura de foragidos.Sobre o  controle jurídico destas tecnologias, em  que  pese  a  Lei  Geral de  Proteção de  Dados Pessoais13.709/2018, o governo brasileiro editou a portaria n° 793/2019, que regulamenta o uso de dinheiro doFundo Nacional de Segurança Pública para o “fomento à implantação de sistemas de vídeo monitoramentocom soluções de reconhecimento facial, por Optical Character Recognition - OCR, uso de inteligência artificialou outros”. A portaria representa o estímulo a políticas de reconhecimento facial, sem, em contrapartida,desenvolver um marco de controle e limitação desses dispositivos, que já são utilizados na atividade policial.Atualmente, a intensificação que nos referimos opera em direção a políticas criminais que trabalham comeficiência. O uso das tecnologias de reconhecimento facial marca a reprodução em outra esfera – tecnológica– do racismo estrutural enquanto evita críticas sob o abrigo da neutralidade científica tecnológica. O usodesses instrumentos constitui uma política atuarial de controle, que corresponde a um processo originalmenteamericano de desenvolver tabelas e testes de cálculo de reincidência. Essa técnica, inicialmente destinada àexecução penal, passa a integrar políticas criminais de atuação policial (DIETER, 2012, p. 84). A eficiência,então, é  medida pela  reincidência específica que  se  traduzirá  como periculosidade. Assim, temos odesenvolvimento de uma política criminal que se justifica pela busca em prender menos e concentrar seusesforços em prender “melhor”, em selecionar indivíduos de alto risco, supostamente responsáveis pela maioriados crimes cometidos. Em tese, guiando a ação policial e as decisões judiciais por meio da vinculação a itensintegrantes do cálculo de risco, seus agentes (policiais e juízes) teriam menor espaço de discricionariedade9 ese reduziriam as práticas racistas desses espaços. Tratou-se literalmente da automação dos processos decriminalização. Ao contrário do que propôs, a adoção da política criminal atuarial foi decisiva no aumento do
Por mais que para alguns a tecnologia de reconhecimento facial possa pareceruma novidade misteriosa e incerta em seus resultados, para os rapazes jovens enegros ela tem representado a certeza de que continuarão a ser abordados deforma preferencial, em nome da chamada “guerra às drogas”. O reconhecimentofacial tem  se  mostrado uma  atualização high-tech para  o  velho e  conhecidoracismo que está na base do sistema de justiça criminal e tem guiado o trabalhopolicial há décadas. (NUNES, 2019, p. 69-70)encarceramento da população negra nos Estados Unidos (DIETER, 2012; ALEXANDER, 2018). Compreendendoo que significa uma política criminal atuarial, principalmente no que versa sobre a automação do controlesocial/penal sobre a criminalização secundária, emerge em toda sua complexidade o uso do reconhecimentofacial como medida de  política criminal no  Brasil, tornando urgentes debates sobre como contribui econtribuirá para o encarceramento em massa e na potencialização e reprodução da discriminação, repressão ereclusão da população negra.Em 2019, uma rede de observatórios de segurança estudou violência e uso do reconhecimento facial comomedida de segurança pública e política criminal em cinco diferentes estados do País, durante cinco meses. Dorelatório, depreende-se que a ideia de eficiência a partir da tecnologia não encontra respaldo: na Bahia,durante o carnaval, o sistema de reconhecimento identificou mais de 1.300.000 rostos, gerando 903 alertas,18 mandados e prisão de 15 pessoas, ou seja, 96% das notificações foram inúteis (NUNES, 2019). Dos dadosobtidos, quanto ao perfil dos presos por reconhecimento facial, 87,9% dos suspeitos foram homens e 12,1%mulheres; já quanto à raça, 90,5% das pessoas eram negras e 9,5% eram brancas. As abordagens forammotivadas majoritariamente por delitos de tráfico e roubo (NUNES, 2019, p. 69).A discriminação racial via reconhecimento facial não é uma exclusividade do Brasil. Nos estudos de Garvie eFrankle (2016) já se apontava que os dispositivos utilizados pela polícia norte americana falhavam duas vezesmais em reconhecer e diferenciar rostos negros do que brancos, levando a intensificação da vigilância sobre apopulação negra através de  falsos positivos. Essas falhas, conforme já  apontamos, são  construídaspreliminarmente nas opções de engenharia e na manutenção desses aparelhos. Nesse sentido, o viés racialnão se dá via intencionalidade da máquina, mas por uma série de amarras na sua construção – envolvendoseus desenvolvedores e operadores, como no banco de imagens utilizado para “treinar” o reconhecimentofacial (GARVIE, FRANKLE, 2016).A pesquisa dos autores reforça o elemento de raça enquanto relacional e circunscrito. Isso porque dispositivosdesenvolvidos em outras regiões do mundo, conforme Patrick J. Grother, George W. Quinn e Jonathon Phillips(2011) pelo National Institute of Standards and Technology (NIST) em relatório que media avanços dessatecnologia, verificaram que as tecnologias desenvolvidas na China, Japão e Coréia do Sul reconheciam commaior precisão feições Asiáticas que  outras. Igualmente, Estados Unidos, França e  Alemanha, em  quereconheciam melhor feições caucasianas que  outras. A  pesquisa, comparando diferentes empresas quetrabalham com reconhecimento facial, identificou sutis diferenças no que se refere a gênero, idade e peso,mas  destacou uma  significativa diferença na  precisão do  reconhecimento no  que  diz  respeito à  raça:  odesempenho dos dispositivos é diretamente ligado ao banco de dados utilizado para treinar a máquina e visamum grupo demográfico específico (GROTHER et al., 2011).Quase dez anos depois, o mesmo instituto lançou uma nova pesquisa comparando 18.270.000 imagens e8.490.000 pessoas, utilizando-se dos  189  algoritmos mais  comerciais de  99  empresas diferentes. Nestapesquisa, verificou-se a manutenção da problemática do estudo anterior no que tange à centralidade que cadaalgoritmo dá para determinada fisionomia, a partir da região em que é produzido (GROTHER et al., 2019). Asconclusões foram ainda mais graves: os falsos positivos são altos nos indivíduos negros norte-americanos,leste e sul asiáticos e indivíduos da América Central. Os indivíduos com menos falsos positivos são homensbrancos americanos ou europeus. Contrariamente, os falsos negativos são majoritariamente da populaçãonegra (GROTHER et al., 2019). Essa armadilha da visibilidade, que ora invisibiliza, ora destaca a populaçãonegra, sempre é feita em um contexto. O elemento relacional da raça demonstra a perspectiva etnocentradados algoritmos, e, no Brasil, apresenta um efeito especialmente nocivo à população negra.5 ConclusãoPela recente importação e implementação da tecnologia, as pesquisas sobre reconhecimento facial no Brasilsão  escassas. Ainda assim, os  estudos preliminares e  os  dados sobre o  perfil  dos  selecionados por  estatecnologia indicam a reprodução da seletividade racial da programação criminalizante. Nesse sentido, Nunes(2019) escreve:Diante deste cenário, três horizontes de pesquisa mostram-se indispensáveis: 1) Estudos jurídicos na buscade uma legislação limitante da atuação estatal frente às novas tecnologias, principalmente em sua face mais
violenta (sistema de  justiça criminal); 2)  Pesquisas voltadas à  análise dos  impactos da  utilização doreconhecimento facial na  criminalização secundária; 3)  Estudos  que  tensionem a  gramática racial naprogramação maquínica destes dispositivos.O presente artigo buscou demonstrar que a tecnologia não é isenta de intenções, não é neutra, e que aprogramação de seus dispositivos, codificados a reconhecer o padrão branco, implica em uma reprodução doracismo na  potencialidade de  empreender o  encarceramento da  população negra através dos  “falsospositivos”. Estes demonstram a incapacidade dos aparelhos em reconhecer rostos não brancos, e implicam emuma generalização do negro como culpado. Como reboot da política criminal atuarial, o reconhecimento facialnão é neutro. Sua programação amplifica e automatiza o já racializado processo de criminalização secundária,porém acrescentando ao agente humano o elemento maquínico. Sobretudo, o funcionamento institucionalancorado no que é branco normatiza e normaliza a violência frente ao que não o é; o que enseja, além deuma discussão crítica, um debate sobre a regulamentação jurídica desses dispositivos.O contexto em que vivemos hoje, atravessado pela pandemia causada pela Covid-19, só demonstra aquiloque  há  muito tempo o  movimento negro e  os/as intelectuais negros/as já  denunciavam: o  racismo,juntamente com outros marcadores de opressão imbricados, estrutura as desigualdades no País. Por meiostecnológicos ou  não,  ancorado sob  uma  suposta neutralidade,  é  que  o  Estado atua  como agentepotencializador do que Abdias do Nascimento (1978) chamou de genocídio da população negra, não apenascomo morte física, e que segue alimentado pelo racismo. Não questionar os indicadores sociais de pobreza eexclusão, impostos às pessoas negras nos mais diversos contextos, é continuar naturalizando o racismo enegá-lo enquanto processo gerador de violência, desigualdade e exclusão!ReferenciasALEXANDER, M. A Nova Segregação: racismo e encarceramento em massa. São Paulo: Boitempo, 2018a.ALEXANDER, M. The newest Jim Crow. The New York Times. New York, p. 3, 8 nov. 2018b. Disponível em:https://www.nytimes.com/2018/11/08/opinion/sunday/criminal-justice-reforms-race-technology.html.  Acessoem 14 ago. 2020ALMEIDA, S. O que é racismo estrutural? Belo Horizonte: Letramento, 2018.ANDRADE, V. R. Pelas mãos da criminologia: o controle penal para além da (des)ilusão. Rio de Janeiro:Instituto Carioca de Criminologia, 2012.BATISTA, V. M. Introdução crítica à criminologia brasileira. Rio de Janeiro: Revan, 2011.BECKER, H.  S. Outsiders:  estudos de  sociologia do  desvio. Tradução Maria Luiza  X.  de  Borges. Rio  dejaneiro: Zahar, 2008.BENJAMIN, R. Race After Technology. Cambridge: Polity Press, 2019.BROWN, S. Dark Matters: on the survillence of blackness. Durhan: Duke Press, 2015.CHUN, W. H. K. Programmed Visions: Software and Memory. Cambridge, Massachusetts: MIT Press, 2011.DIETER, M. S. Política Criminal Atuarial: a criminologia do fim da história. 2012. Tese (Doutorado emDireito) – Universidade Federal do Paraná, Curitiba, 2012.DUARTE, E. P.; QUEIROZ, M. V. L.; COSTA, P. A.. A Hipótese Colonial, um diálogo com Michel Foucault: amodernidade e o Atlântico Negro no centro do debate sobre racismo e Sistema penal. Universitas JUS,Brasília, v. 27, n. 2, p. 1-31, jul/dez. 2016.DUARTE, E. P. Paradigmas em criminologia e relações raciais. In: Cadernos dos CEAS, Salvador, n. 238, p.500-526, Número Especial. 2016.FLAUZINA, A. L. P.; PIRES, T. R. O. Políticas da morte: Covid-19 e os labirintos da cidade negra. RevistaBrasileira de Políticas Públicas. Brasília, n. 2, v. 10, p. 66-84, Ago. 2020.FOUCAULT, M. Em defesa da sociedade. São Paulo: Editora Martins Fontes, 2010.
FRANCISCO, P. A. P; HUREL, L. M.; RIELLI, M. M. Regulação do reconhecimento facial no setor público.Igarapé; Data Search Brasil, 2020.FLUSSER, V. Mundo Codificado. São Paulo: Cosac Naify, 2007.GARVIE, C.;  FRANKLE, J. Facial-Recognition Software Might Have a  Racial Bias  Problem.  Atlantic,2016. Disponível em: https://www.theatlantic.com/technology/archive/2016/04/the-underlying-bias-of-facial-recognition-systems/476991/. Acesso em: 12 ago. 2020.GILMORE, R. Golden Goulag: Prisons, Surplus, Crisis, and Opposition in Globalizing California. Berkeley:California Press, 2007.GROTHER, P.  J.;  QUINN, G.  W.;  PHILLIPS, P.  J. Report on  the  Evaluation of  2D  Still-Image FaceRecognition Algorithms.  NIST, 2011. Disponível em: https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=905968. Acesso em: 12 ago. 2020.GROTHER, P. J.; NGAN, M.; HANAOKA, K. Face Recognition Vendor Test. Part 3: Demographic EffectsNIST, 2019. Disponível em: https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf. Acesso em: 12 ago.2020HAN, B.  C. O  coronavírus de  hoje e  o  mundo de  amanhã.  2020.  Disponível em:https://brasil.elpais.com/ideas/2020-03-22/o-coronavirus-de-hoje-e-o-mundo-de-amanha-segundo-o-filosofo-byung-chul-han.html. Acesso em: 23 out. 2020.INSTITUTO IGARAPÉ. Reconhecimento facial no   Brasil,   n.p., 2019. Disponível em:https://igarape.org.br/infografico-reconhecimento-facial-no-brasil/. Acesso em: 07 ago. 2020.LEAL, J. S. Criminologia da Libertação: a construção da criminologia crítica latino-americana como teoriacrítica do controle social e a contribuição desde o Brasil. Belo Horizonte: D’Plácido, 2017.MCILWAIN, C. D. Black Software: The Internet & Racial Justice, from the AfroNet to Black Lives Matter. NewYork, Oxford University Press, 2020.NASCIMENTO, Abdias do. O Genocídio do Negro Brasileiro.  Processo  dum  racismo mascarado.  Rio  deJaneiro: Paz e Terra, 1978.NUNES, P. Novas ferramentas, velhas práticas: reconhecimento facial e policiamento no Brasil. In: REDE deObservatório de Segurança. Retratos da Violência: cinco meses de monitoramento, análise e descobertas.Centro de Estudos em Segurança e Cidadania, 2019. (relatório).O’NEIL, C. Weapons of Math Destruction: how big data increase inequality and threatens democracy. NY:Crown, 2016.QUIJANO, A.  Colonialidade do  Poder, Eurocentrismo e  América Latina. In:  LANDER, Edgardo (org.)Colonialidade do Saber:  eurocentrismo e  ciências sociais. Perspectivas latinoamericanas. Buenos Aires:CLACSO, 2005. Disponível em: http://biblioteca.clacso.edu.ar/clacso/sur-sur/20100624103322/12_Quijano.pdf. Acesso em: 21 ago. 2020.SANTANA, M.  C.;  BICALHO, P.  S.  S.  A  construção negativa e  o  mito  da  democracia racial: uma  análisecomparativa entre a condição do negro no Brasil e nos Estados Unidos. Revista Eletrônica de InteraçõesSociais –  REIS.   Rio   Grande, v.   3,   n.1, p.   8-16, jan/jun. 2019.   Disponível em:https://periodicos.furg.br/reis/article/view/9074. Acesso em: 10 ago. 2020.SCHUCMAN, L. V. Entre o “encardido”, o “branco” e o “branquíssimo”: raça, hierarquia e poder naconstrução da branquitude paulistana. Tese (Doutorado em Psicologia) Instituto de Psicologia, Universidade deSão Paulo. São Paulo, 2012.SILVA, T. Comunidades, algoritmos e ativismos digitais: Olhares afrodiaspóricos. Literarua: São Paulo,2020.WARK, M. Capital is dead. London: Verso, 2019