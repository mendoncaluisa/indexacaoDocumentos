Um Mecanismo de Aprendizado Incremental para
Detecc¸ ˜ao e Bloqueio de Minerac¸ ˜ao de Criptomoedas
em Redes Definidas por Software
Helio N. C. Neto1, Martin Andreoni Lopez2,
Natalia C. Fernandes1, Diogo M. F. Mattos1
1M´ıdiaCom - PPGEET/TET/UFF
Universidade Federal Fluminense - UFF
2Samsung Research Institute - Brasil
Resumo. A minerac¸ ˜ao n˜ao autorizada de criptomoedas implica o uso de valio-
sos recursos de computac¸ ˜ao e o alto consumo de energia. Este artigo prop˜oe o
mecanismo MineCap, um mecanismo dinˆamico e em linha para detectar e blo-
quear fluxos de minerac¸ ˜ao n˜ao autorizada de criptomoedas, usando o apren-
dizado de m´aquina em redes definidas por software. O MineCap desenvolve a
t´ecnica de super aprendizado incremental, uma variante do super learner apli-
cada ao aprendizado incremental. O super aprendizado incremental proporci-
ona ao MineCap precis˜ao para classificar os fluxos de minerac¸ ˜ao ao passo que
o mecanismo aprende com dados recebidos. Os resultados revelam que o me-
canismo alcanc¸a 98% de acur´acia, 99% de precis˜ao, 97% de sensibilidade e
99,9% de especificidade e evita problemas relacionados ao desvio de conceito.
Abstract. Covert mining of cryptocurrency implies the use of valuable compu-
ting resources and high energy consumption. In this paper, we propose Mine-
Cap, a dynamic online mechanism for detecting and blocking covert crypto-
currency mining flows, using machine learning on software-defined networking.
MineCap uses a novel technique called super incremental learning, a variant
of the super learner with incremental learning. Hence, we design an accurate
mechanism to classify mining flows that learn with incoming data with an ave-
rage of 98% accuracy, 99% accuracy, 97% sensitivity and 99.9% specificity and
avoid concept drift-related issues.
1. Introduc¸ ˜ao
As redes corporativas s˜ao alvos constantes de ataques [Ingols, 2009,
Porras e Valdes, 2001] e a minerac¸ ˜ao n˜ao autorizada de criptomoedas ´e uma nova
ameac¸a a essas redes. Tal atividade prejudica o ambiente corporativo, devido ao consumo
excessivo de recursos de computac¸ ˜ao e energia, embora nem sempre a minerac¸ ˜ao seja ex-
plicitamente proibida na rede [de Oliveira et al., 2019, Tahir et al., 2017]. Uma variac¸ ˜ao
dessa ameac¸a ocorre em aplicativos que mineram criptomoedas sem o conhecimento ou
consentimento do usu´ario, como malwares ou injec¸ ˜ao de scripts em p´aginas Web.
Este trabalho foi realizado com recursos da CNPq, CAPES, FAPERJ, RNP e TAESA.
Em ambientes corporativos, a ameac¸a da minerac¸ ˜ao de criptomoedas pode ser
interna ou externa. A ameac¸a interna consiste em usu´arios internos que usam conscien-
temente o poder computacional da infraestrutura da empresa para realizar a minerac¸ ˜ao
para fins particulares. Por outro lado, as ameac¸as externas consistem em entidades que
exploram vulnerabilidades da infraestrutura para executar c´odigos de minerac¸ ˜ao de crip-
tomoeda. Portanto, identificar o tr´afego de minerac¸ ˜ao torna-se essencial para garantir o
uso eficiente e seguro dos recursos computacionais da empresa. Contudo, esta ´e uma ta-
refa complexa, j´a que as caracter´ısticas de fluxo de minerac¸ ˜ao geralmente s˜ao semelhantes
`as do tr´afego criptografado de navegac¸ ˜ao Web, tornando-se simples ocultar o tr´afego mal-
intencionado. Assim, h´a uma clara necessidade de ferramentas para detectar e impedir o
tr´afego n˜ao autorizado de minerac¸ ˜ao em ambientes em que as pol´ıticas de rede pro´ıbem a
atividade de minerac¸ ˜ao de criptomoeda.
Este artigo prop˜oe o MineCap, um mecanismo que utiliza algoritmos de apren-
dizado de m´aquina para realizar a classificac¸ ˜ao em linha do tr´afego de minerac¸ ˜ao de
criptomoeda em redes definidas por software (Software-Defined Networks - SDN). Nas
redes definidas por software, o plano de controle e encaminhamento s˜ao desacoplados
e introduz-se uma nova entidade, o controlador SDN [Bannour et al., 2018], respons´avel
por executar todas as ac¸ ˜oes de controle na rede. O controlador SDN permite que a rede se
torne program´avel e que os aplicativos de controle interajam com os elementos de rede,
como os comutadores, de forma logicamente centralizada [Mattos et al., 2016]. Assim, as
SDN permitem um bloqueio efetivo dos fluxos de minerac¸ ˜ao, por meio de uma interac¸ ˜ao
direta entre o MineCap e o controlador da rede. Assim, o MineCap consegue bloquear
dinamicamente os fluxos de minerac¸ ˜ao que s˜ao reconhecidos com o algoritmo de apren-
dizado de m´aquina.
O artigo prop˜oe ainda a t´ecnica de super aprendizado incremental que ´e uma va-
riante da t´ecnica super learner aplicada ao aprendizado incremental. A ideia chave da
proposta ´e realizar o aprendizado incremental sobre as classificac¸ ˜oes providas por um
agregado de classificadores de menor acur´acia. Para tanto, avaliou-se o desempenho de
quatro classificadores: Floresta Aleat´oria, Naive Bayes, Regress˜ao Log´ıstica e Gradient
Boosted Tree. Os dois algoritmos com melhor desempenho foram usados na t´ecnica de
super aprendizado incremental, com o objetivo de aumentar a acur´acia da detecc¸ ˜ao. O su-
per aprendizado incremental utiliza a t´ecnica de super learner [Van der Laan et al., 2007]
combinada com o aprendizado incremental, de forma que o super modelo aprende com
novos dados sem o esquecimento catastr´ofico e consequente descarte do classificador.
O MineCap executa sobre o arcabouc¸o de processamento Apache Spark, atrav´es
das bibliotecas Spark Streaming, que manipula o fluxo de dados, e a MLlib, que for-
nece os algoritmos de aprendizado de m´aquina na classificac¸ ˜ao em linha. A avaliac¸ ˜ao
do prot´otipo do MineCap foi realizada em uma rede emulada pela plataforma Mininet,
utilizando o controlador SDN Ryu com a API REST habilitada para instalar regras de
bloqueio dos fluxos. Os resultados das avaliac¸ ˜oes mostram que o MineCap tem baixo
consumo dos recursos de rede e computacional enquanto analisa todo o tr´afego de rede.
Trabalhos relacionados se concentram em identificar o tr´afego de minerac¸ ˜ao usando o
aprendizado de m´aquina [Tahir et al., 2017, Konoth et al., 2018]. Contudo, eles protegem
Dispon´ıvel em https://github.com/mininet/mininet.
Dispon´ıvel em https://osrg.github.io/ryu/.
um ´unico host, enquanto o MineCap protege toda a rede e, por ser baseado no paradigma
SDN, permite a definic¸ ˜ao de pol´ıticas de bloqueio em alto n´ıvel [Mattos et al., 2016] di-
retamente nos elementos de rede mais pr´oximos `as fontes de tr´afego.
O restante do artigo est´a organizado da seguinte forma. A Sec¸ ˜ao 2 discute os tra-
balhos relacionados. A Sec¸ ˜ao 3 apresenta as t´ecnicas para o processamento de grandes
massas de dados, e a Sec¸ ˜ao 4 prop˜oe a t´ecnica de super aprendizado incremental. O me-
canismo MineCap ´e definido na Sec¸ ˜ao 5 e a Sec¸ ˜ao 6 apresenta os resultados da avaliac¸ ˜ao.
Por fim, a Sec¸ ˜ao 7 conclui o artigo.
2. Trabalhos Relacionados
Tahir et al. prop˜oem a ferramenta MineGuard para detectar em tempo real o com-
portamento de processos de minerac¸ ˜ao em m´aquinas virtuais [Tahir et al., 2017]. Mi-
neGuard utiliza contadores de desempenho de hardware (Hardware Performance Coun-
ters - HPCs), um conjunto de registradores integrados em processadores modernos, para
armazenar as contagens de atividades relacionadas ao hardware. Os contadores permi-
tem rastrear com precis˜ao as operac¸ ˜oes de minerac¸ ˜ao de baixo n´ıvel ou eventos dentro da
CPU e GPU com sobrecarga m´ınima, dando `a ferramenta a capacidade de detectar com
precis˜ao, em tempo real, se uma m´aquina virtual est´a tentando minerar criptomoedas.
A MineGuard baseia-se na observac¸ ˜ao de que, para minerar criptomoedas, ´e necess´ario
executar repetidamente o algoritmo de Proof-of-Work (PoW).
O MineSweeper [Konoth et al., 2018] usa a URL do s´ıtio Web como entrada para
verificar se h´a algum software de minerac¸ ˜ao de criptomoedas oculto. O MineSweeper usa
uma m´etrica para identificar func¸ ˜oes criptogr´aficas, medindo o n´umero de operac¸ ˜oes exe-
cutadas por um aplicativo. Os autores analisam o algoritmo CryptoNight e suas variantes,
mas argumentam que adicionar outros algoritmos ´e uma tarefa trivial. O MineSweeper
concentra-se na minerac¸ ˜ao embarcada em p´aginas Web e seu principal objetivo ´e identi-
ficar um novo ataque, o drive-by mining, no qual um s´ıtio infectado executa secretamente
c´odigo JavaScript ou um m´odulo WebAssembly no navegador do usu´ario para minerar
criptomoedas sem o seu consentimento. Diferentemente do MineSweeper, o MineCap
concentra-se em detectar e bloquear tr´afego de minerac¸ ˜ao de criptomoeda na rede.
Andreoni et al. prop˜oem a CATRACA, uma ferramenta em linha para a detecc¸ ˜ao
e prevenc¸ ˜ao de ataques em uma func¸ ˜ao virtual de rede [Andreoni Lopez et al., 2019]. As-
sim como o MineCap, a ferramenta proposta utiliza um sistema de processamento de fluxo
para as grandes massas de dados (Big Data), o Apache Spark, fornecendo um servic¸o de
detecc¸ ˜ao de ameac¸as em tempo real. A ferramenta CATRACA opera em dois modos:
online ou offline. O processo de detecc¸ ˜ao inclui algoritmos de selec¸ ˜ao de caracter´ısticas e
aprendizado de m´aquina para discriminar tr´afego normal, negac¸ ˜ao de servic¸o (Denial of
Service - DoS) e varredura de portas. Em uma detecc¸ ˜ao de ameac¸a, o sistema pode reagir
prontamente e criar regras de bloqueio em um firewall. O MineCap usa uma abordagem
semelhante, mas integra a capacidade de bloqueio de fluxos utilizando uma rede definida
por software sem a necessidade de usar outras ferramentas.
3. Processamento de Grandes Massas de Dados
As t´ecnicas tradicionais de banco de dados n˜ao permitem o processamento de
dados estruturados e n˜ao estruturados em grandes volume, variedade e velocidade.
Na maioria dos ambientes corporativos, o volume e a velocidade de gerac¸ ˜ao dos
dados excede a taxa de transferˆencia dos gerenciadores de banco de dados relacio-
nais [McAfee et al., 2012]. Para a extrac¸ ˜ao de conhecimentos ´uteis dos metadados para
aumentar a receita, conquistar ou reter clientes e melhorar as operac¸ ˜oes, as empresas co-
letam dados de v´arias fontes, incluindo e-mails, dispositivos m´oveis, aplicativos, bancos
de dados, servidores e m´ıdias diversas. Os dados obtidos devem ser extra´ıdos, forma-
tados, manipulados, armazenados e analisados. A an´alise das grandes massas de dados
pode ocorrer em lote ou em fluxo [Medeiros et al., 2019]. O processamento em lote ´e a
forma mais tradicional de processamento de grandes massas de dados. Normalmente, os
dados s˜ao armazenados para serem processados posteriormente por meio de realizac¸ ˜ao
de consultas [Carbone et al., 2015]. No processamento por lotes, ´e comum usar Online
Analytical Processing (OLAP), sistemas capazes de analisar grandes volumes de dados de
forma r´apida e eficiente, t´ecnicas de minerac¸ ˜ao de dados e processamento paralelo com
ferramentas como o Apache Hadoop. O processamento em fluxo ´e comumente usado
por aplicativos que exigem baixo tempo de resposta para combinar a captura de dados em
fluxo (in-stream) com o uso de t´ecnicas de inferˆencia e correlac¸ ˜ao [Medeiros et al., 2019].
No MineCap, todos os pacotes na sa´ıda da rede s˜ao processados, a fim de iden-
tificar os fluxos de minerac¸ ˜ao de criptomoeda. O MineCap utiliza o processamento de
dados em fluxo devido ao grande n´umero de pacotes na sa´ıda da rede, que combina ca-
racter´ısticas de alto volume de dados e alta velocidade de gerac¸ ˜ao. Existem ferramentas
de processamento distribu´ıdo em fluxo de c´odigo aberto, como a Apache Flink, a Apa-
che Storm e a Spark Streaming, que funcionam em aglomerados computacionais, mas
a ´unica que garante a entrega de 100% das mensagens em cen´arios de falha ´e a Spark
Streaming [Andreoni Lopez et al., 2019]. A Spark Streaming permite a programac¸ ˜ao de
aplicac¸ ˜oes nas linguagens Scala, Java, Python e R. Por essas vantagens o MineCap utiliza
o Spark Streaming para processamento em fluxo de grandes massas de dados.
4. Proposta de Super Aprendizado Incremental
A t´ecnica de super aprendizado incremental, proposta neste artigo, ´e a
combinac¸ ˜ao das t´ecnicas super learner [Van der Laan et al., 2007] e aprendizado incre-
mental [Fei-Fei et al., 2007]. Na proposta, algoritmos de aprendizado de m´aquina s˜ao
usados como modelos candidatos que alimentam o super modelo. Os modelos candidatos
s˜ao treinados e realizam as previs˜oes que s˜ao entregues como entrada para o super modelo.
Ent˜ao, posteriormente o super modelo ´e treinado parcialmente utilizando o aprendizado
incremental.
A t´ecnica do super learner consiste em treinar um modelo no qual as amostras
de entrada s˜ao a sa´ıda de outros modelos, semelhante a um sistema hier´arquico. Van der
Laan et al. [Van der Laan et al., 2007] foram os primeiros a usar esta t´ecnica, utilizando a
validac¸ ˜ao cruzada, para propor um novo m´etodo de previs˜ao criado a partir da combinac¸ ˜ao
ponderada de diversos modelos candidatos. O primeiro passo do super learner proposto
por van der Laan et al. ´e treinar n modelos utilizando todo o conjunto de dados. No
segundo passo, ´e feita a divis˜ao do conjunto de dados original em V blocos e, depois, cada
modelo candidato ´e treinado com um desses blocos, chamados de blocos de validac¸ ˜ao.
Logo, ´e feita a previs˜ao dos blocos de dados de validac¸ ˜ao correspondente a cada bloco
de treinamento. Na sequˆencia, s˜ao feitos ajustes do resultado observado dos resultados
previstos de cada modelo candidato e, por fim, ´e feito o treinamento do super modelo
com os resultados previstos pelos modelos candidatos. Pode-se avaliar o super modelo
comparando com as previs˜oes de cada modelo candidato, feito no primeiro passo, com
a sa´ıda do super modelo. A Figura 1 mostra o diagrama da t´ecnica original do super
learner.Conjunto
de dados
1
2
...
V
1
2
...
V
1
2
...
V
RF GBT ... SVM
RF GBT ... SVM
RF GBT ... SVM
RF GBT ... SVM
1 1 ... 1
2 2 ... 2
... ... ... ...
V V ... V
Modelos Candidatos Prev.
Y
1
2
...
V
Super
Modelo
Seleção e
ajuste
2. Dividir os
dados em V
blocos
3. Treinamento de
todos os modelos
candidatos
4. Prever cada amostra do
conjunto de validação com base
em seu conjunto de treinamento
correspondente 5. Ajuste e
seleção para
todos os
resultados
observados dos
modelos
candidatos
RF GBT ... SVM
6. Avaliar o super modelo
combinando previsões de
cada modelo candidato
1. Treinar cada modelo candidato com
o conjunto de dados inteiro
Figura 1. Diagrama de fluxo com as etapas da t ´ecnica Super Learner. Adaptado
de [Van der Laan et al., 2007]
A ideia principal do aprendizado incremental, tamb´em conhecido como aprendi-
zado em linha, ´e limitar a perda de informac¸ ˜ao para o uso de dados finitos em relac¸ ˜ao
a modelos com dados infinitos. Para tanto, a perda de informac¸ ˜ao ´e feita em func¸ ˜ao
do n´umero de amostras em cada est´agio de aprendizado e, assim, o n´umero de amostras
utilizadas em cada um dos est´agios ´e m´ınimo e mantido livre do limiar de perdas preserva-
das [Medeiros et al., 2019]. A resoluc¸ ˜ao do problema de quanta informac¸ ˜ao ´e perdida di-
minuindo o n´umero de amostras ´e dada usando o limite de Hoeffding [Gama et al., 2014].
Considerando uma vari´avel aleat´oria real x, cujo valor est´a contido no intervalo R,
presume-se que n observac¸ ˜oes independentes da vari´avel s˜ao feitas e a m´edia ¯r ´e compu-
tada. O limite de Hoeffding garante com probabilidade 1 − δ que a verdadeira m´edia da
vari´avel ´e dada por pelo menos ¯x − , em que
 =
√
R2ln(1/δ)
2n . (1)
O limite de Hoeffding ´e independente da distribuic¸ ˜ao que gera a vari´avel x. A par-
tir desse resultado, os algoritmos de aprendizado de m´aquina para treinamento de dados
em fluxos s˜ao desenvolvidos. No entanto, assume-se que os valores gerados pela vari´avel
x vˆem de um processo estoc´astico constante. Nos casos em que h´a uma mudanc¸a no
processo que gera a vari´avel usada no treinamento de m´etodos de aprendizado em fluxo,
´e dito que ocorre uma mudanc¸a de conceito (concept drift) e, portanto, faz-se necess´ario
um novo treinamento do m´etodo de aprendizado [Wang et al., 2013].
Abordagens t´ıpicas para o aprendizado de novas informac¸ ˜oes envolvem manter o
comportamento estoc´astico dos dados ou realizar o descarte do classificador existente e
re-treinar com os dados acumulados at´e o momento. Nas abordagens que consideram o
fim da estabilidade estat´ıstica dos dados, o processo deixa de ser estoc´astico, resultando na
perda de todas as informac¸ ˜oes previamente adquiridas, o que ´e conhecido como esqueci-
mento catastr´ofico. Assim, Polikar et al. [Polikar et al., 2001] definem que os algoritmos
de aprendizado incremental devem satisfazer os requisitos a seguir ao obter informac¸ ˜oes
adicionais sobre novos dados: i) n˜ao requerer acesso aos dados originais usados para trei-
nar o classificador existente; ii) preservar o conhecimento previamente adquirido, isto ´e, o
classificador n˜ao deve sofrer o esquecimento catastr´ofico; e iii) ter capacidade de acomo-
dar novas classes que podem ser introduzidas por novos dados. Assim, os classificadores
que adotam o aprendizado incremental n˜ao requerem o treinamento total do classificador
no caso de uma mudanc¸a no comportamento do fluxo de dados.
Na proposta super aprendizado incremental ´e feita uma mesclagem da variante do
super learner e, para gerar o super modelo, s˜ao usadas redes neurais com aprendizado
incremental para o aprendizado em linha. Na variante do super learner, ´e feita a divis˜ao
do conjunto de dados em um conjunto de treinamento e um conjunto de teste. Em se-
guida, utiliza-se o conjunto de treinamento para treinar os modelos candidatos. No caso
do MineCap, foram utilizados os algoritmos floresta aleat´oria e Gradient Boosted Tree,
treinando ambos com o mesmo conjunto de dados. Cada amostra do conjunto de dados
de entrada para o super modelo tem como atributos as probabilidades da amostra ser da
classe fluxo normal, classificado como 0, ou fluxo de minerac¸ ˜ao, classificado como 1,
geradas a partir das previs˜oes feitas dos modelos candidatos aplicados sobre o conjunto
de dados de teste.
Os dois modelos candidatos geram a lista W = (w1, w2, w3, w4, y) em que w1
´e a probabilidade do primeiro modelo candidato retornar como sa´ıda a classe tr´afego
normal, w2 ´e a probabilidade do primeiro modelo candidato retornar como sa´ıda a classe
de trafego de minerac¸ ˜ao, w3 e w4 tˆem a mesma representac¸ ˜ao para o segundo modelo
candidato. Finalmente, y ´e a sa´ıda desejada de cada amostra, ou seja a classe alvo dessa
amostra. A lista W gerada pelos modelos candidatos ´e passada como entrada para treinar
a rede neural incremental utilizando o algoritmo de Perceptron Multi-Camadas (Multi-
Layer Perceptron - MLP). A Figura 2 mostra o diagrama da t´ecnica de super aprendizado
incremental desenvolvida no MineCap.Conjunto
de dados
Treino
Teste
Divisão
Gradient
Booster
Tree
Probabilidade
Verdadeiro
Probabilidade
Falso
Rede
Neural
Saída
(0,1)
Incremental
treinamento
parcial
Floresta
Aleatória
Figura 2. Diagrama de fluxo da t ´ecnica de super aprendizado incremental.
Quando o MineCap recebe novos dados, os envia aos modelos candidatos para
classificac¸ ˜ao e, em seguida, armazena as sa´ıdas em um arquivo chamado incremental.
Somente depois, envia os dados como entrada para a rede neural para realizar a previs˜ao.
A rede neural classifica cada amostra recebida em linha e anexa a sa´ıda prevista `a entrada
da amostra no arquivo incremental. Cada entrada do arquivo incremental possui a lista
W = (w1, w2, w3, w4, y), em que todos os w s˜ao a sa´ıda dos modelos candidatos, floresta
aleat´oria e Gradient Boosted Tree e, no caso do MineCap, y ´e a sa´ıda do super modelo.
Quando um n´umero k suficiente de amostras ´e acumulado, o processo incremental veri-
fica cada amostra e coleta apenas as amostras que possuem maior probabilidade de serem
fluxo de minerac¸ ˜ao e menor probabilidade de serem fluxo normal ou o inverso para depois
realizar a aprendizagem parcial. A quantidade k de amostras acumuladas para o treina-
mento parcial ´e proporcional ao tempo para a aprendizagem com novos dados. Quanto
maior a quantidade, maior o tempo para a aprendizagem. No prot´otipo do mecanismo
propostos, ´e usado o valor de k = 50, pois verificou-se que com 50 amostras h´a o com-
promisso de executar o treinamento parcial do super modelo entre 1 e 2 minutos, no caso
de ocorrˆencia constante de minerac¸ ˜ao na rede.
5. Mecanismo MineCap para Detecc¸ ˜ao e Bloqueio de Minerac¸ ˜ao
O mecanismo MineCap ´e executado em uma estac¸ ˜ao (host) ou em um aglome-
rado computacional (cluster) separado do controlador de rede. A execuc¸ ˜ao do MineCap
em uma estac¸ ˜ao separada do controlador de rede evita a sobrecarga no controlador. O
controlador da rede redireciona todos os pacotes de sa´ıda da rede local para o MineCap,
aplicando a t´ecnica de espelhamento de porta no gateway de rede. Conforme mostrado
na Figura 3, o mecanismo proposto apresenta uma arquitetura de trˆes camadas: captura,
processamento e bloqueio.Camada de Captura
Pacote Coleta
de pacotes
Abstração
de Fluxo
Produtor de
mensagens
libpcap flowtbag
Camada de Processamento
Dataset
Modelo
Treina Consumidor
de Fluxo
Redução de
CarcaterísticasClassificação
Camada de Bloqueio
API
REST Controlador
Rede
Instala os fluxos
de bloqueio
Figura 3. A arquitetura da ferramenta MineCap. Os pacotes chegam na interface
de rede, s ˜ao abstra´ıdos em fluxos que, por sua vez, s ˜ao publicados no servic¸ o
de mensagens Apache Kafka. O Spark Streaming consome a mensagem, pr ´e-
processa os dados e envia para o modelo treinado para classificac¸ ˜ao.
A camada de captura tem como objetivo capturar os dados e prepar´a-los para a
camada superior. O primeiro passo ´e capturar os pacotes de rede atrav´es da execuc¸ ˜ao da
biblioteca libpcap. Esses pacotes capturados s˜ao resumidos em fluxos de rede. Define-
se fluxo de rede como a sequˆencia de pacotes que possuem o mesmo IP de origem, IP
de destino, porta de origem, porta de destino e protocolo de transporte. Foi desenvolvida
uma aplicac¸ ˜ao na linguagem Python, baseada na aplicac¸ ˜ao flowtbag, para realizar a
Dispon´ıvel em https://github.com/DanielArndt/flowtbag.
abstrac¸ ˜ao de pacotes em fluxos. Os fluxos s˜ao publicados no servic¸o de mensagens Apa-
che Kafka, um sistema de publicac¸ ˜ao e assinatura (publisher/subscriber) que garante o
armazenamento e a entrega confi´avel das mensagens.
A camada de processamento ´e respons´avel por consumir, processar e classi-
ficar os fluxos da rede que o Apache Kafka fornece como dados em fluxo. O me-
canismo MineCap adota o Apache Spark como sua plataforma de processamento de
fluxo em linha. O Apache Spark Streaming apresenta melhor desempenho em relac¸ ˜ao
`a tolerˆancia a falhas quando comparado a outras plataformas de processamento de
fluxo [Andreoni Lopez et al., 2016], adicionando robustez e resiliˆencia ao processamento.
O MineCap evita assim a perda de informac¸ ˜ao. O Spark consome o conte´udo do
Kafka com a biblioteca Spark Streaming. O Apache Kafka ´e um intermedi´ario de
mensagens que entrega mensagens aos processos assinantes, mas n˜ao suporta execuc¸ ˜ao
de algoritmos mais complexos, como o aprendizado de m´aquina. O MineCap incor-
pora o algoritmo de An´alise de Componente Principal (Principal Component Analysis
- PCA) [Andreoni Lopez et al., 2016], que reduz um grande conjunto de atributos a um
conjunto menor de caracter´ısticas artificiais que ainda cont´em a maior parte da quantidade
de informac¸ ˜ao do conjunto original. A MLlib ´e a biblioteca de aprendizado de m´aquina
escal´avel do Spark que consiste em algoritmos e utilit´arios comuns para o aprendizado
de m´aquina. Neste trabalho, s˜ao avaliados quatro algoritmos de aprendizado de m´aquina:
Floresta Aleat´oria, Gradient Boosted Tree, Naive Bayes e Regress˜ao Log´ıstica.
A camada de bloqueio recebe a sa´ıda do classificador e instala uma regra
de bloqueio para fluxos rotulados como minerac¸ ˜ao de criptomoeda. O OpenFlow
1.3 [Open Networking Foundation, 2012] ´e o protocolo de rede definida por software uti-
lizado pelo MineCap. O Ryu ´e baseado em Python e foi escolhido como o controlador
SDN para o prot´otipo desenvolvido, devido `a sua facilidade de implantac¸ ˜ao e baixo tempo
para o desenvolvimento de aplicac¸ ˜oes. No entanto, qualquer outro controlador poderia
ser utilizado. A integrac¸ ˜ao entre o MineCap e o controlador ´e agn´ostica, o que possibi-
lita a integrac¸ ˜ao ou atualizac¸ ˜ao de outros controladores SDN. O MineCap se comunica
com o controlador por meio de um interface de Transferˆencia de Estado Representacio-
nal(Representational State Transfer - REST) executada no controlador, que recebe uma
mensagem criptografada, na qual os fluxos de minerac¸ ˜ao s˜ao identificados e, ent˜ao, as re-
gras de bloqueio s˜ao instaladas na rede. Essa ´e a camada de integrac¸ ˜ao com a rede, para o
MineCap funcionar com as redes tradicionais basta modificar essa camada. Por exemplo,
pode ser substitu´ıda a chamada REST para o controlador SDN por um comando via ssh
para o bloqueio no firewall da rede.
6. Avaliac¸ ˜ao do Prot´otipo
Um prot´otipo do MineCap foi desenvolvido para avaliar a proposta. Os experi-
mentos foram realizados em um computador equipado com um processador Intel Core i7
7700 a 3,60 GHz, com oito n´ucleos e 16 GB de RAM. A avaliac¸ ˜ao foi realizada em uma
rede emulada, usando a plataforma de emulac¸ ˜ao Mininet, com 16 hosts em uma topolo-
gia em ´arvore personalizada, usando sete comutadores executando o protocolo OpenFlow
1.3 [Open Networking Foundation, 2012].
Na primeira avaliac¸ ˜ao, entre os 16 hosts do ambiente, quatro deles executavam
Dispon´ıvel em https://osrg.github.io/ryu/.
aplicativos de minerac¸ ˜ao de criptomoedas em linha de comando populares para minerac¸ ˜ao
utilizando CPU e o restante estava repetindo um tr´afego de 30 minutos contido em um ar-
quivo de captura real, gerado por usu´arios reais, de tr´afego de rede, usando tcpreplay.
Nessa etapa, ´e avaliada a diferenc¸a entre os dois melhores modelos dentre os demais.
O tr´afego contido no arquivo de captura foi previamente classificado para ser comparado
com a sa´ıda de modelos de aprendizado de m´aquina, para ser utilizado como linha de base.
Utilizou-se pools de minerac¸ ˜ao com portas TCP conhecidas, para posterior classificac¸ ˜ao
manual do conjunto de dados utilizado para treinar os modelos candidatos. Nos testes
de avaliac¸ ˜ao, utilizaram-se pools diferentes das utilizadas no conjunto de dados de trei-
namento. O gateway de rede teve sua porta espelhada para o MineCap para garantir que
todo o tr´afego de rede passasse pela classificac¸ ˜ao. O MineCap instala um fluxo, com
durac¸ ˜ao de 5 minutos, no controlador SDN bloqueando todo o tr´afego classificado como
minerac¸ ˜ao de criptomoeda e, portanto, os pacotes s˜ao rejeitados diretamente no comuta-
dor OpenFlow da rede. O conjunto de dados utilizado para treinar e testar os modelos
foi criado em laborat´orio, em um ambiente estilo “mundo fechado”, em que o tr´afego foi
capturado em um ambiente controlado com um comutador, computadores atuando como
mineradores e outros utilizando diferentes perfis de navegac¸ ˜ao como streaming de v´ıdeo,
descarga de arquivos e acesso a s´ıtios Web. Os aplicativos de minerac¸ ˜ao utilizados foram
o MinerGate e o GuiMiner, executando em m´aquinas com sistema operacional Windows.
Antes de particionar o conjunto de dados em conjunto de treinamento e teste, o conjunto
de dados foi embaralhado para evitar qualquer elemento de vi´es ou padr˜oes nos conjuntos
de dados. Assim, com o conjunto de dados embaralhado, a qualidade e o desempenho
dos modelos s˜ao melhoradas. O conjunto de dados passou pelo processo de oversam-
pling, pois a t´ecnica ´e frequentemente usada para balancear a quantidade de classes do
conjunto de dados [Luengo et al., 2011].
A Figura 4 mostra a curva de caracter´ısticas operacionais do receptor (Receiver
Operating Characteristic - ROC), a precis˜ao, a sensibilidade e a especificidade de cada
algoritmo de classificac¸ ˜ao testado. A curva ROC mede e especifica o desempenho dos
algoritmos testados atrav´es do relacionamento entre verdadeiros positivos e falsos positi-
vos em diversos pontos de corte na probabilidade de uma amostra pertencer a uma classe.
´E um m´etodo gr´afico robusto e direto que permite estudar a variac¸ ˜ao da sensibilidade e
especificidade para diferentes valores de corte.
Os algoritmos de aprendizado de m´aquina Floresta Aleat´oria e Gradient Boos-
ted Tree superaram os outros algoritmos, com boa precis˜ao e sensibilidade. Regress˜ao
Log´ıstica e Naive Bayes tiveram 0 % de precis˜ao e sensibilidade, por isso ficaram sem
barras na Figura 4(b). A Regress˜ao Log´ıstica classificou cada fluxo como fluxo normal e
o Naive Bayes classificou alguns fluxos como normal e outros como fluxos de minerac¸ ˜ao
de criptomoedas, assim, eles n˜ao ser˜ao utilizados como modelos candidatos do super
aprendizado incremental.
Al´em dos testes de avaliac¸ ˜ao de aprendizado de m´aquina, s˜ao apresentados outros
O tr´afego de minerac¸ ˜ao usado para treinar os algoritmos de aprendizado de m´aquina se originam da
execuc¸ ˜ao dos aplicativos de minerac¸ ˜ao cpuminer e xmrig.
Dispon´ıvel em https://github.com/appneta/tcpreplay.
Dispon´ıvel em https://minergate.com.
Dispon´ıvel em https://guiminer.org.
0.0 0.2 0.4 0.6 0.8 1.0
Taxa de Falsos Positivos
0.0
0.2
0.4
0.6
0.8
1.0
Taxa de Verdadeiros Positivos
FA (AUC = 0.97)
RL (AUC = 0.68)
GB (AUC = 0.90)
NB (AUC = 0.63)(a) Curva de caracter´ısticas operacionais
do receptor (ROC).Precisão Sensibilidade Especificidade
0
20
40
60
80
100
Porcentagem (%) Floresta Aleatória
Regressão Logística
Gradient Booster Tree
Naive Bayes
(b) Precis˜ao, sensibilidade e especificidade dos algorit-
mos de classificac¸ ˜ao avaliados.
Figura 4. Avaliac¸ ˜ao dos algoritmos de aprendizado de m ´aquina. a) O algoritmo
de Floresta Aleat ´oria apresenta uma ´Area Abaixo da Curva (AUC) de 0,97 e, as-
sim, apresenta a melhor relac¸ ˜ao de compromisso entre sensibilidade e especifi-
cidade. b) Gradient Boosted Tree tamb ´em apresenta altas taxas de sensibilidade
e especificidade, por ´em s ˜ao inferiores `as da Floresta Aleat ´oria.
dois testes de desempenho. O primeiro ´e a relac¸ ˜ao dos pacotes entregues e os pacotes
gerados. O segundo consiste em um teste de latˆencia da rede para verificar se o MineCap
gera sobrecarga. Como os algoritmos de aprendizado de m´aquina Naive Bayes e Re-
gress˜ao Log´ıstica obtiveram mal desempenho, apenas os algoritmos de Floresta Aleat´oria
e Gradient Boosted Tree s˜ao apresentados nas pr´oximas avaliac¸ ˜oes. A Figura 5(a) mos-
tra a taxa de tr´afego entregue para os quatro hosts que estavam minerando criptomoedas.
Vale a pena observar que o algoritmo de Floresta Aleat´oria bloqueia pelo menos 80%
do tr´afego de minerac¸ ˜ao, enquanto o Gradient Boosted Tree atinge 25% do tr´afego de
minerac¸ ˜ao entregue no Host 8. Em m´edia, o algoritmo de Floresta Aleat´oria bloqueia
mais tr´afego na rede do que o Gradient Boosted Tree, devido sua maior capacidade de
generalizac¸ ˜ao do conhecimento obtido. Destaca-se tamb´em que os algoritmos baseados
em ´arvore tiveram melhor desempenho do que outros devido `a natureza discreta dos dados
de rede [Andreoni Lopez et al., 2016].Host 5 Host 8 Host 9 Host 13
0.00
0.05
0.10
0.15
0.20
0.25
Taxa de Pacotes Entregues
Floresta Aleatória
Gradient Booster Tree
(a) Taxa de pacotes de minerac¸ ˜ao de criptomoe-
das entregues em um tr´afego gerado de 30 min.FA GBT NB RL S/M
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
Latência (ms)
(b) Latˆencia de comunicac¸ ˜ao no cen´ario avaliado.
Figura 5. Avaliac¸ ˜ao da lat ˆencia na rede com e sem a ferramenta MineCap e
gr ´afico da taxa de pacotes de minerac¸ ˜ao entregue. a) O classificador Floresta
Aleat ´oria bloqueou 80% do tr ´afego de minerac¸ ˜ao enquanto o Gradient Boos-
ted Tree encaminhou mais que 25% do tr ´afego de minerac¸ ˜ao. b) O MineCap
n ˜ao acrescenta lat ˆencia na rede. Floresta Aleat ´oria (FA), Gradiente Boosted Tree
(GBT), Naive Bayes (NB), Regress ˜ao Log´ıstica (RL), Sem MineCap (S/M).
A latˆencia da rede foi analisada enquanto os testes eram realizados gerando pa-
cotes ICMP (Internet Control Message Protocol) de um host na rede para o controlador.
O teste de latˆencia foi executado nos testes com todos os algoritmos e, tamb´em, em um
novo cen´ario reproduzindo o mesmo tr´afego sem intervenc¸ ˜ao do MineCap. Os resultados
mostram que o mecanismo MineCap n˜ao implica mais latˆencia no encaminhamento de
pacotes e, assim, mant´em o desempenho da rede do cen´ario sem a adoc¸ ˜ao do MineCap,
como mostra a Figura 5(b). Tamb´em foi avaliado, separadamente, o tempo de resposta
de chamada REST que foi insignificante, mostrando um atraso de menos de 1 ms em
uma rede local, pois o tamanho dos pacotes nas chamadas ´e muito pequeno. O tempo
de bloqueio ´e em m´edia de 2 minutos, usando ambos os algoritmos, Floresta Aleat´oria
e Gradient Boosted Tree, porque `as vezes o algoritmo classifica fluxos de minerac¸ ˜ao de
criptomoedas como fluxos normais. Os modelos de aprendizado de m´aquina s˜ao pass´ıveis
de falhas, j´a que falsos positivos e negativos existem nos problemas de aprendizado de
m´aquina em que n˜ao h´a sobreajuste [Pietraszek e Tanner, 2005].
Floresta Aleat´oria e Gradient Boosted Tree obtiveram resultados similares, por´em
os testes anteriores utilizavam uma quantidade est´atica de mineradores. ´E importante
avaliar se o aumento na quantidade de mineradores na rede impacta o desempenho dos
classificadores. Assim, o teste com 30 minutos de tr´afego foi realizado variando a quan-
tidade de mineradores.
(a) Precis˜ao, sensibilidade, especificidade e precis˜ao do modelo Floresta Aleat´oria para cen´arios
com diferentes n´umeros de mineradores.
(b) Precis˜ao, sensibilidade, especificidade e precis˜ao do modelo Gradient Boosted Tree para
cen´arios com diferentes n´umeros de mineradores.
Figura 6. Avaliac¸ ˜ao dos algoritmos de aprendizado de m ´aquina de acordo com o
crescimento do n ´umero de mineradores.
A Figura 6 mostra que, `a medida que mais mineradores s˜ao adicionados `a rede,
a precis˜ao e a sensibilidade dos modelos diminuem, mas continuam com resultados
aceit´aveis, superiores a 75%. Paralelamente, ´e proposto uma variante do super lear-
ner [Van der Laan et al., 2007] usando esses dois modelos pelos seguintes motivos: i) ´e
desejado ter um desempenho igual ou superior ao dos algoritmos usados utilizando no su-
per learner; ii) ´e importante o uso de algoritmos de aprendizado de m´aquina presentes na
biblioteca MLlib [Meng et al., 2016] do Spark, pois obtˆem-se melhores aproveitamentos
da abstrac¸ ˜ao de dados do Spark e a biblioteca n˜ao possui suporte para o aprendizado in-
cremental. Assim, utiliza-se uma rede neural como o super modelo, pois suporta o apren-
dizado incremental. Para testar a efic´acia do super aprendizado incremental, utilizou-se
o super modelo em dois cen´arios diferentes. O cen´ario a) com cinco mineradores, e o
cen´ario b) com quinze mineradores. Esses cen´arios representam ambientes com poucos
mineradores e muitos mineradores, proporcionalmente ao total de dezesseis hosts. Em
cada cen´ario, executou-se o mesmo padr˜ao de 30 minutos de tr´afego de rede reprodu-
zido. Esse tempo foi discretizado em fatias de cinco minutos. A cada cinco minutos s˜ao
calculadas a precis˜ao, a sensibilidade, a especificidade e a precis˜ao do modelo.
(a) Precis˜ao, sensibilidade, especificidade e precis˜ao do super aprendizado incremental com pou-
cos mineradores durante o tempo.
(b) Precis˜ao, sensibilidade, especificidade e precis˜ao do super aprendizado incremental com mui-
tos mineradores durante o tempo.
Figura 7. Avaliac¸ ˜ao da t ´ecnica de super aprendizado incremental durante repro-
duzindo um tr ´afego de 30 min.
´E poss´ıvel verificar na Figura 7 que em algumas fatias de tempo o modelo se
comporta mal, mas melhora quando aprende com os novos dados. Ainda, em alguns
momentos, acontece o desvio de conceito como ´e poss´ıvel ver na fatia de tempo de 15
minutos da Figura 7(a) e nas fatias de tempo 5, 10 e 30 minutos da Figura 7(b), mas o
super modelo se adapta como ´e poss´ıvel identificar nos 20 e 25 minutos na Figura 7(a) e 15
e 20 minutos na Figura 7(b), pois ´e treinado incrementalmente com as melhores amostras
selecionadas de acordo com sua probabilidade de classificac¸ ˜ao e, ent˜ao, ´e garantido que o
super modelo aprender´a com dados que possuem alta probabilidade de estarem corretos.
7. Conclus˜ao
A tendˆencia da minerac¸ ˜ao de criptomoeda ´e crescer proporcionalmente ao valor
monet´ario das moedas digitais. O mecanismo MineCap foi desenvolvido para identificar
e bloquear os fluxos em linha de minerac¸ ˜ao de criptomoeda em uma rede definida por
software. Foi desenvolvido um prot´otipo do mecanismo para avaliac¸ ˜ao. O artigo propˆos a
t´ecnica de super aprendizado incremental que combina modelos candidatos como entrada
de um super modelo de aprendizado incremental. Os resultados das avaliac¸ ˜oes mostram
que os algoritmos de aprendizado de m´aquina mais adequados a serem modelos candi-
datos a fornecerem atributos ao aprendizado incremental foram a Floresta Aleat´oria e o
Gradient Boosted Tree. Ambos apresentaram boa capacidade de generalizac¸ ˜ao, com pre-
cis˜ao e especificidade de cerca de 100% e sensibilidade de 66,5%. A t´ecnica de super
aprendizado incremental obteve bons resultados e demonstrou um correto funcionamento
em relac¸ ˜ao a fatias de tempo com diferentes quantidades de mineradores na rede. A
t´ecnica aprende com novos dados, mantendo alto desempenho desde o in´ıcio da execuc¸ ˜ao
e, em alguns casos, melhorando com o tempo.
Referˆencias
Andreoni Lopez, M., Lobato, A. G. P. e Duarte, O. C. M. B. (2016). A performance
comparison of open-source stream processing platforms. Em 2016 IEEE Global Com-
munications Conference (GLOBECOM), p. 1–6.
Andreoni Lopez, M., Mattos, D. M. F., Duarte, O. C. M. B. e Pujolle, G. (2019). Toward
a monitoring and threat detection system based on stream processing as a virtual
network function for big data. Concurrency and Computation: Practice and Expe-
rience, 0(0):1–17.
Bannour, F., Souihi, S. e Mellouk, A. (2018). Distributed SDN control: Survey, taxonomy,
and challenges. IEEE Communications Surveys Tutorials, 20(1):333–354.
Carbone, P., Ewen, S., Haridi, S., Katsifodimos, A., Markl, V. e Tzoumas, K. (2015).
Apache Flink: Unified Stream and Batch Processing in a Single Engine. Data Engine-
ering, p. 28–38.
de Oliveira, M. T., Carrara, G. R., Fernandes, N. C., Albuquerque, C. V. N., Carrano,
R. C., de Medeiros, D. S. V. e Mattos, D. M. F. (2019). Towards a performance eva-
luation of private blockchain frameworks using a realistic workload. Em 2019 22nd
Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN),
Paris.
Fei-Fei, L., Fergus, R. e Perona, P. (2007). Learning generative visual models from few
training examples: An incremental bayesian approach tested on 101 object categories.
Computer Vision and Image Understanding, 106(1):59 – 70. Special issue on Genera-
tive Model Based Vision.
Gama, J., ˇZliobait˙e, I., Bifet, A., Pechenizkiy, M. e Bouchachia, A. (2014). A survey on
concept drift adaptation. ACM computing surveys (CSUR), 46(4):44.
Ingols, K. (2009). Modeling modern network attacks and countermeasures using attack
graphs. Computer Security Applications Conference.
Konoth, R. K., Vineti, E., Moonsamy, V., Lindorfer, M., Kruegel, C., Bos, H. e Vigna,
G. (2018). Minesweeper: An in-depth look into drive-by cryptocurrency mining and
its defense. Em Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, p. 1714–1730. ACM.
Luengo, J., Fern´andez, A., Garc´ıa, S. e Herrera, F. (2011). Addressing data complexity
for imbalanced data sets: analysis of smote-based oversampling and evolutionary un-
dersampling. Soft Computing, 15(10):1909–1936.
Mattos, D. M. F., Duarte, O. C. M. B. e Pujolle, G. (2016). Reverse update: A consistent
policy update scheme for software-defined networking. IEEE Communications Letters,
20(5):886–889.
McAfee, A., Brynjolfsson, E., Davenport, T. H., Patil, D. e Barton, D. (2012). Big data:
the management revolution. Harvard business review, 90(10):60–68.
Medeiros, D. S. V., Cunha Neto, H. N., Andreoni Lopez, M., Magalh˜aes, L. C. S., Silva,
E. F., Vieira, A. B., Fernandes, N. C. e Mattos, D. M. F. (2019). An´alise de dados em
redes sem fio de grande porte: Processamento em fluxo em tempo real, tendˆencias
e desafios. Minicursos do Simp´osio Brasileiro de Redes de Computadores-SBRC,
2019:142–195.
Meng, X., Bradley, J., Yavuz, B., Sparks, E., Venkataraman, S., Liu, D., Freeman, J., Tsai,
D., Amde, M., Owen, S. et al. (2016). Mllib: Machine learning in apache spark. The
Journal of Machine Learning Research, 17(1):1235–1241.
Open Networking Foundation (2012). OpenFlow Switch Specification Version 1.3.0 (Wire
Protocol 0x04). The OpenFlow Consortium.
Pietraszek, T. e Tanner, A. (2005). Data mining and machine learning—towards reducing
false positives in intrusion detection. Information security technical report, 10(3):169–
183.
Polikar, R., Upda, L., Upda, S. S. e Honavar, V. (2001). Learn++: an incremental learning
algorithm for supervised neural networks. IEEE Transactions on Systems, Man, and
Cybernetics, Part C (Applications and Reviews), 31(4):497–508.
Porras, P. A. e Valdes, A. (2001). Network surveillance. US Patent 6,321,338.
Tahir, R., Huzaifa, M., Das, A., Ahmad, M., Gunter, C., Zaffar, F., Caesar, M. e Borisov,
N. (2017). Mining on someone else’s dime: Mitigating covert mining operations in
clouds and enterprises. Em International Symposium on Research in Attacks, Intrusi-
ons, and Defenses, p. 287–310. Springer.
Van der Laan, M. J., Polley, E. C. e Hubbard, A. E. (2007). Super learner. Statistical
applications in genetics and molecular biology, 6(1).
Wang, S., Minku, L. L., Ghezzi, D., Caltabiano, D., Tino, P. e Yao, X. (2013). Concept
drift detection for online class imbalance learning. Em The 2013 Int. Joint Conference
on Neural Networks (IJCNN), p. 1–10.