Um Mecanismo de Aprendizado Incremental para
DeteccÂ¸ Ëœao e Bloqueio de MineracÂ¸ Ëœao de Criptomoedas
em Redes Definidas por Software
Helio N. C. Neto1, Martin Andreoni Lopez2,
Natalia C. Fernandes1, Diogo M. F. Mattos1
1MÂ´Ä±diaCom - PPGEET/TET/UFF
Universidade Federal Fluminense - UFF
2Samsung Research Institute - Brasil
Resumo. A mineracÂ¸ Ëœao nËœao autorizada de criptomoedas implica o uso de valio-
sos recursos de computacÂ¸ Ëœao e o alto consumo de energia. Este artigo propËœoe o
mecanismo MineCap, um mecanismo dinË†amico e em linha para detectar e blo-
quear fluxos de mineracÂ¸ Ëœao nËœao autorizada de criptomoedas, usando o apren-
dizado de mÂ´aquina em redes definidas por software. O MineCap desenvolve a
tÂ´ecnica de super aprendizado incremental, uma variante do super learner apli-
cada ao aprendizado incremental. O super aprendizado incremental proporci-
ona ao MineCap precisËœao para classificar os fluxos de mineracÂ¸ Ëœao ao passo que
o mecanismo aprende com dados recebidos. Os resultados revelam que o me-
canismo alcancÂ¸a 98% de acurÂ´acia, 99% de precisËœao, 97% de sensibilidade e
99,9% de especificidade e evita problemas relacionados ao desvio de conceito.
Abstract. Covert mining of cryptocurrency implies the use of valuable compu-
ting resources and high energy consumption. In this paper, we propose Mine-
Cap, a dynamic online mechanism for detecting and blocking covert crypto-
currency mining flows, using machine learning on software-defined networking.
MineCap uses a novel technique called super incremental learning, a variant
of the super learner with incremental learning. Hence, we design an accurate
mechanism to classify mining flows that learn with incoming data with an ave-
rage of 98% accuracy, 99% accuracy, 97% sensitivity and 99.9% specificity and
avoid concept drift-related issues.
1. IntroducÂ¸ Ëœao
As redes corporativas sËœao alvos constantes de ataques [Ingols, 2009,
Porras e Valdes, 2001] e a mineracÂ¸ Ëœao nËœao autorizada de criptomoedas Â´e uma nova
ameacÂ¸a a essas redes. Tal atividade prejudica o ambiente corporativo, devido ao consumo
excessivo de recursos de computacÂ¸ Ëœao e energia, embora nem sempre a mineracÂ¸ Ëœao seja ex-
plicitamente proibida na rede [de Oliveira et al., 2019, Tahir et al., 2017]. Uma variacÂ¸ Ëœao
dessa ameacÂ¸a ocorre em aplicativos que mineram criptomoedas sem o conhecimento ou
consentimento do usuÂ´ario, como malwares ou injecÂ¸ Ëœao de scripts em pÂ´aginas Web.
Este trabalho foi realizado com recursos da CNPq, CAPES, FAPERJ, RNP e TAESA.
Em ambientes corporativos, a ameacÂ¸a da mineracÂ¸ Ëœao de criptomoedas pode ser
interna ou externa. A ameacÂ¸a interna consiste em usuÂ´arios internos que usam conscien-
temente o poder computacional da infraestrutura da empresa para realizar a mineracÂ¸ Ëœao
para fins particulares. Por outro lado, as ameacÂ¸as externas consistem em entidades que
exploram vulnerabilidades da infraestrutura para executar cÂ´odigos de mineracÂ¸ Ëœao de crip-
tomoeda. Portanto, identificar o trÂ´afego de mineracÂ¸ Ëœao torna-se essencial para garantir o
uso eficiente e seguro dos recursos computacionais da empresa. Contudo, esta Â´e uma ta-
refa complexa, jÂ´a que as caracterÂ´Ä±sticas de fluxo de mineracÂ¸ Ëœao geralmente sËœao semelhantes
`as do trÂ´afego criptografado de navegacÂ¸ Ëœao Web, tornando-se simples ocultar o trÂ´afego mal-
intencionado. Assim, hÂ´a uma clara necessidade de ferramentas para detectar e impedir o
trÂ´afego nËœao autorizado de mineracÂ¸ Ëœao em ambientes em que as polÂ´Ä±ticas de rede proÂ´Ä±bem a
atividade de mineracÂ¸ Ëœao de criptomoeda.
Este artigo propËœoe o MineCap, um mecanismo que utiliza algoritmos de apren-
dizado de mÂ´aquina para realizar a classificacÂ¸ Ëœao em linha do trÂ´afego de mineracÂ¸ Ëœao de
criptomoeda em redes definidas por software (Software-Defined Networks - SDN). Nas
redes definidas por software, o plano de controle e encaminhamento sËœao desacoplados
e introduz-se uma nova entidade, o controlador SDN [Bannour et al., 2018], responsÂ´avel
por executar todas as acÂ¸ Ëœoes de controle na rede. O controlador SDN permite que a rede se
torne programÂ´avel e que os aplicativos de controle interajam com os elementos de rede,
como os comutadores, de forma logicamente centralizada [Mattos et al., 2016]. Assim, as
SDN permitem um bloqueio efetivo dos fluxos de mineracÂ¸ Ëœao, por meio de uma interacÂ¸ Ëœao
direta entre o MineCap e o controlador da rede. Assim, o MineCap consegue bloquear
dinamicamente os fluxos de mineracÂ¸ Ëœao que sËœao reconhecidos com o algoritmo de apren-
dizado de mÂ´aquina.
O artigo propËœoe ainda a tÂ´ecnica de super aprendizado incremental que Â´e uma va-
riante da tÂ´ecnica super learner aplicada ao aprendizado incremental. A ideia chave da
proposta Â´e realizar o aprendizado incremental sobre as classificacÂ¸ Ëœoes providas por um
agregado de classificadores de menor acurÂ´acia. Para tanto, avaliou-se o desempenho de
quatro classificadores: Floresta AleatÂ´oria, Naive Bayes, RegressËœao LogÂ´Ä±stica e Gradient
Boosted Tree. Os dois algoritmos com melhor desempenho foram usados na tÂ´ecnica de
super aprendizado incremental, com o objetivo de aumentar a acurÂ´acia da deteccÂ¸ Ëœao. O su-
per aprendizado incremental utiliza a tÂ´ecnica de super learner [Van der Laan et al., 2007]
combinada com o aprendizado incremental, de forma que o super modelo aprende com
novos dados sem o esquecimento catastrÂ´ofico e consequente descarte do classificador.
O MineCap executa sobre o arcaboucÂ¸o de processamento Apache Spark, atravÂ´es
das bibliotecas Spark Streaming, que manipula o fluxo de dados, e a MLlib, que for-
nece os algoritmos de aprendizado de mÂ´aquina na classificacÂ¸ Ëœao em linha. A avaliacÂ¸ Ëœao
do protÂ´otipo do MineCap foi realizada em uma rede emulada pela plataforma Mininet,
utilizando o controlador SDN Ryu com a API REST habilitada para instalar regras de
bloqueio dos fluxos. Os resultados das avaliacÂ¸ Ëœoes mostram que o MineCap tem baixo
consumo dos recursos de rede e computacional enquanto analisa todo o trÂ´afego de rede.
Trabalhos relacionados se concentram em identificar o trÂ´afego de mineracÂ¸ Ëœao usando o
aprendizado de mÂ´aquina [Tahir et al., 2017, Konoth et al., 2018]. Contudo, eles protegem
DisponÂ´Ä±vel em https://github.com/mininet/mininet.
DisponÂ´Ä±vel em https://osrg.github.io/ryu/.
um Â´unico host, enquanto o MineCap protege toda a rede e, por ser baseado no paradigma
SDN, permite a definicÂ¸ Ëœao de polÂ´Ä±ticas de bloqueio em alto nÂ´Ä±vel [Mattos et al., 2016] di-
retamente nos elementos de rede mais prÂ´oximos `as fontes de trÂ´afego.
O restante do artigo estÂ´a organizado da seguinte forma. A SecÂ¸ Ëœao 2 discute os tra-
balhos relacionados. A SecÂ¸ Ëœao 3 apresenta as tÂ´ecnicas para o processamento de grandes
massas de dados, e a SecÂ¸ Ëœao 4 propËœoe a tÂ´ecnica de super aprendizado incremental. O me-
canismo MineCap Â´e definido na SecÂ¸ Ëœao 5 e a SecÂ¸ Ëœao 6 apresenta os resultados da avaliacÂ¸ Ëœao.
Por fim, a SecÂ¸ Ëœao 7 conclui o artigo.
2. Trabalhos Relacionados
Tahir et al. propËœoem a ferramenta MineGuard para detectar em tempo real o com-
portamento de processos de mineracÂ¸ Ëœao em mÂ´aquinas virtuais [Tahir et al., 2017]. Mi-
neGuard utiliza contadores de desempenho de hardware (Hardware Performance Coun-
ters - HPCs), um conjunto de registradores integrados em processadores modernos, para
armazenar as contagens de atividades relacionadas ao hardware. Os contadores permi-
tem rastrear com precisËœao as operacÂ¸ Ëœoes de mineracÂ¸ Ëœao de baixo nÂ´Ä±vel ou eventos dentro da
CPU e GPU com sobrecarga mÂ´Ä±nima, dando `a ferramenta a capacidade de detectar com
precisËœao, em tempo real, se uma mÂ´aquina virtual estÂ´a tentando minerar criptomoedas.
A MineGuard baseia-se na observacÂ¸ Ëœao de que, para minerar criptomoedas, Â´e necessÂ´ario
executar repetidamente o algoritmo de Proof-of-Work (PoW).
O MineSweeper [Konoth et al., 2018] usa a URL do sÂ´Ä±tio Web como entrada para
verificar se hÂ´a algum software de mineracÂ¸ Ëœao de criptomoedas oculto. O MineSweeper usa
uma mÂ´etrica para identificar funcÂ¸ Ëœoes criptogrÂ´aficas, medindo o nÂ´umero de operacÂ¸ Ëœoes exe-
cutadas por um aplicativo. Os autores analisam o algoritmo CryptoNight e suas variantes,
mas argumentam que adicionar outros algoritmos Â´e uma tarefa trivial. O MineSweeper
concentra-se na mineracÂ¸ Ëœao embarcada em pÂ´aginas Web e seu principal objetivo Â´e identi-
ficar um novo ataque, o drive-by mining, no qual um sÂ´Ä±tio infectado executa secretamente
cÂ´odigo JavaScript ou um mÂ´odulo WebAssembly no navegador do usuÂ´ario para minerar
criptomoedas sem o seu consentimento. Diferentemente do MineSweeper, o MineCap
concentra-se em detectar e bloquear trÂ´afego de mineracÂ¸ Ëœao de criptomoeda na rede.
Andreoni et al. propËœoem a CATRACA, uma ferramenta em linha para a deteccÂ¸ Ëœao
e prevencÂ¸ Ëœao de ataques em uma funcÂ¸ Ëœao virtual de rede [Andreoni Lopez et al., 2019]. As-
sim como o MineCap, a ferramenta proposta utiliza um sistema de processamento de fluxo
para as grandes massas de dados (Big Data), o Apache Spark, fornecendo um servicÂ¸o de
deteccÂ¸ Ëœao de ameacÂ¸as em tempo real. A ferramenta CATRACA opera em dois modos:
online ou offline. O processo de deteccÂ¸ Ëœao inclui algoritmos de selecÂ¸ Ëœao de caracterÂ´Ä±sticas e
aprendizado de mÂ´aquina para discriminar trÂ´afego normal, negacÂ¸ Ëœao de servicÂ¸o (Denial of
Service - DoS) e varredura de portas. Em uma deteccÂ¸ Ëœao de ameacÂ¸a, o sistema pode reagir
prontamente e criar regras de bloqueio em um firewall. O MineCap usa uma abordagem
semelhante, mas integra a capacidade de bloqueio de fluxos utilizando uma rede definida
por software sem a necessidade de usar outras ferramentas.
3. Processamento de Grandes Massas de Dados
As tÂ´ecnicas tradicionais de banco de dados nËœao permitem o processamento de
dados estruturados e nËœao estruturados em grandes volume, variedade e velocidade.
Na maioria dos ambientes corporativos, o volume e a velocidade de geracÂ¸ Ëœao dos
dados excede a taxa de transferË†encia dos gerenciadores de banco de dados relacio-
nais [McAfee et al., 2012]. Para a extracÂ¸ Ëœao de conhecimentos Â´uteis dos metadados para
aumentar a receita, conquistar ou reter clientes e melhorar as operacÂ¸ Ëœoes, as empresas co-
letam dados de vÂ´arias fontes, incluindo e-mails, dispositivos mÂ´oveis, aplicativos, bancos
de dados, servidores e mÂ´Ä±dias diversas. Os dados obtidos devem ser extraÂ´Ä±dos, forma-
tados, manipulados, armazenados e analisados. A anÂ´alise das grandes massas de dados
pode ocorrer em lote ou em fluxo [Medeiros et al., 2019]. O processamento em lote Â´e a
forma mais tradicional de processamento de grandes massas de dados. Normalmente, os
dados sËœao armazenados para serem processados posteriormente por meio de realizacÂ¸ Ëœao
de consultas [Carbone et al., 2015]. No processamento por lotes, Â´e comum usar Online
Analytical Processing (OLAP), sistemas capazes de analisar grandes volumes de dados de
forma rÂ´apida e eficiente, tÂ´ecnicas de mineracÂ¸ Ëœao de dados e processamento paralelo com
ferramentas como o Apache Hadoop. O processamento em fluxo Â´e comumente usado
por aplicativos que exigem baixo tempo de resposta para combinar a captura de dados em
fluxo (in-stream) com o uso de tÂ´ecnicas de inferË†encia e correlacÂ¸ Ëœao [Medeiros et al., 2019].
No MineCap, todos os pacotes na saÂ´Ä±da da rede sËœao processados, a fim de iden-
tificar os fluxos de mineracÂ¸ Ëœao de criptomoeda. O MineCap utiliza o processamento de
dados em fluxo devido ao grande nÂ´umero de pacotes na saÂ´Ä±da da rede, que combina ca-
racterÂ´Ä±sticas de alto volume de dados e alta velocidade de geracÂ¸ Ëœao. Existem ferramentas
de processamento distribuÂ´Ä±do em fluxo de cÂ´odigo aberto, como a Apache Flink, a Apa-
che Storm e a Spark Streaming, que funcionam em aglomerados computacionais, mas
a Â´unica que garante a entrega de 100% das mensagens em cenÂ´arios de falha Â´e a Spark
Streaming [Andreoni Lopez et al., 2019]. A Spark Streaming permite a programacÂ¸ Ëœao de
aplicacÂ¸ Ëœoes nas linguagens Scala, Java, Python e R. Por essas vantagens o MineCap utiliza
o Spark Streaming para processamento em fluxo de grandes massas de dados.
4. Proposta de Super Aprendizado Incremental
A tÂ´ecnica de super aprendizado incremental, proposta neste artigo, Â´e a
combinacÂ¸ Ëœao das tÂ´ecnicas super learner [Van der Laan et al., 2007] e aprendizado incre-
mental [Fei-Fei et al., 2007]. Na proposta, algoritmos de aprendizado de mÂ´aquina sËœao
usados como modelos candidatos que alimentam o super modelo. Os modelos candidatos
sËœao treinados e realizam as previsËœoes que sËœao entregues como entrada para o super modelo.
EntËœao, posteriormente o super modelo Â´e treinado parcialmente utilizando o aprendizado
incremental.
A tÂ´ecnica do super learner consiste em treinar um modelo no qual as amostras
de entrada sËœao a saÂ´Ä±da de outros modelos, semelhante a um sistema hierÂ´arquico. Van der
Laan et al. [Van der Laan et al., 2007] foram os primeiros a usar esta tÂ´ecnica, utilizando a
validacÂ¸ Ëœao cruzada, para propor um novo mÂ´etodo de previsËœao criado a partir da combinacÂ¸ Ëœao
ponderada de diversos modelos candidatos. O primeiro passo do super learner proposto
por van der Laan et al. Â´e treinar n modelos utilizando todo o conjunto de dados. No
segundo passo, Â´e feita a divisËœao do conjunto de dados original em V blocos e, depois, cada
modelo candidato Â´e treinado com um desses blocos, chamados de blocos de validacÂ¸ Ëœao.
Logo, Â´e feita a previsËœao dos blocos de dados de validacÂ¸ Ëœao correspondente a cada bloco
de treinamento. Na sequË†encia, sËœao feitos ajustes do resultado observado dos resultados
previstos de cada modelo candidato e, por fim, Â´e feito o treinamento do super modelo
com os resultados previstos pelos modelos candidatos. Pode-se avaliar o super modelo
comparando com as previsËœoes de cada modelo candidato, feito no primeiro passo, com
a saÂ´Ä±da do super modelo. A Figura 1 mostra o diagrama da tÂ´ecnica original do super
learner.Conjunto
de dados
1
2
...
V
1
2
...
V
1
2
...
V
RF GBT ... SVM
RF GBT ... SVM
RF GBT ... SVM
RF GBT ... SVM
1 1 ... 1
2 2 ... 2
... ... ... ...
V V ... V
Modelos Candidatos Prev.
Y
1
2
...
V
Super
Modelo
SeleÃ§Ã£o e
ajuste
2. Dividir os
dados em V
blocos
3. Treinamento de
todos os modelos
candidatos
4. Prever cada amostra do
conjunto de validaÃ§Ã£o com base
em seu conjunto de treinamento
correspondente 5. Ajuste e
seleÃ§Ã£o para
todos os
resultados
observados dos
modelos
candidatos
RF GBT ... SVM
6. Avaliar o super modelo
combinando previsÃµes de
cada modelo candidato
1. Treinar cada modelo candidato com
o conjunto de dados inteiro
Figura 1. Diagrama de fluxo com as etapas da t Â´ecnica Super Learner. Adaptado
de [Van der Laan et al., 2007]
A ideia principal do aprendizado incremental, tambÂ´em conhecido como aprendi-
zado em linha, Â´e limitar a perda de informacÂ¸ Ëœao para o uso de dados finitos em relacÂ¸ Ëœao
a modelos com dados infinitos. Para tanto, a perda de informacÂ¸ Ëœao Â´e feita em funcÂ¸ Ëœao
do nÂ´umero de amostras em cada estÂ´agio de aprendizado e, assim, o nÂ´umero de amostras
utilizadas em cada um dos estÂ´agios Â´e mÂ´Ä±nimo e mantido livre do limiar de perdas preserva-
das [Medeiros et al., 2019]. A resolucÂ¸ Ëœao do problema de quanta informacÂ¸ Ëœao Â´e perdida di-
minuindo o nÂ´umero de amostras Â´e dada usando o limite de Hoeffding [Gama et al., 2014].
Considerando uma variÂ´avel aleatÂ´oria real x, cujo valor estÂ´a contido no intervalo R,
presume-se que n observacÂ¸ Ëœoes independentes da variÂ´avel sËœao feitas e a mÂ´edia Â¯r Â´e compu-
tada. O limite de Hoeffding garante com probabilidade 1 âˆ’ Î´ que a verdadeira mÂ´edia da
variÂ´avel Â´e dada por pelo menos Â¯x âˆ’ , em que
 =
âˆš
R2ln(1/Î´)
2n . (1)
O limite de Hoeffding Â´e independente da distribuicÂ¸ Ëœao que gera a variÂ´avel x. A par-
tir desse resultado, os algoritmos de aprendizado de mÂ´aquina para treinamento de dados
em fluxos sËœao desenvolvidos. No entanto, assume-se que os valores gerados pela variÂ´avel
x vË†em de um processo estocÂ´astico constante. Nos casos em que hÂ´a uma mudancÂ¸a no
processo que gera a variÂ´avel usada no treinamento de mÂ´etodos de aprendizado em fluxo,
Â´e dito que ocorre uma mudancÂ¸a de conceito (concept drift) e, portanto, faz-se necessÂ´ario
um novo treinamento do mÂ´etodo de aprendizado [Wang et al., 2013].
Abordagens tÂ´Ä±picas para o aprendizado de novas informacÂ¸ Ëœoes envolvem manter o
comportamento estocÂ´astico dos dados ou realizar o descarte do classificador existente e
re-treinar com os dados acumulados atÂ´e o momento. Nas abordagens que consideram o
fim da estabilidade estatÂ´Ä±stica dos dados, o processo deixa de ser estocÂ´astico, resultando na
perda de todas as informacÂ¸ Ëœoes previamente adquiridas, o que Â´e conhecido como esqueci-
mento catastrÂ´ofico. Assim, Polikar et al. [Polikar et al., 2001] definem que os algoritmos
de aprendizado incremental devem satisfazer os requisitos a seguir ao obter informacÂ¸ Ëœoes
adicionais sobre novos dados: i) nËœao requerer acesso aos dados originais usados para trei-
nar o classificador existente; ii) preservar o conhecimento previamente adquirido, isto Â´e, o
classificador nËœao deve sofrer o esquecimento catastrÂ´ofico; e iii) ter capacidade de acomo-
dar novas classes que podem ser introduzidas por novos dados. Assim, os classificadores
que adotam o aprendizado incremental nËœao requerem o treinamento total do classificador
no caso de uma mudancÂ¸a no comportamento do fluxo de dados.
Na proposta super aprendizado incremental Â´e feita uma mesclagem da variante do
super learner e, para gerar o super modelo, sËœao usadas redes neurais com aprendizado
incremental para o aprendizado em linha. Na variante do super learner, Â´e feita a divisËœao
do conjunto de dados em um conjunto de treinamento e um conjunto de teste. Em se-
guida, utiliza-se o conjunto de treinamento para treinar os modelos candidatos. No caso
do MineCap, foram utilizados os algoritmos floresta aleatÂ´oria e Gradient Boosted Tree,
treinando ambos com o mesmo conjunto de dados. Cada amostra do conjunto de dados
de entrada para o super modelo tem como atributos as probabilidades da amostra ser da
classe fluxo normal, classificado como 0, ou fluxo de mineracÂ¸ Ëœao, classificado como 1,
geradas a partir das previsËœoes feitas dos modelos candidatos aplicados sobre o conjunto
de dados de teste.
Os dois modelos candidatos geram a lista W = (w1, w2, w3, w4, y) em que w1
Â´e a probabilidade do primeiro modelo candidato retornar como saÂ´Ä±da a classe trÂ´afego
normal, w2 Â´e a probabilidade do primeiro modelo candidato retornar como saÂ´Ä±da a classe
de trafego de mineracÂ¸ Ëœao, w3 e w4 tË†em a mesma representacÂ¸ Ëœao para o segundo modelo
candidato. Finalmente, y Â´e a saÂ´Ä±da desejada de cada amostra, ou seja a classe alvo dessa
amostra. A lista W gerada pelos modelos candidatos Â´e passada como entrada para treinar
a rede neural incremental utilizando o algoritmo de Perceptron Multi-Camadas (Multi-
Layer Perceptron - MLP). A Figura 2 mostra o diagrama da tÂ´ecnica de super aprendizado
incremental desenvolvida no MineCap.Conjunto
de dados
Treino
Teste
DivisÃ£o
Gradient
Booster
Tree
Probabilidade
Verdadeiro
Probabilidade
Falso
Rede
Neural
SaÃ­da
(0,1)
Incremental
treinamento
parcial
Floresta
AleatÃ³ria
Figura 2. Diagrama de fluxo da t Â´ecnica de super aprendizado incremental.
Quando o MineCap recebe novos dados, os envia aos modelos candidatos para
classificacÂ¸ Ëœao e, em seguida, armazena as saÂ´Ä±das em um arquivo chamado incremental.
Somente depois, envia os dados como entrada para a rede neural para realizar a previsËœao.
A rede neural classifica cada amostra recebida em linha e anexa a saÂ´Ä±da prevista `a entrada
da amostra no arquivo incremental. Cada entrada do arquivo incremental possui a lista
W = (w1, w2, w3, w4, y), em que todos os w sËœao a saÂ´Ä±da dos modelos candidatos, floresta
aleatÂ´oria e Gradient Boosted Tree e, no caso do MineCap, y Â´e a saÂ´Ä±da do super modelo.
Quando um nÂ´umero k suficiente de amostras Â´e acumulado, o processo incremental veri-
fica cada amostra e coleta apenas as amostras que possuem maior probabilidade de serem
fluxo de mineracÂ¸ Ëœao e menor probabilidade de serem fluxo normal ou o inverso para depois
realizar a aprendizagem parcial. A quantidade k de amostras acumuladas para o treina-
mento parcial Â´e proporcional ao tempo para a aprendizagem com novos dados. Quanto
maior a quantidade, maior o tempo para a aprendizagem. No protÂ´otipo do mecanismo
propostos, Â´e usado o valor de k = 50, pois verificou-se que com 50 amostras hÂ´a o com-
promisso de executar o treinamento parcial do super modelo entre 1 e 2 minutos, no caso
de ocorrË†encia constante de mineracÂ¸ Ëœao na rede.
5. Mecanismo MineCap para DeteccÂ¸ Ëœao e Bloqueio de MineracÂ¸ Ëœao
O mecanismo MineCap Â´e executado em uma estacÂ¸ Ëœao (host) ou em um aglome-
rado computacional (cluster) separado do controlador de rede. A execucÂ¸ Ëœao do MineCap
em uma estacÂ¸ Ëœao separada do controlador de rede evita a sobrecarga no controlador. O
controlador da rede redireciona todos os pacotes de saÂ´Ä±da da rede local para o MineCap,
aplicando a tÂ´ecnica de espelhamento de porta no gateway de rede. Conforme mostrado
na Figura 3, o mecanismo proposto apresenta uma arquitetura de trË†es camadas: captura,
processamento e bloqueio.Camada de Captura
Pacote Coleta
de pacotes
AbstraÃ§Ã£o
de Fluxo
Produtor de
mensagens
libpcap flowtbag
Camada de Processamento
Dataset
Modelo
Treina Consumidor
de Fluxo
ReduÃ§Ã£o de
CarcaterÃ­sticasClassificaÃ§Ã£o
Camada de Bloqueio
API
REST Controlador
Rede
Instala os fluxos
de bloqueio
Figura 3. A arquitetura da ferramenta MineCap. Os pacotes chegam na interface
de rede, s Ëœao abstraÂ´Ä±dos em fluxos que, por sua vez, s Ëœao publicados no servicÂ¸ o
de mensagens Apache Kafka. O Spark Streaming consome a mensagem, pr Â´e-
processa os dados e envia para o modelo treinado para classificacÂ¸ Ëœao.
A camada de captura tem como objetivo capturar os dados e preparÂ´a-los para a
camada superior. O primeiro passo Â´e capturar os pacotes de rede atravÂ´es da execucÂ¸ Ëœao da
biblioteca libpcap. Esses pacotes capturados sËœao resumidos em fluxos de rede. Define-
se fluxo de rede como a sequË†encia de pacotes que possuem o mesmo IP de origem, IP
de destino, porta de origem, porta de destino e protocolo de transporte. Foi desenvolvida
uma aplicacÂ¸ Ëœao na linguagem Python, baseada na aplicacÂ¸ Ëœao flowtbag, para realizar a
DisponÂ´Ä±vel em https://github.com/DanielArndt/flowtbag.
abstracÂ¸ Ëœao de pacotes em fluxos. Os fluxos sËœao publicados no servicÂ¸o de mensagens Apa-
che Kafka, um sistema de publicacÂ¸ Ëœao e assinatura (publisher/subscriber) que garante o
armazenamento e a entrega confiÂ´avel das mensagens.
A camada de processamento Â´e responsÂ´avel por consumir, processar e classi-
ficar os fluxos da rede que o Apache Kafka fornece como dados em fluxo. O me-
canismo MineCap adota o Apache Spark como sua plataforma de processamento de
fluxo em linha. O Apache Spark Streaming apresenta melhor desempenho em relacÂ¸ Ëœao
`a tolerË†ancia a falhas quando comparado a outras plataformas de processamento de
fluxo [Andreoni Lopez et al., 2016], adicionando robustez e resiliË†encia ao processamento.
O MineCap evita assim a perda de informacÂ¸ Ëœao. O Spark consome o conteÂ´udo do
Kafka com a biblioteca Spark Streaming. O Apache Kafka Â´e um intermediÂ´ario de
mensagens que entrega mensagens aos processos assinantes, mas nËœao suporta execucÂ¸ Ëœao
de algoritmos mais complexos, como o aprendizado de mÂ´aquina. O MineCap incor-
pora o algoritmo de AnÂ´alise de Componente Principal (Principal Component Analysis
- PCA) [Andreoni Lopez et al., 2016], que reduz um grande conjunto de atributos a um
conjunto menor de caracterÂ´Ä±sticas artificiais que ainda contÂ´em a maior parte da quantidade
de informacÂ¸ Ëœao do conjunto original. A MLlib Â´e a biblioteca de aprendizado de mÂ´aquina
escalÂ´avel do Spark que consiste em algoritmos e utilitÂ´arios comuns para o aprendizado
de mÂ´aquina. Neste trabalho, sËœao avaliados quatro algoritmos de aprendizado de mÂ´aquina:
Floresta AleatÂ´oria, Gradient Boosted Tree, Naive Bayes e RegressËœao LogÂ´Ä±stica.
A camada de bloqueio recebe a saÂ´Ä±da do classificador e instala uma regra
de bloqueio para fluxos rotulados como mineracÂ¸ Ëœao de criptomoeda. O OpenFlow
1.3 [Open Networking Foundation, 2012] Â´e o protocolo de rede definida por software uti-
lizado pelo MineCap. O Ryu Â´e baseado em Python e foi escolhido como o controlador
SDN para o protÂ´otipo desenvolvido, devido `a sua facilidade de implantacÂ¸ Ëœao e baixo tempo
para o desenvolvimento de aplicacÂ¸ Ëœoes. No entanto, qualquer outro controlador poderia
ser utilizado. A integracÂ¸ Ëœao entre o MineCap e o controlador Â´e agnÂ´ostica, o que possibi-
lita a integracÂ¸ Ëœao ou atualizacÂ¸ Ëœao de outros controladores SDN. O MineCap se comunica
com o controlador por meio de um interface de TransferË†encia de Estado Representacio-
nal(Representational State Transfer - REST) executada no controlador, que recebe uma
mensagem criptografada, na qual os fluxos de mineracÂ¸ Ëœao sËœao identificados e, entËœao, as re-
gras de bloqueio sËœao instaladas na rede. Essa Â´e a camada de integracÂ¸ Ëœao com a rede, para o
MineCap funcionar com as redes tradicionais basta modificar essa camada. Por exemplo,
pode ser substituÂ´Ä±da a chamada REST para o controlador SDN por um comando via ssh
para o bloqueio no firewall da rede.
6. AvaliacÂ¸ Ëœao do ProtÂ´otipo
Um protÂ´otipo do MineCap foi desenvolvido para avaliar a proposta. Os experi-
mentos foram realizados em um computador equipado com um processador Intel Core i7
7700 a 3,60 GHz, com oito nÂ´ucleos e 16 GB de RAM. A avaliacÂ¸ Ëœao foi realizada em uma
rede emulada, usando a plataforma de emulacÂ¸ Ëœao Mininet, com 16 hosts em uma topolo-
gia em Â´arvore personalizada, usando sete comutadores executando o protocolo OpenFlow
1.3 [Open Networking Foundation, 2012].
Na primeira avaliacÂ¸ Ëœao, entre os 16 hosts do ambiente, quatro deles executavam
DisponÂ´Ä±vel em https://osrg.github.io/ryu/.
aplicativos de mineracÂ¸ Ëœao de criptomoedas em linha de comando populares para mineracÂ¸ Ëœao
utilizando CPU e o restante estava repetindo um trÂ´afego de 30 minutos contido em um ar-
quivo de captura real, gerado por usuÂ´arios reais, de trÂ´afego de rede, usando tcpreplay.
Nessa etapa, Â´e avaliada a diferencÂ¸a entre os dois melhores modelos dentre os demais.
O trÂ´afego contido no arquivo de captura foi previamente classificado para ser comparado
com a saÂ´Ä±da de modelos de aprendizado de mÂ´aquina, para ser utilizado como linha de base.
Utilizou-se pools de mineracÂ¸ Ëœao com portas TCP conhecidas, para posterior classificacÂ¸ Ëœao
manual do conjunto de dados utilizado para treinar os modelos candidatos. Nos testes
de avaliacÂ¸ Ëœao, utilizaram-se pools diferentes das utilizadas no conjunto de dados de trei-
namento. O gateway de rede teve sua porta espelhada para o MineCap para garantir que
todo o trÂ´afego de rede passasse pela classificacÂ¸ Ëœao. O MineCap instala um fluxo, com
duracÂ¸ Ëœao de 5 minutos, no controlador SDN bloqueando todo o trÂ´afego classificado como
mineracÂ¸ Ëœao de criptomoeda e, portanto, os pacotes sËœao rejeitados diretamente no comuta-
dor OpenFlow da rede. O conjunto de dados utilizado para treinar e testar os modelos
foi criado em laboratÂ´orio, em um ambiente estilo â€œmundo fechadoâ€, em que o trÂ´afego foi
capturado em um ambiente controlado com um comutador, computadores atuando como
mineradores e outros utilizando diferentes perfis de navegacÂ¸ Ëœao como streaming de vÂ´Ä±deo,
descarga de arquivos e acesso a sÂ´Ä±tios Web. Os aplicativos de mineracÂ¸ Ëœao utilizados foram
o MinerGate e o GuiMiner, executando em mÂ´aquinas com sistema operacional Windows.
Antes de particionar o conjunto de dados em conjunto de treinamento e teste, o conjunto
de dados foi embaralhado para evitar qualquer elemento de viÂ´es ou padrËœoes nos conjuntos
de dados. Assim, com o conjunto de dados embaralhado, a qualidade e o desempenho
dos modelos sËœao melhoradas. O conjunto de dados passou pelo processo de oversam-
pling, pois a tÂ´ecnica Â´e frequentemente usada para balancear a quantidade de classes do
conjunto de dados [Luengo et al., 2011].
A Figura 4 mostra a curva de caracterÂ´Ä±sticas operacionais do receptor (Receiver
Operating Characteristic - ROC), a precisËœao, a sensibilidade e a especificidade de cada
algoritmo de classificacÂ¸ Ëœao testado. A curva ROC mede e especifica o desempenho dos
algoritmos testados atravÂ´es do relacionamento entre verdadeiros positivos e falsos positi-
vos em diversos pontos de corte na probabilidade de uma amostra pertencer a uma classe.
Â´E um mÂ´etodo grÂ´afico robusto e direto que permite estudar a variacÂ¸ Ëœao da sensibilidade e
especificidade para diferentes valores de corte.
Os algoritmos de aprendizado de mÂ´aquina Floresta AleatÂ´oria e Gradient Boos-
ted Tree superaram os outros algoritmos, com boa precisËœao e sensibilidade. RegressËœao
LogÂ´Ä±stica e Naive Bayes tiveram 0 % de precisËœao e sensibilidade, por isso ficaram sem
barras na Figura 4(b). A RegressËœao LogÂ´Ä±stica classificou cada fluxo como fluxo normal e
o Naive Bayes classificou alguns fluxos como normal e outros como fluxos de mineracÂ¸ Ëœao
de criptomoedas, assim, eles nËœao serËœao utilizados como modelos candidatos do super
aprendizado incremental.
AlÂ´em dos testes de avaliacÂ¸ Ëœao de aprendizado de mÂ´aquina, sËœao apresentados outros
O trÂ´afego de mineracÂ¸ Ëœao usado para treinar os algoritmos de aprendizado de mÂ´aquina se originam da
execucÂ¸ Ëœao dos aplicativos de mineracÂ¸ Ëœao cpuminer e xmrig.
DisponÂ´Ä±vel em https://github.com/appneta/tcpreplay.
DisponÂ´Ä±vel em https://minergate.com.
DisponÂ´Ä±vel em https://guiminer.org.
0.0 0.2 0.4 0.6 0.8 1.0
Taxa de Falsos Positivos
0.0
0.2
0.4
0.6
0.8
1.0
Taxa de Verdadeiros Positivos
FA (AUC = 0.97)
RL (AUC = 0.68)
GB (AUC = 0.90)
NB (AUC = 0.63)(a) Curva de caracterÂ´Ä±sticas operacionais
do receptor (ROC).PrecisÃ£o Sensibilidade Especificidade
0
20
40
60
80
100
Porcentagem (%) Floresta AleatÃ³ria
RegressÃ£o LogÃ­stica
Gradient Booster Tree
Naive Bayes
(b) PrecisËœao, sensibilidade e especificidade dos algorit-
mos de classificacÂ¸ Ëœao avaliados.
Figura 4. AvaliacÂ¸ Ëœao dos algoritmos de aprendizado de m Â´aquina. a) O algoritmo
de Floresta Aleat Â´oria apresenta uma Â´Area Abaixo da Curva (AUC) de 0,97 e, as-
sim, apresenta a melhor relacÂ¸ Ëœao de compromisso entre sensibilidade e especifi-
cidade. b) Gradient Boosted Tree tamb Â´em apresenta altas taxas de sensibilidade
e especificidade, por Â´em s Ëœao inferiores `as da Floresta Aleat Â´oria.
dois testes de desempenho. O primeiro Â´e a relacÂ¸ Ëœao dos pacotes entregues e os pacotes
gerados. O segundo consiste em um teste de latË†encia da rede para verificar se o MineCap
gera sobrecarga. Como os algoritmos de aprendizado de mÂ´aquina Naive Bayes e Re-
gressËœao LogÂ´Ä±stica obtiveram mal desempenho, apenas os algoritmos de Floresta AleatÂ´oria
e Gradient Boosted Tree sËœao apresentados nas prÂ´oximas avaliacÂ¸ Ëœoes. A Figura 5(a) mos-
tra a taxa de trÂ´afego entregue para os quatro hosts que estavam minerando criptomoedas.
Vale a pena observar que o algoritmo de Floresta AleatÂ´oria bloqueia pelo menos 80%
do trÂ´afego de mineracÂ¸ Ëœao, enquanto o Gradient Boosted Tree atinge 25% do trÂ´afego de
mineracÂ¸ Ëœao entregue no Host 8. Em mÂ´edia, o algoritmo de Floresta AleatÂ´oria bloqueia
mais trÂ´afego na rede do que o Gradient Boosted Tree, devido sua maior capacidade de
generalizacÂ¸ Ëœao do conhecimento obtido. Destaca-se tambÂ´em que os algoritmos baseados
em Â´arvore tiveram melhor desempenho do que outros devido `a natureza discreta dos dados
de rede [Andreoni Lopez et al., 2016].Host 5 Host 8 Host 9 Host 13
0.00
0.05
0.10
0.15
0.20
0.25
Taxa de Pacotes Entregues
Floresta AleatÃ³ria
Gradient Booster Tree
(a) Taxa de pacotes de mineracÂ¸ Ëœao de criptomoe-
das entregues em um trÂ´afego gerado de 30 min.FA GBT NB RL S/M
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
LatÃªncia (ms)
(b) LatË†encia de comunicacÂ¸ Ëœao no cenÂ´ario avaliado.
Figura 5. AvaliacÂ¸ Ëœao da lat Ë†encia na rede com e sem a ferramenta MineCap e
gr Â´afico da taxa de pacotes de mineracÂ¸ Ëœao entregue. a) O classificador Floresta
Aleat Â´oria bloqueou 80% do tr Â´afego de mineracÂ¸ Ëœao enquanto o Gradient Boos-
ted Tree encaminhou mais que 25% do tr Â´afego de mineracÂ¸ Ëœao. b) O MineCap
n Ëœao acrescenta lat Ë†encia na rede. Floresta Aleat Â´oria (FA), Gradiente Boosted Tree
(GBT), Naive Bayes (NB), Regress Ëœao LogÂ´Ä±stica (RL), Sem MineCap (S/M).
A latË†encia da rede foi analisada enquanto os testes eram realizados gerando pa-
cotes ICMP (Internet Control Message Protocol) de um host na rede para o controlador.
O teste de latË†encia foi executado nos testes com todos os algoritmos e, tambÂ´em, em um
novo cenÂ´ario reproduzindo o mesmo trÂ´afego sem intervencÂ¸ Ëœao do MineCap. Os resultados
mostram que o mecanismo MineCap nËœao implica mais latË†encia no encaminhamento de
pacotes e, assim, mantÂ´em o desempenho da rede do cenÂ´ario sem a adocÂ¸ Ëœao do MineCap,
como mostra a Figura 5(b). TambÂ´em foi avaliado, separadamente, o tempo de resposta
de chamada REST que foi insignificante, mostrando um atraso de menos de 1 ms em
uma rede local, pois o tamanho dos pacotes nas chamadas Â´e muito pequeno. O tempo
de bloqueio Â´e em mÂ´edia de 2 minutos, usando ambos os algoritmos, Floresta AleatÂ´oria
e Gradient Boosted Tree, porque `as vezes o algoritmo classifica fluxos de mineracÂ¸ Ëœao de
criptomoedas como fluxos normais. Os modelos de aprendizado de mÂ´aquina sËœao passÂ´Ä±veis
de falhas, jÂ´a que falsos positivos e negativos existem nos problemas de aprendizado de
mÂ´aquina em que nËœao hÂ´a sobreajuste [Pietraszek e Tanner, 2005].
Floresta AleatÂ´oria e Gradient Boosted Tree obtiveram resultados similares, porÂ´em
os testes anteriores utilizavam uma quantidade estÂ´atica de mineradores. Â´E importante
avaliar se o aumento na quantidade de mineradores na rede impacta o desempenho dos
classificadores. Assim, o teste com 30 minutos de trÂ´afego foi realizado variando a quan-
tidade de mineradores.
(a) PrecisËœao, sensibilidade, especificidade e precisËœao do modelo Floresta AleatÂ´oria para cenÂ´arios
com diferentes nÂ´umeros de mineradores.
(b) PrecisËœao, sensibilidade, especificidade e precisËœao do modelo Gradient Boosted Tree para
cenÂ´arios com diferentes nÂ´umeros de mineradores.
Figura 6. AvaliacÂ¸ Ëœao dos algoritmos de aprendizado de m Â´aquina de acordo com o
crescimento do n Â´umero de mineradores.
A Figura 6 mostra que, `a medida que mais mineradores sËœao adicionados `a rede,
a precisËœao e a sensibilidade dos modelos diminuem, mas continuam com resultados
aceitÂ´aveis, superiores a 75%. Paralelamente, Â´e proposto uma variante do super lear-
ner [Van der Laan et al., 2007] usando esses dois modelos pelos seguintes motivos: i) Â´e
desejado ter um desempenho igual ou superior ao dos algoritmos usados utilizando no su-
per learner; ii) Â´e importante o uso de algoritmos de aprendizado de mÂ´aquina presentes na
biblioteca MLlib [Meng et al., 2016] do Spark, pois obtË†em-se melhores aproveitamentos
da abstracÂ¸ Ëœao de dados do Spark e a biblioteca nËœao possui suporte para o aprendizado in-
cremental. Assim, utiliza-se uma rede neural como o super modelo, pois suporta o apren-
dizado incremental. Para testar a eficÂ´acia do super aprendizado incremental, utilizou-se
o super modelo em dois cenÂ´arios diferentes. O cenÂ´ario a) com cinco mineradores, e o
cenÂ´ario b) com quinze mineradores. Esses cenÂ´arios representam ambientes com poucos
mineradores e muitos mineradores, proporcionalmente ao total de dezesseis hosts. Em
cada cenÂ´ario, executou-se o mesmo padrËœao de 30 minutos de trÂ´afego de rede reprodu-
zido. Esse tempo foi discretizado em fatias de cinco minutos. A cada cinco minutos sËœao
calculadas a precisËœao, a sensibilidade, a especificidade e a precisËœao do modelo.
(a) PrecisËœao, sensibilidade, especificidade e precisËœao do super aprendizado incremental com pou-
cos mineradores durante o tempo.
(b) PrecisËœao, sensibilidade, especificidade e precisËœao do super aprendizado incremental com mui-
tos mineradores durante o tempo.
Figura 7. AvaliacÂ¸ Ëœao da t Â´ecnica de super aprendizado incremental durante repro-
duzindo um tr Â´afego de 30 min.
Â´E possÂ´Ä±vel verificar na Figura 7 que em algumas fatias de tempo o modelo se
comporta mal, mas melhora quando aprende com os novos dados. Ainda, em alguns
momentos, acontece o desvio de conceito como Â´e possÂ´Ä±vel ver na fatia de tempo de 15
minutos da Figura 7(a) e nas fatias de tempo 5, 10 e 30 minutos da Figura 7(b), mas o
super modelo se adapta como Â´e possÂ´Ä±vel identificar nos 20 e 25 minutos na Figura 7(a) e 15
e 20 minutos na Figura 7(b), pois Â´e treinado incrementalmente com as melhores amostras
selecionadas de acordo com sua probabilidade de classificacÂ¸ Ëœao e, entËœao, Â´e garantido que o
super modelo aprenderÂ´a com dados que possuem alta probabilidade de estarem corretos.
7. ConclusËœao
A tendË†encia da mineracÂ¸ Ëœao de criptomoeda Â´e crescer proporcionalmente ao valor
monetÂ´ario das moedas digitais. O mecanismo MineCap foi desenvolvido para identificar
e bloquear os fluxos em linha de mineracÂ¸ Ëœao de criptomoeda em uma rede definida por
software. Foi desenvolvido um protÂ´otipo do mecanismo para avaliacÂ¸ Ëœao. O artigo propË†os a
tÂ´ecnica de super aprendizado incremental que combina modelos candidatos como entrada
de um super modelo de aprendizado incremental. Os resultados das avaliacÂ¸ Ëœoes mostram
que os algoritmos de aprendizado de mÂ´aquina mais adequados a serem modelos candi-
datos a fornecerem atributos ao aprendizado incremental foram a Floresta AleatÂ´oria e o
Gradient Boosted Tree. Ambos apresentaram boa capacidade de generalizacÂ¸ Ëœao, com pre-
cisËœao e especificidade de cerca de 100% e sensibilidade de 66,5%. A tÂ´ecnica de super
aprendizado incremental obteve bons resultados e demonstrou um correto funcionamento
em relacÂ¸ Ëœao a fatias de tempo com diferentes quantidades de mineradores na rede. A
tÂ´ecnica aprende com novos dados, mantendo alto desempenho desde o inÂ´Ä±cio da execucÂ¸ Ëœao
e, em alguns casos, melhorando com o tempo.
ReferË†encias
Andreoni Lopez, M., Lobato, A. G. P. e Duarte, O. C. M. B. (2016). A performance
comparison of open-source stream processing platforms. Em 2016 IEEE Global Com-
munications Conference (GLOBECOM), p. 1â€“6.
Andreoni Lopez, M., Mattos, D. M. F., Duarte, O. C. M. B. e Pujolle, G. (2019). Toward
a monitoring and threat detection system based on stream processing as a virtual
network function for big data. Concurrency and Computation: Practice and Expe-
rience, 0(0):1â€“17.
Bannour, F., Souihi, S. e Mellouk, A. (2018). Distributed SDN control: Survey, taxonomy,
and challenges. IEEE Communications Surveys Tutorials, 20(1):333â€“354.
Carbone, P., Ewen, S., Haridi, S., Katsifodimos, A., Markl, V. e Tzoumas, K. (2015).
Apache Flink: Unified Stream and Batch Processing in a Single Engine. Data Engine-
ering, p. 28â€“38.
de Oliveira, M. T., Carrara, G. R., Fernandes, N. C., Albuquerque, C. V. N., Carrano,
R. C., de Medeiros, D. S. V. e Mattos, D. M. F. (2019). Towards a performance eva-
luation of private blockchain frameworks using a realistic workload. Em 2019 22nd
Conference on Innovation in Clouds, Internet and Networks and Workshops (ICIN),
Paris.
Fei-Fei, L., Fergus, R. e Perona, P. (2007). Learning generative visual models from few
training examples: An incremental bayesian approach tested on 101 object categories.
Computer Vision and Image Understanding, 106(1):59 â€“ 70. Special issue on Genera-
tive Model Based Vision.
Gama, J., Ë‡ZliobaitË™e, I., Bifet, A., Pechenizkiy, M. e Bouchachia, A. (2014). A survey on
concept drift adaptation. ACM computing surveys (CSUR), 46(4):44.
Ingols, K. (2009). Modeling modern network attacks and countermeasures using attack
graphs. Computer Security Applications Conference.
Konoth, R. K., Vineti, E., Moonsamy, V., Lindorfer, M., Kruegel, C., Bos, H. e Vigna,
G. (2018). Minesweeper: An in-depth look into drive-by cryptocurrency mining and
its defense. Em Proceedings of the 2018 ACM SIGSAC Conference on Computer and
Communications Security, p. 1714â€“1730. ACM.
Luengo, J., FernÂ´andez, A., GarcÂ´Ä±a, S. e Herrera, F. (2011). Addressing data complexity
for imbalanced data sets: analysis of smote-based oversampling and evolutionary un-
dersampling. Soft Computing, 15(10):1909â€“1936.
Mattos, D. M. F., Duarte, O. C. M. B. e Pujolle, G. (2016). Reverse update: A consistent
policy update scheme for software-defined networking. IEEE Communications Letters,
20(5):886â€“889.
McAfee, A., Brynjolfsson, E., Davenport, T. H., Patil, D. e Barton, D. (2012). Big data:
the management revolution. Harvard business review, 90(10):60â€“68.
Medeiros, D. S. V., Cunha Neto, H. N., Andreoni Lopez, M., MagalhËœaes, L. C. S., Silva,
E. F., Vieira, A. B., Fernandes, N. C. e Mattos, D. M. F. (2019). AnÂ´alise de dados em
redes sem fio de grande porte: Processamento em fluxo em tempo real, tendË†encias
e desafios. Minicursos do SimpÂ´osio Brasileiro de Redes de Computadores-SBRC,
2019:142â€“195.
Meng, X., Bradley, J., Yavuz, B., Sparks, E., Venkataraman, S., Liu, D., Freeman, J., Tsai,
D., Amde, M., Owen, S. et al. (2016). Mllib: Machine learning in apache spark. The
Journal of Machine Learning Research, 17(1):1235â€“1241.
Open Networking Foundation (2012). OpenFlow Switch Specification Version 1.3.0 (Wire
Protocol 0x04). The OpenFlow Consortium.
Pietraszek, T. e Tanner, A. (2005). Data mining and machine learningâ€”towards reducing
false positives in intrusion detection. Information security technical report, 10(3):169â€“
183.
Polikar, R., Upda, L., Upda, S. S. e Honavar, V. (2001). Learn++: an incremental learning
algorithm for supervised neural networks. IEEE Transactions on Systems, Man, and
Cybernetics, Part C (Applications and Reviews), 31(4):497â€“508.
Porras, P. A. e Valdes, A. (2001). Network surveillance. US Patent 6,321,338.
Tahir, R., Huzaifa, M., Das, A., Ahmad, M., Gunter, C., Zaffar, F., Caesar, M. e Borisov,
N. (2017). Mining on someone elseâ€™s dime: Mitigating covert mining operations in
clouds and enterprises. Em International Symposium on Research in Attacks, Intrusi-
ons, and Defenses, p. 287â€“310. Springer.
Van der Laan, M. J., Polley, E. C. e Hubbard, A. E. (2007). Super learner. Statistical
applications in genetics and molecular biology, 6(1).
Wang, S., Minku, L. L., Ghezzi, D., Caltabiano, D., Tino, P. e Yao, X. (2013). Concept
drift detection for online class imbalance learning. Em The 2013 Int. Joint Conference
on Neural Networks (IJCNN), p. 1â€“10.