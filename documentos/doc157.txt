The Time Complexity of Maximum Matching 
by Simulated Annealing 
GALEN H. SASAKI AND BRUCE HAJEK 
University of Illinois at Urbana-Champaign, Urbana, Illinois 
Abstract. The random, heuristic search algorithm called simulated annealing is considered for the 
problem of finding the maximum cardinality matching in a graph. It is shown that neither a basic form 
of the algorithm, nor any other algorithm in a fairly large related class of algorithms, can find maximum 
cardinality matchings such that the average time required grows as a polynomial in the number of nodes 
of the graph. In contrast, it is also shown for arbitrary graphs that a degenerate form of the basic 
annealing algorithm (obtained by letting “temperature” be a suitably chosen constant) produces 
matchings with nearly maximum cardinality in polynomial average time. 
Categories and Subject Descriptors: F.2.2 [Analysis of Algorithms and Problem Complexity]: Non- 
numerical Algorithms and Problems; G.3. [Mathematics of Computing]: Probability and Statistics- 
probabilistic algorithms; 1.2.8 [Artificial Intelligence]: Problem Solving, Control Methods and Search- 
heuristic methods 
General Terms: Algorithms, Performance, Theory, Verification 
Additional Key Words and Phrases: Maximum matching, simulated annealing 
1. Introduction 
1.1 MOTIVATION. Simulated annealing is a Monte Carlo search heuristic that 
can be used to solve minimization (or maximization) problems. The simulated 
annealing method has received much attention from researchers since it was 
introduced in [2], [9] and [ 131, but there are apparently no concrete theoretical 
results regarding the average time complexity of the algorithm as the size of the 
problem instance tends to infinity, for a nontrivial problem. 
In this paper we consider simulated annealing applied to maximum matching, a 
fundamental problem in combinatorial optimization. An instance of the maximum 
matching problem is a simple graph G = (V, E), where V denotes the set of nodes 
of G and E denotes the set of (undirected) edges of G. A matching M in G is a 
subset of E such that no two edges in M share a node. The maximum matching 
problem for instance G is to find a matching in G with maximum cardinality. 
This work has been supported by the National Science Foundation under grant NSF ECS 83-52030 
with matching funds from Hughes Aircraft Company and the Army Research Oflice under grant 
DAAG29-84-K-0005. 
Much of the work was performed while the authors were visiting the Laboratory for Information and 
Decision Systems, Massachusetts Institute of Technology. 
Authors’ present address: Coordinated Science Laboratory, 110 1 West Springfield Avenue, Urbana, IL 
61801. 
Permission to copy without fee all or part of this material is granted provided that the copies are not 
made or distributed for direct commercial advantage, the ACM copyright notice and the title of the 
publication and its date appear, and notice is given that copying is by permission of the Association for 
Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. 
0 1988 ACM 0004-541 l/88/0400-0387 $01.50 
Journal 
of the Association 
for Computing 
Machinery, 
Vol. 
35, No. 2, April, 
1988, pp. 387403. 
388 
G. H. SASAKI AND B. HAJEK 
The maximum matching problem is easy in the sense that there is a known 
deterministic algorithm that solves the problem in O( Jrvi 
] E I) steps (see [lo]), 
where ] V ] is the cardinality of V. However, we do not consider maximum matching 
to be trivial since the deterministic algorithm is somewhat subtle. 
1.2 THE BASIC ANNEALING ALGORITHM FOR MAXIMUM MATCHING. We de- 
scribe here what is perhaps the most obvious way to apply simulated annealing to 
search for the maximum matching of a graph G = (I’, E). Let h, , Xz, . . . be a 
nonincreasing sequence of numbers in the interval (0, I]. (X, plays the role of 
exp(- l/T& where Tk is the “temperature” at time k [9].) We say that an edge e is 
matchable relative to a matching A4 if e 4 M and if M + e is a matching (here 
M + e is our notation for M U (e}, which we use only if e 4 M). Let Q(M) 
denote the set of matchable edges relative to matching M. 
To begin the algorithm, choose an arbitrary matching X0 in G-for example, XC, 
could be the empty set 0. Having selected X0, XI, . . . , Xk, choose Xk+, as follows. 
Choose an edge e at random, all edges in E being equally likely. 
If e is matchable relative to Xk, let Xk+, = Xk + e. 
If e E Xk, let 
Xk - e 
X k+l 
= 
{ 
xk 
with probability xk, 
with probability 1 - xk. 
Else, let Xk+, = Xk. 
The sequence of states visited by the algorithm, XO, XI, . . . , forms a Markov 
chain. 
I .3 CONVERGENCE IN PROBABILITY. We begin by giving some standard nota- 
tion [ 121. Given a matching M in G, a node v is exposed if no edge in M is incident 
to v. A path p in G is a sequence of nodes p = [IA, ~2, . . . , vk], where k Z 1, the 
vk are distinct, and [vi, vi+,] E E for 1 I i 5 k - 1. The length 
i 
nodesv,,~~,..., 
of such a path is k - 1. The path is augmenting for M if its length is odd (so k is 
even), if v1 and vk are exposed, and if [Vi, Vi+] ] E M for even values of i with 
2 I 
[VI, 
5 k - 2. A well-known result of Berge and Norman and Rabin is that a 
matching M does not have maximum cardinality if and only if there exists an 
augmenting path for M [ 12, theorem 10.11. 
Let M, be a matching that does not have maximum cardinality, and let 
U2, * *. , vk], be an augmenting path for MO. Starting from MO, it is possible for 
the basic annealing algorithm to reach a higher cardinality matching by passing 
through the sequence of matchings MI, M2, . . . , Mk- I given by 
Ml 
A43 
Mk-3 
and finally 
= 
= 
= 
MO - [U2, u31, 
A42 
Mk--4 - 
Iv4, hl - 
[Uk-2, 
Mk-1 
M2 
M4 
Uk-I], 
= 
M/c--2 
Mk-2 
+ 
[Uk, 
= 
= 
= 
MI 
M3 
M/c-3 
Uk-I]. 
+ 
+ 
EUl, u21, 
IU3, 
+ 
u41, 
[Uk-3, 
Uk-21, 
The matchings in the sequence have cardinality at least as large as ] MO I - 1. In 
the terminology of [7] the depths of the local maxima for the matching problem 
are at most one. The following theorem is thus an immediate consequence of 
Time Complexity of Maximum Matching 
389 
[7, theorem 11. A matching Mis said to be maximal if no edge is matchable relative 
to M. Let S* denote the set of matchings with maximum cardinality. 
THEOREM 1. Let G = (V, E) be a graph with a nonempty set of edges E. If all 
maximal matchings of G are in S*, then 
lim P[Xk E S*] = 1 
k-m 
if and only if 
If some maximal matching is not in S*, then 
lim P[& E S*] = 1 
tf and only if 
lim Xk = 0. 
k-e 
lim xk = 0 and i xk = +w. 
k-m 
k-m 
k=O 
Theorem 1 gives a large-time asymptotic result for each fixed instance G, and 
the conditions do not depend on the size of G. In contrast, our goal in this paper 
is to give asymptotic results as ] V ] tends to infinity. Interesting general work on 
the analysis of simulated annealing run for a finite number of iterations has 
appeared (see, e.g., [I], [4], and [ll]). 
However, the general theory does not 
determine, for example, whether or not simulated annealing exactly (or nearly) 
solves the maximum matching problem in an amount of time growing as a 
polynomial in ] V ] . Moreover, it is not yet clear whether any general theory could 
answer such questions. In the meantime, we hope this paper presents the kinds of 
results that one would like to establish more generally. 
1.4 ORGANIZATION OF THE PAPER. In Section 2 we show that for a certain 
family of graphs the basic annealing algorithm, or any other algorithm in a fairly 
large related class, cannot find maximum cardinality matchings using average time 
upper bounded by a polynomial in ] V 1. In contrast, we show in Section 3 that a 
degenerate form of the basic simulated annealing algorithm (obtained by letting xk 
be a suitably chosen constant, independent on k) produces matchings with nearly 
maximum cardinality using average time upper bounded by a polynomial in ] V ] . 
Sections 2 and 3 can be read independently. 
2. The Impossibility of Maximum Matching in Polynomial Average Time using 
Certain Annealing-Type Algorithms 
Certain local search algorithms for the maximum matching problem are considered 
in this section. The algorithms are not restricted much in an attempt to include 
several implementations of simulated annealing. Both the basic simulated annealing 
algorithm (given in Section 1.2) when X0 = 0 and a particular multistart descent 
algorithm are included. Nevertheless, it is proved that the algorithms cannot reach 
a maximum matching in average time bounded by a polynomial in ] V 1, for a 
particular family of graphs. 
First, we allow the “temperature” to depend on both time and the current and 
past states of the algorithm. Second, we assume that the type of each move can be 
specified from among the three possibilities whenever they exist: addition of an 
edge, deletion of an edge, or no change. The key restriction we do impose is that, 
given the type of a move, the location of the edge to be added or deleted is 
uniformly distributed over the possible locations. 
We thus view the sequence X0, X,, . . . of states generated by the algorithm 
as a controlled Markov process. Suppose that “controls” a, and d, are given 
390 
such that for each t 
a,, 4, a, + d E [O, II 
Jw+, 
= M’ Ix, = M, Xl-l, . . . , XO] 
c 1 - a, - dl 
4 
= IMI 
J- 
I 
G. H. SASAKI AND B. HAJEK 
with probability one, 
and a, and dt are functions of (X0, . . . , X,), 
if 
if 
if 
if 
M = M’, 
eEM 
eEQ(M) 
IM@M’I 
and M’=M-e, 
and M’=M+e, 
22, 
(1) 
(2) 
0 
where M @ M’ denotes the symmetric difference of M and M’ (recall that Q(M) 
is the set of edges matchable relative to M). 
Clearly, if we choose the controls appropriately, we can use this controlled 
Markov process to mimic the basic simulated annealing process of Section 1.2. We 
can also control the Markov process to mimic a multistart descent algorithm 
(although only at half speed). To do this, we assume that X0 = 0. We then let 
a, = I for 0 I t c S,, where S, is the first time that a maximal matching is 
reached. Then we let d* = 1 for S, 5 t < 2S1, which guarantees that X, = 0 for 
t = 2Sr. We then keep repeating this process. 
The family of graphs, we focus on is (Gr , G2, G3, . . .), where G,, = (V, E), 
I/= 
(Uij: 1 5 i, j 5 n + 1) U {Vij: 1 I i, j I: n + l), 
?I+1 
E=HUB, 
H = U Hj, B = 6 Bj, 
j=l 
Hj = ([uii, Uij]: 1 I i 5 n + 1) 
Bj = ([vii, ukj+l]: 1 5 i, k I n + 1) 
j=l 
forjsuchthat 
for j such that 
1 Ij=n+ 
1, 
1 I j I ~1. 
Graph G, is a bipartite graph with 2(n + l)* nodes and (n + 1)3 edges. For each j, 
the subgraph of G, induced by Bj is complete and bipartite, and the subgraph of 
G, induced by Hj consists of n + 1 disjoint edges. The set of edges His a matching, 
and it is maximum since it leaves no nodes exposed. In addition, there are no other 
maximum matchings, since, by induction, any matching that has no nodes exposed 
must include the edges in HI, Hz, . . . , H,, , . As an example, G3 is sketched in 
Figure 1. 
The main result of this section is the following theorem. 
THEOREM 
2. 
There exist positive constants u1 and c2 such that the following is 
true. For any n z 1, let (X, a, d) be a controlled process forjinding 
the maximum 
matching of G, satisfying conditions (1) and (2). Define R* by 
R* = min(k: Xk is a maximum matching). 
Then 
E[R* 1 X0 = 01 r u1 exp(u2n). 
In the proof of Theorem 2 we use a function g(M) that measures how far 
a matching M is from the unique maximum matching H. It includes the term 
1 B n M 1 and a second term that is related to the set of edges in B that are 
Time Complexity of Maximum Matching 
FIG. 1. Sketch of Gs. 
matchable relative to M: 
g(M) = c I B n MI + j$, HUM), 
where c = 18, 
J/(x, Y) = 2 mink 
ui+l(Mh 
Y) + 4xB~,y~~,xfy~, 
VO(M) = Un+2(M) = 0, and for all j such that 1 5 j 5 12 + 1, Q(M) (respectively, 
F(M)) is the number of exposed nodes in (Uij: 1 5 i 5 n + 1) (respectively 
(Vii: 1 I i 5 n + 1)) relative to M. Some trivial properties of g are that g is non- 
negative, g(H) = 0, and g(0) = 2n(n + 1). 
The next set of lemmas and definitions are used to show that g(X) tends to drift 
away from zero (and hence X. drifts away from H) when g(X) is below a certain 
threshold (see eq. (3) below). After the lemmas and definitions the proof of 
Theorem 2 is presented. 
LEMMA 3. Suppose x, y 10. Then 
(4 
(4 
$(x + 1, Y) - +(x9 Y) 
w 
if 
y 2 max(x, l), 
otherwise; 
if x 2 max(y, I), 
otherwise; 
+ 1, Y + 1) - w, Y) E 12, 3). 
PROOF. Easy by inspection of Table I. Cl 
LEMMA 4. Let M be a matching of G,. 
(a) Suppose e E Mn Hi. Then g(M - e) - g(M) > 0 ifand only if 
K-l(M) 
2 ma(Uj(M), 
(b) g(M-e)-g(M)E(O, 
I,..., 
1) 
or 
&+1(M) 1 ma(vj(M), 
6JfireEMnH, 
(c) g(M - e) - g(M) E (-c + 2, -c + 3) fir e E M fl B. 
1) 3 
392 
PROOF. 
g(M - e) - g(M) = $(&i(M), 
+ $(b(M) 
andforeEMnBj 
g(M - 
e) 
G. H. SASAKI AND B. HAJEK 
TABLE I. VALUES OF $(x, y) 
Y 
x 
0 
0 
1 
2 
3 
403518 
5 
6 
0 
0 
0 
0 
0 
0 
1 
0 
2 
3 
3 
3 
3 
2 
0 
3 
4 
5 
5 
5 
3 
0 
3 
5 
6 
7 
7 
4 
0 
3 
5 
I 
9 
9 
It is easy to see that for e E M n Hj 
Uj(M) 
5 
0 
7 
9 
10 
11 
6 
3 
5 
0 
3 
5 
7 
9 
11 
12 
+ 1) - +(&l(W, 
+ 13 uj+l(W) - 
Uj(M)) 
+(Q(W, &+1(W), - 
g(W 
= --C 
+ 
$4WJ) 
+ 
1, 
~+I(W 
+ 
1) - 
$+WW, 
uj+l(M)). 
Lemma 4 can be easily deduced from these equations and Lemma 3. 0 
For each matching M of G,, define 
A(M) = (e is matchable relative to M and g(M + e) # g(M)), 
D(M) = (e E M: g(M - e) # g(M)), 
A+(M) = ie E A(M): g(M + e) > g(M)), 
A-(M) = (e E A(M): g(A4 + e) C g(M)), 
D+(M) = (e E WO g(M - 4 > gWf)J, 
D-(M) = (e E D(M): g(M - e) < g(M)). 
LEMMA 
5. 
Let M be a matching of G, and let 0 < 6 < 1. Then 
(a) D+(M) c M n H, D-(M) = M n B, A-(M) c H - 44, A+(M) = B n Q(M), 
(b) I4MI 
=2 IA+(WI, 
(c) 1 D-(M) 1 5 n6 ifg(M) 5 no?, 
(d) I D+(M) I L n(1 - 6(c/2 + 1)) $0 < g(M) < nc& 
PROOF. 
Part (a) is a consequence of parts (b) and (c) of Lemma 4 and the fact 
that c> 3. 
We now prove the following two facts, which imply part (b): Every edge in 
A-(M) has a node in common with an edge in A+(M), and for every edge in 
A+(M) there are at most two edges in A-(M) that have nodes in common with it. 
Let e E A-(M). Then e E Hj for some j by part (a), and, moreover, at least one of 
5-r (M) or Uj+r (M) is strictly positive by part (a) of Lemma 4. Thus, there is at 
least one edge e’ in Bj-1 U Bj that is matchable relative to M and has a node in 
common with e. Then e’ is in A+(M), and hence we can conclude that every edge 
in A-(M) has a node in common with an edge in A+(M). On the other hand, part 
(a) implies A-(M) C H, A+(M) C B, and therefore for every edge in A+(M) there 
are at most two edges in A-(M) that have nodes in common with it. Part (b) is 
proved. 
Time Complexity of Maximum Matching 
I D-W) 
393 
which proves part (c). 
We now prove part (d), wh ich completes the proof of Lemma 5. Let A4 be a 
matching with 0 < g(M) 5 nc6. The fact that g(M) > 0 implies that A4 is not equal 
to the unique maximum matching I& which in turn implies that there exists at 
least one exposed node. Since g(M) < nc, M contains fewer than 12 edges from 
B1 UBZU **- U B,,. Hence M fl Bk = 0 for some k. Now, the set of nodes, 
Z = (Uij: 1 I i 5 n + 1, 1 5 j I k] U (Uij: 1 I i I n + 1, k + 1 rj I n + 11, 
contains exactly half of the nodes of the graph. Since M fl Bk = 0, each edge in A4 
is incident to a node in Z and a node not in Z. Thus, Z contains half, and therefore 
at least one, of the exposed nodes, so at least one of the 2n numbers, 
VI(M), -**, ‘VnW), We), 
* * *, Un+lW), 
is nonzero. By the symmetry between the Vi’s and Vj’s, we can restrict attention to 
the case that for some j with 1 5 j 5 rz, Uj+, (M) is as least as large as any of the 
other 2n - 1 numbers. Then Uj+l(M) 2: max(l$(M), l), SO A4 fl Hj C D+(M) by 
part (a) of Lemma 4. Hence 
ID+(M)1 2 IMn Hjl = n + 1 - F(M) - (Mn Bjl 
=n+l - - 
> n ----..(l 
min( b(M), U,+,(M)) - ( M n Bj I 
g(lM) g(W 
2 
which proves part (d). 0 
c -a(;+ 
l)), 
LEMMA 6. Now set 6 = &. If M is a matching of G,, such that 0 < g(M) < nc6, 
then 
1 A(M) I -1 lzMj [gW + 4 - 001 2 1 
and 
I D(M) I -I eezMj MM - e) - g(M)1 = + 
zj- A(M)#0 
zj- D(M) #0. 
PROOF. By part (a) of Lemma 5 and parts (b) and (c) of Lemma 4 we have 
g(M+e)-g(M)? 
C_i3 -I 
which, together with part (b) of Lemma 5 yields 
I&W I --I II& 
if 
if 
MM + e) - g(M)1 
2 IA(M’[(c - 
3)lA+(M)I - 
e E .4+(M), 
e E A-(M), 
61/l-(M)l] 
(3) 
(4) 
2 1. 
394 
G. H. SASAKI AND B. HAJEK 
Similarly, by part (a) of Lemma 5 and parts (b) and (c) of Lemma 4, we have 
if 
gW-e)-gW)~ 
i 
!c+2 
e E D+(M), 
if 
e E D-(M), 
which, together with parts (c) and (d) of Lemma 5, yields (4). 0 
PROOF OF THEOREM 2. Let to = 0, and for all k > 0 let tk = min{t > tk--L : 
g(X,) # g(X,-, )). We can and do assume that P[R* < +UJ ] X0 = 0]= 1. It follows 
that, with probability 1, R* E (tl , t2, . . .), which implies that 
p[tk+, < 00 1 R* > tk, X0 = 01 = 1. 
Given a matching M, define s(M, 1) and s(M, -1) to be the normalized sums 
appearing in inequalities (3) and (4), respectively, whenever they are well defined. 
By Lemma 6, s(M, 0) L f if 0 < g(M) < nca and if s(M, 13) is well defined. 
Let Ok = 1 if the jump at time t k+L is caused by the addition of an edge,’ and let 
Ok = - 1 if the jump at time t k+, is caused by the deletion of an edge. 
Suppose M is a matching with 0 < g(M) C nc& Then 
m(&k+,) - 
* * * , x01 = SW, 0) = +. 
mfk) IX,,,-, = M, Ok = 4 x1*+,-2> 
Averaging over appropriate values of Ok and (Xi: tk < i < tk+, ), it follows that 
mGGk+,) - mtk) - ; 1 g(x,) 5 X6, R* > tk, X,, . . . , X,] 2 O. 
(5) 
Also, by parts (b) and (c) of Lemma 4, the magnitudes of the increments 
of g(X,) are bounded by c - 2. Thus, Theorem 2.3 of [6] is in force if we define 
(Y, to, a*, b*) by 
~0 = $, 
yk 
= -g(x,,), 
a* = -n&z, 
and 
b* = 0. 
(6) 
Using the fact that Y. = -g(0) = -2n(n + 1) 5 a*, this produces constants q > 0, 
p E (0, l), and D* > 0 such that 
P[g(&) 
= 0, R* > tk-] IX, = 01 5 24, 
(7) 
where u = D* exp(--)7nc6)/( 1 - p). The term P[R* = tk ] X0 = 01 is less than the 
left-hand side of inequality (7), because if X, is the maximum matching, then 
g(X,) is equal to zero. Therefore, P[R* = tk I X0 = 01 5 u. Since R* E (t, , t2, . . .) 
and since tk 2 k, we have 
P[R* > klXo = 0] h P[R* > &IX0 = 01 
= 1 - i P[R* = $1X0 = 01 I max(O, 1 - ku). 
j=l 
Hence 
EIR*IXo=O]= 
i 
k=O 
PIR*>klXo=O]r 
i 
k=O 
max(O, 1 -ku)&. 
Thus, taking ul = (1 - p)/2D* and u2 = vcS, Theorem 2 is proved. Cl 
Remark. Some extra work shows that Conditions D.1 and D.2 of [6] are 
satisfied for Y, a* and b* given in (6) and f = 0.0033683, p = 0.9998, a* = -n&, 
b* = 0, and D* = 1. This shows that Theorem 2 above is true for u1 = 0.0001 and 
a2 = 0.0014. 
Time Complexity of Maximum Matching 
3. Near-Maximum Matching in Polynomial Time 
395 
Let d* denote the maximum node degree of the graph G, and let m* denote the 
maximum of the cardinalities of matchings in G. The next theorem is the main 
result of this section. 
THEOREM 7. Let p > 1. Consider a run of the basic simulated annealing 
algorithm (of Section 1.2) with xk = h for all k, where X is given by 
1 
x = 31 v1w* 
and 
w* = ,6 1 VI (2d*)O-‘a 
Let R denote the random time R = min(k: I & I 2 m* (1 - l/p)). Then 
ER 5 24p2 I VI 5(2d*)2B-2. 
Remarks 
(1) If /I and d* are bounded as ] V ] --, m, then ER = 0( ] V] ‘). In the proof 
below, we see that three of these live factors of ] V] arise from our upper bound 
D1 on the mean time it takes the algorithm to make a single move. A smaller 
average run time can be achieved by using an efficient implementation of an 
algorithm that simulates X,, , &, . . . , where Jk is the time process X makes its kth 
move (see [5]). 
(2) Since 2d* I 2 ] VI, we have with no restriction on d* that ER 5 
6f12228 1 V 1 3+28. Also note that, if ,6 > m*, then XR is a maximum matching. 
(3) We comment briefly on our choice of constant X (equivalently, on our choice 
of temperature). It must be large enough so that the process X “jumps sufficiently 
often,” which is reflected in the bounds given in Lemmas 8 and 9a below. On the 
other hand, X must be small enough so that there is a net drift toward larger 
matchings, enabling us to obtain the bound of Lemma 10 below. 
We have chosen hk to be independent of k, though we can see some motivation 
for letting it decrease as k increases. More precisely, it is clear that an improved 
algorithm can be obtained by letting xk be a decreasing function of ] xk 1. For 
example, it is shown in the proof of Claim 1 below that a matching M in G has an 
augmenting path of length at most 1 + 2 ] M I/(m* - ] MI ). This bound increases 
sharply as ] M ] approaches the final value of ] & 1, which is m *( 1 - ( 1 l/3)), and in 
the proof we replace ] M ] in the bound by this final value. However, working with 
the ] M ]-dependent bound shows that a larger value of Xk can be used when ] & ] 
is small so that the algorithm “jumps more often,” while maintaining sufficient 
drift toward larger matchings. 
We have chosen xk to be independent of k primarily for two reasons: (1) we want 
to demonstrate that Xk can be chosen independently of the algorithm state (open- 
loop in control-theoretic terms), and (2) we do not think the complexity bounds 
can be improved much by letting Xk be either a function of ] & ] or a decreasing 
function of k, because our choice of xk is tuned to the situation in which ] .& ] is 
close to its target value m*( 1 - l/p), and this situation is the most time consuming 
for the algorithm anyway. 
Finally, we think it is significant that we need X to decrease as a function of 
problem size. It suggests that, if the sequence XI, X2, . . . is to be chosen indepen- 
dently of the graph, it should be decreasing. 
PROOF. Define a random process Y by 
i=O, 1,2 ,..., 
Yi = XJiy 
396 
where 4, = 0 and, for i 1 0, 
G. H. SASAKI AND B. HAJEK 
A+, = min(k > Ji: Xk # X,-l), 
and define 
R r=min 
i:IYj)Zm* 
{ 
1-j 
. 
( 
NO&Z. that ) Yi+l ) - ) Yi ) E (- 1, 1) with probability 1 for each i. 
Next, define a random process 2 by 
)I 
Zj = Ysi, 
where&=O,S, 
= 1 and,forir 
Si+* 
= 
1, 
i=O, 
1, . . . . 
min{j: j > Sip ) Yj) - ) 5-2 ) E I-2, 2)), 
and define 
RZ = min i: 
Define constants DI , I& and II3 by 
D, = 6 1 VI *co*, 
LEMMA 8 
Dz = 2w*, 
D3 = 21 VI. 
E[Ji+t - Ji I Ji, vo, XI, . * . , &)I 5 D, * 
LEMMA 9a 
LEMMA 10 
EWi+, - Si)l{i<Rd 
I 
Si, 
(Y,, 
Yl, 
ERz s D3. - - 
* 7 KS,)] 
5 
DP- 
We next prove Theorem 7 assuming the lemmas are true. We have 
ER = EJRy = E i (Ji+l - Ji)lii<R,\ = i E[Ji+l - Ji I i < Ry]P[i c Ry]. 
i=O 
i=O 
Now the outcome of the event (i < RY) is determined by (Ji, (X0, . . . , AT,)), so 
we can apply Lemma 8 to get 
ER s i D,P[i < RY] = DIERy. 
i-0 
Similarly, the fact Rr = SRz and Lemma 9a imply that ERr 5 DzERz. So, also 
using Lemma 10, we conclude that ER I D1 D2D3. This will establish the theorem 
once we prove the three lemmas above. Cl 
PRWF OF LEMMA 8. By the strong Markov property of X, 
E[Ji+, - Ji IA, (x09 XI, * * - 7 Si)l = E[Ji+l - Ji I Y;:]. 
since hk = h for all k, the transition probabilities of X are time invariant; so 
E[Ji+I - Ji I Yi = M] = P[Xk+, # Xk 1 Xk = M-J-‘. 
Time Complexity of Maximum Matching 
397 
Now, fix a matching M. One of two cases is true: 
Case 1. Some edge in E is matchable relative to M. Then 
P[&+,ZXxl&=M]+. 
Case 2. No two of the ] V 1 - 2 1 M 1 exposed nodes are connected by an edge 
in the graph. Then 
IEl= 
so that 
I;’ 
()( - 
Ivl-221Ml 
= ]M](2]V] 
P[Xk+,fXkIXk=M]=-~----- 
Hence, in either case, EIJi+l -Jil 
AIMI -2]M] 
IEI 
Yi=M]~max(IE~,2~ -2]V]’ - 
x 
1)12]MI 
Vl/X)=D,. 
IV1 
Cl 
PROOF OF LEMMA 9a. Lemma 9a is trivial for i = 0, so we fix i with i L 1. Let 
m be an integer with 1 5 m C m*( 1 - l/p). Define a set of matchings B by B = 
(M:IMI=m- 
1 or ] MI = m) and let M,, be a fixed matching in B. Consider 
the event F = (Ys, = M,, Ys,_, E B and Rz > i). The outcome of F is determined 
by (Si, (Yo, 
YI, - - - 9 Ysi)), and the union of events of the form of F as IV&, and m 
vary as above is equal to the event (Rz > i). Hence, it suffices to prove that 
E[Si+l - Si I Si, (YO, YIP * . * 9 YSi,)lIF 
5 
D2 
for arbitrary fixed values of m and M, as above. Without loss of generality, we 
assume that, if I I%&, I = m - 1, then Q(Mo) # 0, otherwise F = 0 (recall that 
Q(I&) is the set of matchable edges relative to I%&,). 
Now, on the event F, we have Si+r = minb > Si: Yj 4 BJ. Using this and the 
strong Markov property of Y, we have 
E[Si+ 1 - Si I Sip (YO, * . * 3 Ys)]G = E[min(j > Si: & S BJ - Si I Ys, = M,]ZF 
= E[S I Yo = M,]G, 
where S denotes the stopping time S = min(j 2 1: Yj Q B). 
LetBbethesetofmatchingsB=(M: 
]iVI 
let 
P denote a stationary-transition 
zm- 
l).NotethatBCB.We 
(8) 
Markov chain with state space B and 
one-step transition probabilities determined by conditioning Y to stay in B for 
each consecutive jump: 
P[Ykk+L 
=,f’I 
p,=Ml~wk+l 
=M’I yIc=Ml 
A(M) 
for M, M’ in B, where A(M) = P[ Yk+, E B I Yk = M]. 
Define a stopping time 3, by S+ = min(k 1 1: yk E B - B). Let S- denote 
a random variable on the same (or possibly enlarged) probability space as 
073, &, - - .) such that 
k-l 
P[S->kl 
To, FI ,... ]= n A(K). 
j-0 
Let S = min(S+, S-). Then, if we impose the conditions To = &I, and Y. = M,,, 
(3, (ykk: 0 5 k < s)) and (S, (Yk: 0 s k 5 S)) have the same distribution. 
398 
Since s 5 r+, it follows that 
G. H. SASAKI AND B. HAJEK 
E[S 1 Yo = M,] 5 E[%+ 1 yo = M,]. 
(9) 
Lemma 9a is implied by (8), (9), and Lemma 9b, which is stated and proved 
next. 
0 
LEMMA 9b. Under the conditions given in the proof of Lemma 9a 
E[s+ 1 y, = M,] 5 2w*. 
PROOF OF LEMMA 9b. Either ] MO ] = m or ] MO I = m - 1. We prove that, if 
]MO] = m, then 
E[s+I 5=M,]52w*- 
1. 
(10) 
This will imply the lemma in general. Hence, we assume that ] 44, ] = m for the 
rest of the proof of Lemma 9b. 
For any matching M, let f(M) denote the length of the shortest augmenting path 
for 44. The function f(M) is well defined if A4 is not a maximum matching (in 
particular if ] M ] = m), and f(M) E ( 1, 3, 5, . . .). Let z denote the maximum of 
f(M) over all M with ] M ] = m. 
CLAIM 1 [8]. 1 I 2p ;- 1. 
PROOF OF CLAIM 1. Let A4 be a matching with I M ] = m and let M* be a 
maximum cardinality matching in G. Let G’ denote the graph with a set of nodes 
V and a set of edges M @ M*, where M @ M* denotes the symmetric difference of 
M and AI*. Each node in G’ has incident to it at most one edge from M and at 
most one edge from M*. Thus, all maximal connected components of G’ are paths 
or cycles, and all cycles have even length. The cycles and even length paths each 
have an equal number of edges from M and M*, while each odd length path has 
exactly one more edge of M* than A4 and is an augmenting path for M. Thus, 
there are at least m * - m vertex-disjoint augmenting paths for M, which, altogether, 
have at most m edges of M. Thus, one of the augmenting paths has no more than 
m/(m* - m) edges of M and hence has length at most 1 + 2m/(m* - m). Finally, 
1+2m/(m*-m)52P- 
1 since m 5 m*( 1 - l/p), and the proof is complete. 0 
CLAIM 2. Suppose M is a matching with I MI = m and define PO and p1 by 
1 
PO = G 
and 
p, =min($, 
1 -PO). 
Then for all k r 0 
(a) P[f@zk+d =f(M) - 2 I FX = Ml = PO iff(M) 2 3, 
(b) P[ I Fx+~ I L m + 1 ] yzk = M] 2 p. if f(M) = 1, 
(cl P[f(%+,) 
>f(M) 
(4 
P[f@-x+,1 =f(M) 
+ 2 I 6, = Ml = 0, 
+ 2 I yzc = Ml 5 PI. 
PROOF OF CLAIM 2. We first prove part (a) under the assumption that 
f(M) > 5. Choose an augmenting path p for M of length f(M), and label some of 
its nodes and edges as indicated in Figure 2. Since p is an augmenting path of 
shortest length, no neighbor of ul, except possibly node ul, can be an exposed 
node. Also, if u1 and uI are neighbors, then w1 and v2 are not. Thus, there are at 
most two choices for an edge e’, namely, el and possibly either [u,, ul] or [w,, uz], 
such that f(M - el + e’) 2 f(M). There is also at least one choice of e’, namely, 
Time Complexity of Maximum Matching 
FIG. 2. An augmenting path for M. 
e’ = PI, such thatf(M - el + e’) = f(M) - 2. Thus, 
P[f(F2k+2) =f(M) - 2 I F2k+, =M- 
This is true with el replaced by e2 as well, so 
ml 
F22k+2) =f(M) - 
> 
P(Y2k+l 
c->-c 
2 
= 
31MI-2lMI 
This establishes part (a) iff(M) - 
2 I F2k = Ml 
M - el or Yzk+l = M - e2 1 F2k = M] 
3 
1 
“* 
399 
ell 2 f. 
2 5. 
We now complete the proof of part (a) by considering the case f(M) = 3. Let 
[IJ, , wI , w2, u2] be an augmenting path for M of length 3 and let e = [WI, WZ]. Then 
e is in M, and nodes uI and u2 are not neighbors. Now, if e’ is an edge such that 
f(M-e+e’)r3, 
then e’ must be incident to either uI or w1 and to either u2 or ~2. 
Moreover, if e’ = [ul, w2] is such an edge, then u2 and wI must not be neighbors. 
Thus, there are at most two choices of e’ such that (11) is true, namely, e and 
possibly one of [u, , w2] or [u2, wI 1. There are also at least two values of e’ such 
thatf(M 
(11) - 
e + e’) = 1, namely, [ul, w,] and [u2, w2]. Thus, 
P[f(&+2)=f(M)-2 
1 &k=M]&P[&+,=M-eI 
y&=M]=p,-,. 
Part (a) is proved. 
Turning to part (b), assume thatf(M) = 1. Then Q(M) is not empty. Hence 
P[ 1 yZk+l 1 2 m + 1 1 y2k = M] = P[ 1 yzk+l 1 m + 1 1 yzk M] 
= 
= 
2 (1 + mA)-’ 2 (1 + m)-’ 1 po, 
tit 
= 
I Q(M) I 
IQW>I+hm 
so that part (b) is proved. 
We now prove parts (c) and (d). Choose an augmenting path p for M of length 
f(M). 
I?+ = {(e, , e2): el E M, e2 is matchable relative to M - el , 
andf(M - el + 4) rf(M) 
+ 2). 
Suppose (eI , e2) E I’+. Then el and q are incident to a common node (otherwise, 
el is matchable relative to M - el + e2, e2 is matchable relative to M, and hence 
f(M - el + e2) = f(M) = 1, a contradiction) and el # e2. Since p is not an 
augmenting path for M - el + e2, at least one of el or e2 is incident to a node of 
p. This means that either el is an edge of p or e2 is incident to one of the exposed 
nodes on the ends of p. Thus, we have narrowed down the possibilities to one of 
the four cases shown in Figure 3. We can rule out the first three of these cases since 
400 
G. H. SASAKI AND B. HAJEK 
FIG. 3. Four possibilities for (e,, 4). Edges in the path p are drawn straight and 
horizontally. Edges in M are bold. Nodes u, and V~ are the end nodes of an augmenting 
path for M - e, + e2. Only the fourth possibility can really occur. 
in these cases there is an augmenting path for A4 - el + e2 with length at most the 
length of p. We have thus shown that, if (e, , e2) E I’+, then e2 is incident to an 
exposed node of p, el and e2 are incident to a common node, and el is not in the 
path p. It follows that f(M - el + e2) = f(M) + 2 for any (el, e2) in I’+, which 
proves part (c). 
Define 
W= (e2: (e,, e2) E IT+ for some el). 
If e E W, there is exactly one edge, call it w(e), such that (w(e), e) E F+. Each 
edge in W is incident to an exposed node of p so that 1 W 1 5 2d*. Thus, 
P[.M2,,+2) 
= 
=f(M) 
z 
(e,,qF-+ 
+ 
2 
I 
F22k 
= 
Ml 
P[ F2k+2 = A4 - el + e2, F2k+, = M - el 1 F2k = M] 
= & P[F22k+2 = M - w(e) + e 1 F2,k+l = M - w(e)] 
X P[F2,k+l = M - w(e) 1 F22k = MJ 
1 
=r, 
1 
eEw 1 Q(M - w(e)) 1 x z 
Iwl 
= m 
d* 
5 z 
’ 
Together with parts (a)-(c), this proves part (d) so that Claim 2 is completely 
proved. 0 
We now complete the proof of Lemma 9b using Claims 1 and 2. Define a process 
u = (u3, UI, . . .) by Uk = :( 1 + f( y22k))1t2kd~+). 
Note that Uk takes values in 
(0, 1, * - - 9 LJ where L = (1 + E)/2. Claim 1 implies that L 5 ,f3, and Claim 2 
implies that 
2 PO 
P[Uk+l = i I Uk = j, Uk-,, . . . , Uo] = 0 
f 
5 PI 
if 
if 
if 
i=j-1, 
i 
2 j + 2, 
i=j+l. 
(12) 
Let w= (Wo, w,, . . .) denote the Markov chain with one-step transition proba- 
bilities shown in Figure 4. From (3.5) it follows that, if W. = UO, then the chain 
Time Complexity of Maximum Matching 
PO 
1 
> 
0 
PO 
1 
4 
2 
FIG. 4. One-step transition probabilities for the Markov chain IV. 
W stochastically dominates the process U. Hence 
E[S+ ] FO = M,] + 1 = 2E[min(j: Uj 
= 0) ] FO = M,] 
5 2E[min(j: 
5 2E[min(j: 
= $ yg: (L - j) k ’ 
J 
401 -JzJ&pi 
** 
l 
Wj 
9 
= 0) ] WO = f(Mo)] 
Wj = 0) ] W. = L] 
( 
)’ 
The establishes inequality (lo), so the proof of Lemma 9b, and hence also the 
proof of Lemma 9a, is complete. •i 
PROOF OF LEMMA 10. In the first part of the proof, we refer to the setup in the 
proof of Lemma 9a. By the reasoning there, we see that, for i L 1, 
~Hy,,,I>Iy,I 
ISi,(YO,Y,,..., 
The term A( 5) is equal to 
p[yk+, E j’jl yk = El = 
Ysi)]ZF = P[ 1 Ys 1 = m + 1 I Y. = M,]IF 
= P[S- > $+I FCC = M,]ZF 
Iem 
1 Q(F) 1 + A(m - 1) 
1 
if 
if 
] C] = m - ” 
I Fj 
I 
2 m. 
As in the proof of Lemma 9a we assume that, if I A& I = m - 1, then 
Q(k&,) # 0. Hence, if Y. = M, and I y. I = m - 1, then Q( Fob) # 0. Moreover, 
if 
r 
I-Fj I = m - 1 for some j L 1, then &.-I is a matching containing q and so 
Q( rj) # 0. Thus, given y. = M,, Q( 5) # 0 whenever I 5 I = m - 1, for all 
j 
0. Therefore, given FO = A&, we have A(F) 2 (1 + (m - 1)X)-’ 2 
(1 + X I V]/2)-‘. 
Also, note that I E I 1 m for at least half of the values of j with 
O=jsS+- 
l.Thus, 
402 
G. H. SASAKI AND B. HAJEK 
1, 
where for the second inequality ,we used Lemma 9b and Jensen’s inequality, and 
for the last two inequalities we used the inequality exp(u) 2 1 + U. Therefore, 
foril 
E[ 
1 Zi+, 
1 - 
1 Zi 
1 1 ZO, - . * 9 zi]z(Rz>ii 
which implies that the process 
I & 
I - 
%$ 
1 
(2 - 
2 
* 
8z{Rz>ij 
IR,sil~ 
= 
i= 
4 z{R,>iJ, 
1,2,... 
is a submartingale uniformly bounded from above. Thus, by a version of Doob’s 
optional sampling theorem [3, theorem 7.4.6.iil 
E lZR,I -'1z-zl' 
which yields 
ER~I~E~ZR~I+I=~~*+~=(~/I+ 
I 
2 0, 
l=D3. 
Lemma 10, and hence Theorem 2, are completely proved. Cl 
4. Speculations 
We believe that Theorem 2 is true for constants ul and a2 much larger than what 
we provided in the proof and that ER is significantly smaller than the upper bound 
given in Theorem 3. Moreover, we conjecture that for 0 < r < 1, the average time 
needed for the controlled processes described in Section 2 to reach a matching 
having cardinality at least the maximum possible minus ] V ] ’ is not upper bounded 
by a polynomial in ] V 1, for some sequence of graphs. The key to proving stronger 
statements may be to keep track of the progress of many augmenting paths, instead 
of concentrating, as we have, on just one. 
The upper bound on ER given in Theorem 7 is valid for all graphs. Perhaps one 
can find a much smaller bound on ER by restricting attention to graphs G that are 
“typical” in some sense, or by considering a random graph. 
Our methods of analyzing simulated annealing, like the deterministic methods 
known for solving the maximum matching problem, do not easily carry over to 
“industrial 
strength” variations of the problem or to other problems. More work 
will be needed to evaluate the average time complexity of simulated annealing and 
other search heuristics for a wide range of problems. 
REFERENCES 
1. ANILY, S., AND FEDERGRUEN, A. Simulated annealing methods with general acceptance probabil- 
ities. J. Appl. Prob. 24 (1987), 657-667. 
2. CERNY, V. A thermodynamical approach to the traveling salesman problem: An efficient simu- 
lation algorithm. J. Optim. Theory Appl. 45 (1985), 41-51. 
3. CHOW, Y. S. AND TEICHER, H. Probability Theory: Independence, Interchangeability, Martingales. 
Springer-Verlag, New York, 1978. 
4. GELFAND, S. B., AND MITTER, S. K. Analysis of simulated annealing for optimization. 
In Proceedings of the 24th Conference on Decision and Control. IEEE, New York, 1985, pp. 
779-786. 
5. GREENE, J. W., AND SUPOWIT, K. J. Simulated annealing without rejected moves. IEEE Trans. 
Comput. Aided Des. 5 (1986), 221-228. 
Time Complexity of Maximum Matching 
6. HAJEK, B. Hitting time and occupation time bounds implied by drift analysis with applications. 
Adv. Appl. Probab. 14 (1982), 502-525. 
7. HAJEK, B. Cooling schedules for optimal annealing. Math. Oper. Res. 13 (Feb. 1988). 
8. HOPCROFT, J. E., AND KARP, R. M. An n ‘I2 algorithm for maximum matchings in bipartite 
graphs. SZAMJ. Cornput. 2 (1973), 225-231. 
9. KIRKPATRICK, S., GELETT, C. D., AND VECCHI, M. P. Optimization by simulated annealing. 
Science 220 (1983), 621-630. 
10. MICALI, S. AND VAZIRANI, V. V. An 0( a 
. 
1 E 1) algorithm for finding maximum matching 
in general graphs. In Proceedings of the 21st Annual Symposium on the Foundations of Computer 
Science. IEEE, New York, 1980, pp. 17-27. 
11. MITRA, D., ROMEO, F. AND SANGIOVANNI-VINCENTELLI, 
A. 
Convergence and finite-time behavior 
of simulated annealing. Adv. Appl. Probab. 18 ( 1986), 747-77 1. 
12. PAPADIMITRIOU, C. H., AND STEIGLITZ, K. Combinatorial Optimization: Algorithms and Com- 
plexity. Prentice Hall, Englewood Cliffs, N.J., 1982. 
13. VECCHI, M. P. AND KIRKPATRICK, 
S. Global wiring by simulated annealing. IEEE Trans. Comput. 
Aided Des. 2 (1983), 2 15-222. 
RECEIVED 
JULY 
1986; REVISED 
FEBRUARY 
1987; ACCEPTED 
Journal 
of the Association 
MAY 
1987 
for Computing 
Machinery, 
Vol. 
35, No. 2, April 
1988. 