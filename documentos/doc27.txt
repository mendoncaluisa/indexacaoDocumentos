See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/260346033
 Redes Definidas por Software: uma abordagem sistêmica para o
 desenvolvimento de pesquisas em Redes de Computadores
 Chapter · November 2014
 CITATIONS
 17
 5 authors, including:
 Dorgival Olavo Guedes
 Federal University of Minas Gerais
 161 PUBLICATIONS   1,652 CITATIONS   
SEE PROFILE
 Marcos Augusto M. Vieira
 Federal University of Minas Gerais
 185 PUBLICATIONS   2,986 CITATIONS   
SEE PROFILE
 All content following this page was uploaded by Dorgival Olavo Guedes on 16 May 2014.
 READS
 10,486
 Luiz Vieira
 Federal University of Minas Gerais
 153 PUBLICATIONS   4,737 CITATIONS   
SEE PROFILE
 Rafaela Natalia da Silva Nunes
 61 PUBLICATIONS   645 CITATIONS   
SEE PROFILE
 The user has requested enhancement of the downloaded file.
Cap´ ıtulo
 4
 Redes Definidas por Software:
 umaabordagem sistˆ emica para o desenvolvimento
 de pesquisas em Redes de Computadores
 Dorgival Guedes, Luiz Filipe Menezes Vieira, Marcos Menezes Vieira,
 Henrique Rodrigues e Rog´ erio Vinhal Nunes
 Abstract
 Software Defined Networks (SDN) are a new paradigm for the development of research
 in computer networks, which has been getting the attention of the academic community
 and the network industry. A lot of the attention so far has focused on the OpenFlow stan
dard, one of the elements which make this approach possible. However, Software Defined
 Networks go way beyond OpenFlow, creating new perspectives in terms of abstractions,
 control environments and network applications which can be developed easily and with
out the limitations of the current network technologies. This short course take a systemic
 approach to the topic, with theoretical and practical aspects. Considering the theory, we
 discuss the various components of a software-defined network system, including issues
 such as network element virtualization, the structure of the network operating system and
 its applications, as well as the challenges this new approach still has to face, and the on
going research efforts in Brazil and around the world. To illustrate the new development
 possibilities offered by the new paradigm, the practical part of the course focuses on the
 POXnetwork operating system, created with research and teaching in mind.
 Resumo
 Redes Definidas por Software (Software Defined Networks, ou SDN) constituem um novo
 paradigma para o desenvolvimento de pesquisas em redes de computadores que vem ga
nhando a atenc ¸˜ao de grande parte da comunidade acadˆemica e da ind´ustria da ´area.
 Muita da atenc ¸˜ao at´e o momento tem sido voltada para o padr˜ao OpenFlow, um dos ele
mentos que tornaram poss´ıvel esse enfoque. Entretanto, Redes Definidas por Software
 v˜ao al´em de OpenFlow, abrindo novas perspectivas em termos de abstrac¸˜oes, ambientes
 de controle e aplicac¸˜oes de rede que podem ser desenvolvidas de forma simples e livre
Minicursos Livro Texto
 161
 das limitac ¸˜oes das tecnologias de rede atuais. Este minicurso adota uma abordagem
 sistˆemica da ´area, com aspectos de teoria e pr´atica. Na parte te´orica, discutimos os di
versos componentes de um sistema de rede definido por software, incluindo soluc¸˜oes para
 virtualizac ¸˜ao dos elementos de rede, sistemas operacionais de rede e novas aplicac ¸˜oes,
 bem como os desafios de pesquisa que esse paradigma ainda precisa enfrentar e os di
versos esforc ¸os de pesquisa em andamento no Brasil e no mundo. Para ilustrar as novas
 possibilidades de desenvolvimento que o paradigma oferece, a parte pr´atica foca no sis
tema operacional de redes POX, desenvolvido especificamente para fins de pesquisa e
 ensino.
 4.1. Introduc¸˜ ao
 A comunidade de redes se encontra hoje em uma situac ¸˜ao complexa: o sucesso da ´ area
 pode ser considerado estrondoso, j´ a que hoje a tecnologia de redes de computadores per
meia todos os n´ ıveis da sociedade. A maioria das atividades da sociedade hoje de al
guma forma atravessa uma ou mais redes de computadores. A tecnologia est´ a nos lares,
 na forma de redes domiciliares, nas rotinas de implementac¸˜ao de pol´ ıticas p´ ublicas, na
 forma do governo eletrˆ onico, na educac ¸˜ao, onde a Web se tornou uma das fontes essenci
ais de informac ¸˜ ao para os estudantes nos diversos n´ ıveis. A Internet se tornou um artefato
 conhecido e acessado por uma frac ¸˜ao significativa da populac¸˜ao e iniciativas de inclus˜ ao
 digital s˜ ao desenvolvidas em diversas esferas com o objetivo de expandir seu alcance,
 idealmente a toda a populac ¸˜ ao mundial.
 Tamanho sucesso, entretanto, traz consigo um problema para a comunidade de
 pesquisa. Como grande parte da sociedade depende hoje da Internet em suas atividades
 do dia-a-dia e tecnologias de acesso `a rede se tornaram commodities de f´acil acesso, es
tabilidade se tornou uma caracter´ ıstica essencial da Internet. Isso significa que pesquisas
 com novos protocolos e tecnologias n˜ ao s˜ao mais poss´ ıveis na Internet em geral, devido
 ao risco de interrupc ¸˜ ao das atividades para as quais ela j´ a se tornou ferramenta essencial.
 N˜ao s´ o isso, mas tamb´ em a economia de escala poss´ ıvel pelo crescimento da rede e a
 larga adoc ¸˜ ao das tecnologias j´a desenvolvidas inviabiliza a inserc¸˜ ao de novas tecnologias
 que dependam de alterac ¸˜ oes do hardware a ser utilizado.
 Mesmo pesquisadores trabalhando em iniciativas como backbones de pesquisa
 b´asica, como a Internet2, se vˆ em frente a um problema complexo para justificar a adoc¸˜ ao
 em larga escala das tecnologias desenvolvidas nesses ambientes. O potencial de ruptura
 de tais avanc ¸os se torna um forte argumento contra sua adoc ¸˜ao.
 Esses problemas levaram diversos pesquisadores a afirmar que a arquitetura de
 redes de computadores em geral e a rede mundial (a Internet) atingiram um n´ ıvel de
 amadurecimento que as tornaram pouco flex´ ıveis. A express˜ao usada em muitos casos ´ e
 que a Internet est´ a calcificada (ossified, em inglˆes), referindo-se ao processo que substitui
 cartilagens (mais el´ asticas) por ossos ao longo do envelhecimento dos seres vivos.
 Para tentar contornar esse problema, a comunidade de pesquisa em Redes de
 Computadores tem investido em iniciativas que levem `a implantac¸˜ ao de redes com
 maiores recursos de programac ¸˜ao, de forma que novas tecnologias possam ser inse
ridas na rede de forma gradual. Exemplos de iniciativas desse tipo s˜ ao as propostas
 de redes ativas (active networks) [Tennenhouse and Wetherall 2007], de testbeds como
162
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 o PlanetLab [Peterson and Roscoe 2006] e, mais recentemente, do GENI [Turner 2006,
 Elliott and Falk 2009]. Redes ativas, apesar do seu potencial, tiveram pouca aceitac ¸˜ao
 pela necessidade de alterac ¸˜ ao dos elementos de rede para permitir que se tornassem pro
gram´aveis. Iniciativas mais recentes, como PlanetLab e GENI, apostam na adoc¸˜ ao de
 recursos de virtualizac¸˜ao para facilitar a transic ¸˜ ao para novas tecnologias. Apesar de se
rem consideradas de grande potencial no longo prazo, tais iniciativas ainda enfrentam
 desafios em quest˜ oes como garantir o desempenho exigido pelas aplicac ¸˜ oes largamente
 utilizadas hoje utilizando-se tais elementos de rede virtualizados.
 Uma outra forma de abordar o problema, a fim de oferecer um caminho de
 menor impacto e que possa ser implementado em prazos mais curtos e com bom de
sempenho, consiste em estender o hardware de encaminhamento de pacotes de forma
 mais restrita. Considerando-se que a operac ¸˜ao que precisa de alto desempenho nos
 elementos de comutac ¸˜ao atual ´ e o encaminhamento de pacotes, algumas iniciativa
 prop˜ oem manter essa operac ¸˜ ao pouco alterada, para manter a viabilidade de desen
volvimento de hardware de alto desempenho, mas com uma possibilidade de maior
 controle por parte do administrador da rede. Essa proposta se inspira em uma tec
nologia j´ a largamente adotada atualmente, o chaveamento (encaminhamento) base
ado em r´ otulos program´aveis, popularizado pelo MPLS (Multi-protocol Label Swit
ching) [Davie and Farrel 2008, Kempf et al. 2011].
 ComMPLS,ocontrole fino sobre o tr´afego de rede se torna poss´ ıvel ao se atribuir
 a cada pacote um r´ otulo (label) que determina como o mesmo ser´a tratado pelos elemen
tos de rede. Explorando esse recurso, administradores de rede podem exercer controle
 diferenciado sobre cada tipo de tr´ afego de rede, assumindo que os mesmos possam ser
 identificados para receberem r´ otulos apropriados. Com base nessa observac¸˜ao, uma ideia
 trabalhada por diversos pesquisadores ´e a manutenc ¸˜ao de um hardware de encaminha
mento de alto desempenho, com a possibilidade de permitir que o administrador de rede
 (ou o desenvolvedor de aplicac ¸˜ oes para a rede) determine como fluxos sejam rotulados e
 encaminhados.
 4.1.1. Origens
 A iniciativa mais bem sucedida nesse sentido foi, sem d´ uvida, a definic ¸˜ ao da interface e
 do protocolo OpenFlow [McKeown et al. 2008]. Com OpenFlow, os elementos de enca
minhamento oferecem uma interface de programac¸˜ ao simples que lhes permite estender o
 acesso e controle da tabela de consulta utilizada pelo hardware para determinar o pr´ oximo
 passo de cada pacote recebido. Dessa forma, o encaminhamento continua sendo eficiente,
 pois a consulta ` a tabela de encaminhamento continua sendo tarefa do hardware, mas a de
cis˜ ao sobre como cada pacote deve ser processado pode ser transferida para um n´ ıvel
 superior, onde diferentes funcionalidades podem ser implementadas. Essa estrutura per
mite que a rede seja controlada de forma estens´ ıvel atrav´es de aplicac ¸˜ oes, expressas em
 software. A esse novo paradigma, deu-se o nome de Redes Definidas por Software, ou
 Software Defined Networks (SDN).
 Do ponto de vista hist´ orico, SDNs tˆem sua origem na definic ¸˜ao da arquite
tura de redes Ethane, que definia uma forma de se implementar pol´ ıticas de con
trole de acesso de forma distribu´ ıda, a partir de um mecanismo de supervis˜ao centrali
Minicursos Livro Texto
 163
 zado [Casado et al. 2009]. Naquela arquitetura, cada elemento de rede deveria consultar
 o elemento supervisor ao identificar um novo fluxo. O supervisor consultaria um grupo
 de pol´ ıticas globais para decidir, com base nas caracter´ ısticas de cada fluxo, como o ele
mento de encaminhamento deveria trat´ a-lo. Essa decis˜ ao seria comunicada ao comutador
 na forma da programac ¸˜ao de uma entrada em sua tabela de encaminhamento com uma
 regra adequada para o novo fluxo (que poderia, inclusive, ser seu descarte). Esse modelo
 foi posteriormente formalizado por alguns dos autores na forma da arquitetura OpenFlow.
 4.1.2. Motivac¸˜ ao
 Desde seu surgimento, diversos pesquisadores da ´area de Redes de Computadores e em
presas voltadas para o desenvolvimento de equipamentos e sistemas de gerˆencia de redes
 tˆem voltado sua atenc¸˜ ao para o paradigma de Redes Definidas por Software (SDN). O
 Open Networking Summit, um encontro de pesquisadores e profissionais da ind´ ustria, or
ganizado recentemente pela Universidade de Stanford e a empresa Nicira, teve um n´ umero
 de participantes muito acima do esperado pelos organizadores, resultando em 250 inscri
tos e uma lista de espera de mais de 250 nomes. Outro indicador desse interesse ´e o
 n´ umero de publicac¸˜ oes em conferˆ encias da ´area que abordam algum elemento de Redes
 Definidas por Software. No SBRC 2011, por exemplo, mais de 10 trabalhos focaram
 aspectos da ´ area.
 Esse interesse se deve ` as diversas possibilidades de aplicac¸˜ao do paradigma, que se
 apresenta como uma forma potencial de implantac¸˜ao do que se convencionou denominar
 Internet do Futuro. Com a proposta de uma interface de programac¸˜ao para os elementos
 de comutac ¸˜ao da rede, como o padr˜ ao OpenFlow, fabricantes e pesquisadores abrac ¸aram a
 ideia de uma estrutura de redes onde a comutac ¸˜ ao de pacotes n˜ ao precisa mais ser definida
 pelo princ´ ıpio de roteamento de redes Ethernet ou IP, mas que pode ser controlado por
 aplicac ¸˜ oes (software) desenvolvido independentemente do hardware de rede. Al´em de um
 modelo de referˆencia de um comutador OpenFlow implementado como um processo de
 usu´ario e de uma implementac¸˜ ao de um comutador no espac ¸o do kernel para ambientes
 virtualizados, o Open vSwitch, diversos fabricantes j´a oferecem no mercado produtos que
 implementa a interface OpenFlow.
 Um aspecto importante ´e que Redes de Definidas por Software constituem um
 universo muito maior que aquele definido pelo padr˜ao OpenFlow. OpenFlow oferece,
 por exemplo, uma soluc ¸˜ ao simples para a criac ¸˜ao de diversas redes virtuais sobre uma
 infraestrutura f´ ısica, onde cada rede virtual ´e composta por switches n´ ıvel 2, roteadores
 e gateways de aplicac ¸˜ ao tradicionais. Mas o paradigma de Redes Definidas por Soft
ware tamb´ em abre a possibilidade de se desenvolver novas aplicac ¸˜ oes que controlem os
 elementos de comutac ¸˜ao de uma rede f´ ısica de formas impensadas no passado.
 Para se desenvolver essas novas aplicac¸˜ oes, ´ e importante se compreender a funcio
nalidade de controladores de rede (tamb´ em denominados Sistemas Operacionais de Rede
 ou Network Hypervisors). Esses elementos oferecem um ambiente de programac¸˜ao onde
 o desenvolvedor pode ter acesso aos eventos gerados por uma interface de rede que siga
 um padr˜ ao como OpenFlow e pode tamb´ em gerar comandos para controlar a infraestru
tura de chaveamento. Com esse ambiente, torna-se mais simples implementar pol´ ıticas
 de seguranc ¸a baseadas em n´ ıveis de abstrac ¸˜ ao maiores que enderec ¸os Ethernet ou IP, que
164
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 cubram todos os pontos de rede, por exemplo. Da mesma forma, com SDNs ´e poss´ ıvel
 implementar controladores de rede que implementem l´ ogicas de monitorac¸˜ ao e acompa
nhamento de tr´ afego mais sofisticadas, ou soluc ¸˜ oes que oferec¸am novas abstrac¸˜ oes para
 os usu´ arios da rede, como cada usu´ ario de um datacenter ter a vis˜ao de que todas as suas
 m´ aquinas est˜ao ligadas a um switch ´ unico e privado, independente dos demais.
 Este minicurso foi concebido tendo essas possibilidades em mente, com o ob
jetivo de oferecer aos alunos, pesquisadores e profissionais da ´area uma introduc¸˜ ao ao
 paradigma e ` as oportunidades que ele oferece. Para isso apresentar o POX, um controla
dor desenvolvido especificamente para o ambiente de pesquisa e ensino, com a proposta
 de ser facilmente extens´ ıvel e de f´ acil entendimento.
 4.1.3. Organizac ¸˜ ao do texto
 Com a motivac¸˜ao apresentada na sec ¸˜ao anterior em mente, este material est´a organizado
 nas seguintes sec ¸˜ oes:
 1. Introduc ¸˜ ao — esta sec ¸˜ao, cujo objetivo foi introduzir o tema de forma abstrada;
 2. Componentes de um sistema baseado em SDNs — apresenta uma definic¸˜ ao mais
 refinada do conceito de SDN, abordando os elementos normalmente identificados
 com oparadigma de forma a dar ao leitor uma vis˜ao geral do papel de cada compo
nente e das relac ¸˜ oes entre eles;
 3. Programac ¸˜ao dos elementos de rede — discute os requisitos m´ ınimos da interface
 de programac ¸˜ao, com foco principal na definic ¸˜ ao do modelo OpenFlow;
 4. Particionamento de recursos (virtualizac¸˜ ao) — detalha o conceito de slicing da rede
 e seu uso para permitir a implementac ¸˜ao de redes virtuais;
 5. Controladores de rede — aborda os principais projetos de controladores dispon´ ıveis
 para a implementac ¸˜ ao de SDNs;
 6. Aplicac ¸˜ oes — discute como o conceito de SDN pode ser aplicado a diferentes con
textos e lista iniciativas de pesquisa relacionadas no Brasil e no mundo;
 7. Desenvolvimento de sistemas utilizando POX — apresenta os detalhes da arquite
tura do controlador POX e os elementos principais para a programac ¸˜ao do mesmo;
 8. Desafios de pesquisa — discute desafios para a arquitetura SDN que devem ser
 abordados para viabilizar sua aplicac ¸˜ ao nos diversos contextos;
 9. Considerac ¸˜ oes finais — oferece um fechamento da discuss˜ ao, amarrando os diver
sos conceitos e pontos de vista apresentados.
 Ao final deste trabalho, esperamos que os participantes tenham uma vis˜ ao das possibili
dades da ´area e um entendimento de como um controlador como POX pode ser utilizado
 para colocar em pr´atica diferentes ideias.
Minicursos Livro Texto
 165
 4.2. Componentes de um sistema baseado em SDNs
 Combasenadiscuss˜ao anterior, de forma abstrata, podemos dizer que uma Rede Definida
 por Software (SDN) ´e caracterizada pela existˆencia de um sistema de controle (software)
 que podecontrolar o mecanismodeencaminhamentodoselementosdecomutac ¸˜ ao da rede
 por uma interface de programac¸˜ao bem definida. De forma mais espec´ ıfica, os elementos
 de comutac ¸˜ ao exportam uma interface de programac ¸˜ao que permite ao software inspeci
onar, definir e alterar entradas da tabela de roteamento do comutador como ocorre, por
 exemplo, com comutadores OpenFlow. O software envolvido, apesar de potencialmente
 poder ser uma aplicac¸˜ ao monol´ ıtica especialmente desenvolvida, na pr´atica tende a ser or
ganizado com base em um controlador de aplicac¸˜ao geral, em torno do qual se contr´ oem
 aplicac ¸˜ oes espec´ ıficas para o fim de cada rede. ´ E poss´ ıvel, ainda, utilizar-se um divisor de
 vis˜ oes para permitir que as aplicac¸˜ oes sejam divididas entre diferentes controladores. A
 f
 igura 4.1 ilustra essa organizac ¸˜ ao, para uma rede com elementos com e sem fio.
 Divisor
 Figura 4.1. Estrutura geral de uma SDN
 4.2.1. Elementos de comutac ¸˜ ao program´ aveis
 Obviamente, o princ´ ıpio b´asico de redes definidas por software ´e possibilidade
 de programac¸˜ ao dos elementos de rede. Como mencionado anteriormente, essa
 programac ¸˜ ao, ao contr´ ario de propostas anteriores, como Redes Ativas, se restringe a
 uma manipulac ¸˜ ao simples de pacotes baseado no conceito de fluxos, ou seja, sequˆencias
 de pacotes que compartilham atributos com valores bem definidos. A definic ¸˜ ao exata
 do que constitui um fluxo ´ e func¸˜ ao exatamente dos recursos oferecidos pela interface de
 programac ¸˜ ao.
 Aoperac¸˜ao de encaminhamento dos elementos de comutac ¸˜ ao em redes baseadas
 em pacotes segue um princ´ ıpio simples: cada pacote recebido em uma das interfaces do
 comutador ´e inspecionado e gera uma consulta `a tabela de encaminhamento do comu
tador. No caso de switches Ethernet, essa consulta ´ e baseada no enderec¸o de hardware
 (MAC) de destino do pacote; em roteadores IP, em um prefixo do enderec ¸o IP de destino;
 em redes ATM, nos valores dos campos VCI/VPI da c´ elula ATM, etc. Caso a consulta
 n˜ao tenha sucesso, o pacote ´e descartado. Usualmente, h´ a ainda a possibilidade de se de
f
 inir um comportamento padr˜ ao (default) nos casos de insucesso. Uma vez identificado o
166
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 destino do pacote, o mesmo atravessa as interconex˜ oes internas do comutador para atingir
 a porta de destino, onde ela ´ e enfileirada para transmiss˜ ao.
 Aolongo da evoluc ¸˜ao das redes de computadores, esse processo de consulta (loo
kup) e chaveamento (switching) j´ a foi amplamente estudado, resultando hoje em soluc¸˜ oes
 baseadas usualmente em hardware com desempenho suficiente para acompanhar as taxas
 de transmiss˜ ao do meio (wire speed switching).
 4.2.2. Divisores de recursos/vis˜ oes
 Apossibilidade de se associar todo um processamento complexo, definido por software, a
 pacotes que se encaixem em um determinado padr˜ao abriu a possibilidade de se associar
 diversos comportamentos em uma mesma rede. Tornou-se vi´ avel, por exemplo, manter
 um comportamento tradicional para fluxos denominados “de operac¸˜ ao” e dar tratamento
 diferente para fluxos “de pesquisa”. Uma nova possibilidade, imediatamente identificada
 por pesquisadores, ´ e a de estender essa divis˜ ao para permitir que diferentes tipos de pes
quisa sejam colocados em operac¸˜ ao em paralelo, na mesma rede f´ ısica. Para isso, seria
 necess´ario estender o modelo com a noc¸˜ao de vis˜ oes diferentes da rede, dividindo os
 recursos entre diferentes controladores.
 Estendendo o modelo de comportamento dos elementos de chaveamento, basea
dos em consultas usando campos do pacote, o processo de divis˜ao de recursos se baseia
 exatamente em definir partic¸˜ oes do espac¸o de consulta dispon´ ıvel. Isso pode ser visto
 como umaextens˜ ao do princ´ ıpio de particionamento baseado em padr˜ oes parciais: alguns
 dos bits usados no processo de consulta s˜ao utilizados para definir espac ¸os que devem
 ser tratados de forma isolada. Essa pr´atica ´e basicamente uma extens˜ ao do princ´ ıpio de
 particionamento do tr´ afego Internet baseado em n´ umero de porto, por exemplo.
 4.2.3. Controlador
 Umavezdefinida umainterface de programac ¸˜ao para os elementos de chaveamento, seria
 poss´ ıvel desenvolver uma aplicac ¸˜ao que utilizasse diretamente as chamadas dessa inter
face para controlar cada switch separadamente. Entretanto, esse enfoque traz limitac ¸˜ oes
 semelhantes `aquelas associadas ao desenvolvimento de software diretamente ligado a um
 elemento de hardware: o desenvolvimento exige que o programador lide com tarefas de
 baixo n´ ıvel na interface com o dispositivo e o sofware resultante ´e normalmente muito
 dependente do hardware adotado. Novos desenvolvimentos exigem que todas as funcio
nalidades de baixo n´ ıvel sejam reimplementadas.
 Essas limitac ¸˜ oes levaram `a identificac ¸˜ao da necessidade de um novo n´ ıvel na
 arquitetura, que concentre as tarefas de manipulac¸˜ao direta dos dispositivos de rede e
 oferec ¸a uma abstrac ¸˜ ao de mais alto n´ ıvel para o desenvolvedor. Esse elemento, talvez
 mais que a arquitetura OpenFlow, define a natureza de uma rede definida por software.
 Em uma analogia direta das funcionalidades de um sistema operacional, esse elemento
 age como um sistema operacional para a rede: provendo o controle direto dos dispositi
vos de rede, oferecendo uma interface mais eficiente para os desenvolvedores, isolando
 os detalhes de cada componente.
 O controlador de rede, ou sistema operacional de rede, ou, ainda, hypervisor da
 rede (em alus˜ao ao conceito derivado da area de sistemas virtualizados) pode, dessa
Minicursos Livro Texto
 167
 forma, concentrar a comunicac¸˜ ao com todos os elementos program´aveis que comp˜ oem
 a rede e oferecer uma vis˜ao unificada do estado da rede [Casado et al. 2010b]. Sobre
 essa vis˜ao, comandos podem ser executados e outros programas podem ser desenvolvidos
 que implementem novas funcionalidades. Um dos pontos fortes de SDNs ´e exatamente a
 formac¸˜ ao dessa vis˜ao centralizada das condic¸˜ oes da rede, sobre a qual ´e poss´ ıvel desen
volver an´alises detalhadas e chegar a decis˜ oes operacionais sobre como o sistema como
 um todo deve operar. A existˆ encia dessa vis˜ao global simplifica a representac ¸˜ ao dos pro
blemas e a tomada de decis˜ao, bem como a express˜ao das ac ¸˜ oes a serem tomadas.
 ´
 E importante observar que essa noc ¸˜ao de vis˜ao ´ unica e centralizada da rede como
 expressa pelo sistema operacional da rede ´ e uma vis˜ ao l´ ogica. N˜ ao necessariamente exige
 que o controlador opere como um elemento concentrador, fisicamente localizado em um
 ponto ´ unico do sistema. A abstrac ¸˜ao de vis˜ ao global pode muito bem ser implementada de
 forma distribu´ ıda, seja pela divis˜ ao dos elementos da vis˜ao entre dom´ ınios diferentes, seja
 pela implementac¸˜ao de um controlador realmente distribu´ ıdo, que se valha de algoritmos
 de consenso, por exemplo, para manter a vis˜ ao consistente entre suas partes.
 Diferentes tipos de controladores de rede j´ a foram desenvolvidos dentro do con
texto de redes definidas por software. Muitos deles se apresentam como ambientes
 de tempo de execuc¸˜ ao (run-time systems) que oferecem uma interface imperativa para
 programac ¸˜ ao da rede. A linguagem utilizada, nesse caso, determina em grande parte o
 estilo de desenvolvimento e as funcionalidades oferecidas. Outros controladores, entre
tanto, ultrapassam a noc ¸˜ao de uma interface de programac ¸˜ ao imperativa e oferecem novas
 abstrac ¸˜ oes, como um ambiente de programac ¸˜ao funcional ou declarativa. Nesses casos,
 os recursos da linguagem utilizada se prestam ` a implementac ¸˜ ao de novas funcionalidades,
 como detecc ¸˜ ao de conflitos ou depurac ¸˜ao automatizada da rede.
 Muitos controladores j´ a implementados, desenvolvidos sem a preocupac¸˜ao b´ asica
 de escalabilidade frente a grandes demandas, optam pela estrutura centralizada por sim
plicidade. Por outro lado, alguns dos esforc¸os de desenvolvimento voltados para a
 implantac ¸˜ao em grandes sistemas, como os datacenters de grandes corporac¸˜ oes, utili
zam diferentes formas de distribuic ¸˜ao para garantir a escalabilidade e disponibilidade do
 sistema.
 4.2.4. Aplicac ¸˜ oes de rede
 Nesse contexto, considerando os controladores de SDN como o sistema operacional da
 rede, o software desenvolvido para criar novas funcionalidades pode ser visto com a
 aplicac ¸˜ao que executa sobre a rede f´ ısica. Valendo-se da vis˜ao unificada dos recursos
 de rede que o controlador oferece, pode-se, por exemplo, implementar soluc¸˜ oes de rotea
mento especialmente desenhadas para um ambiente particular, controlar a interac ¸˜ ao entre
 os diversos comutadores, oferecendo para os computadores a eles ligados a impress˜ao de
 estarem ligados a um ´ unico switch, ou a um ´ unico roteador IP.
 4.3. Programac¸˜ ao dos elementos de rede
 O princ´ ıpio por tr´ as de Redes Definidas por Software ´e a capacidade de se controlar o
 plano de encaminhamento de pacotes atrav´ es de uma interface bem definida. Sem d´ uvida,
 a interface associada ao paradigma desde seu in´ ıcio (de fato, um dos elementos motivado
168
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 res da sua criac ¸˜ ao) ´e OpenFlow, apesar de n˜ ao ser a ´ unica forma de se implementar uma
 SDN.
 4.3.1. O padr˜ ao OpenFlow
 OOpenFlow ´ e um padr˜ ao aberto para Redes Definidas por Software que tem como prin
cipal objetivo permitir que se utilize equipamentos de rede comerciais para pesquisa e
 experimentac ¸˜ao de novos protocolos de rede, em paralelo com a operac¸˜ao normal das
 redes. Isso ´e conseguido com a definic ¸˜ ao de uma interface de programac¸˜ao que permite
 ao desenvolvedor controlar diretamente os elementos de encaminhamento de pacotes pre
sentes no dispositivo. Com OpenFlow, pesquisadores podem utilizar equipamentos de
 rede comerciais, que normalmente possuem maior poder de processamento que os comu
tadores utilizados em laborat´ orios de pesquisa, para realizar experimentos em redes “de
 produc¸˜ao”. Isso facilita a transferˆencia dos resultados de pesquisa para a ind´ ustria.
 Uma caracter´ ıstica b´asica do modelo OpenFLow ´e uma separac¸˜ ao clara entre os
 planos de dados e controle em elementos de chaveamento. O plano de dados cuida do
 encaminhamento de pacotes com base em regras simples (chamadas de ac¸˜ oes na termino
logia OpenFlow) associadas a cada entrada da tabela de encaminhamento do comutador
 de pacotes (um switch ou roteador). Essas regras, definidas pelo padr˜ ao, incluem (i)
 encaminhar o pacote para uma porta especifica do dispositivo, (ii) alterar parte de seus
 cabec¸alhos, (iii) descart´ a-lo, ou (iv) encaminh´a-lo para inspec¸˜ao por um controlador da
 rede. Em dispositivos dedicados, o plano de dados pode ser implementado em hardware
 utilizando os elementos comuns a roteadores e switches atuais. J´ a o m´ odulo de controle
 permite ao controlador da rede programar as entradas dessa tabela de encaminhamento
 com padr˜ oes que identifiquem fluxos de interesse e as regras associadas a eles. O ele
mento controlador pode ser um m´ odulo de software implementado de forma independente
 em algum ponto da rede.
 4.3.1.1. Estrutura e Possibilidades
 Umgrande trunfo da arquitetura OpenFlow ´ e a flexibilidade que ela oferece para se pro
gramar de forma independente o tratamento de cada fluxo observado, do ponto de vista de
 como o mesmo deve (ou n˜ ao) ser encaminhado pela rede. Basicamente, o padr˜ao Open
Flow determina como um fluxo pode ser definido, as ac¸˜ oes que podem ser realizadas
 para cada pacote pertencente a um fluxo e o protocolo de comunicac¸˜ao entre comutador
 e controlador, utilizado para realizar alterac ¸˜ oes dessas definic¸˜ oes e ac¸˜ oes. A uni˜ ao de
 uma definic¸˜ ao de fluxo e um conjunto de ac¸˜ oes forma uma entrada da tabela de fluxos
 OpenFlow [McKeown et al. 2008].
 Em um switch OpenFlow, cada entrada na tabela de fluxos pode ser implemen
tada como um padr˜ ao de bits representado em uma mem´ oria TCAM (Ternary Content
Addressable Memory). Nesse tipo de mem´ oria, bits podem ser representados como zero,
 umou“n˜ao importa” (don’t care), indicando que ambos os valores s˜ ao aceit´ aveis naquela
 posic¸˜ ao. Como o padr˜ ao ´e programado a partir do plano de controle, fluxos podem ser
 definidos da forma escolhida pelo controlador (p.ex., todos os pacotes enviados a par
tir do enderec ¸o f´ ısico A para o enderec ¸o f´ ısico B, ou todos os pacotes TCP enviados da
Minicursos Livro Texto
 169
 m´ aquina com enderec¸o IP X para o porto 80 da m´ aquina com enderec¸o IP Y). A figura 4.2
 apresenta uma vis˜ao geral de uma entrada da tabela OpenFlow. Cada pacote que chega
 a um comutador OpenFlow ´e comparado com cada entrada dessa tabela; caso um casa
mento seja encontrado, considera-se que o pacote pertence ` aquele fluxo e aplica-se as
 ac¸˜ oes relacionadas ` a esse fluxo. Caso um casamento n˜ao seja encontrado, o pacote ´e en
caminhado para o controlador para ser processado — o que pode resultar na criac ¸˜ao de
 uma nova entrada para aquele fluxo. Al´ em das ac ¸˜ oes, a arquitetura prevˆe a manutenc ¸˜ao
 de trˆ es contadores por fluxo: pacotes, bytes trafegados e durac ¸˜ ao do fluxo. Esses contado
res s˜ao implementados para cada entrada da tabela de fluxos e podem ser acessados pelo
 controlador atrav´ es do protocolo.
 Figura 4.2. Exemplo de uma entrada na tabela de fluxos OpenFlow.
 Esse pequeno conjunto de regras cria diversas possibilidades, pois muitas das fun
cionalidades que s˜ ao implementadas separadamente podem ser agrupadas em um ´ unico
 controlador OpenFlow, utilizando um pequeno conjunto de regras. Alguns exemplos das
 possibilidades s˜ ao apresentadas na figura 4.3. As entradas representam o uso do switch
 OpenFlow para realizar encaminhamento de pacotes na camada de enlace, implemen
tar um firewall e realizar encaminhamento de pacotes na camada de enlace utilizando
 VLANs, respectivamente.
 Figura 4.3. Exemplos de uso de um Switch OpenFlow.
 Apesar de possuir um conjunto pequeno de ac¸˜ oes simples, alguns descrevem o
 OpenFlow com uma analogia ao conjunto de instruc ¸˜ oes de um microprocessador x86
 que, apesar de pequeno e simples, provˆe uma vasta gama de possibilidades para o desen
volvimento de aplicac ¸˜ oes. O OpenFlow cria possibilidades semelhantes para o desenvol
vimento de aplicac ¸˜ oes no contexto de redes de computadores.
170
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 4.3.1.2. Limitac ¸˜ oes e futuras vers˜ oes
 Avers˜ao atual do OpenFlow ´e a 1.1, que ainda possui algumas limitac ¸˜ oes em termos do
 uso do padr˜ ao em circuitos ´ opticos e uma definic¸˜ ao de fluxos que englobe protocolos que
 n˜ao fazem parte do modelo TCP/IP. No entanto, a vers˜ao 2.0 est´ a sendo formulada e um
 dos objetivos ´e eliminar algumas dessas limitac ¸˜ oes.
 Alguns switches comerciais j´a suportam o padr˜ ao OpenFlow, como ´ e o caso do HP
 Procurve 5400zl, do NEC IP880 e do Pronto 3240 e 3290. Espera-se que ` a medida que a
 especificac ¸˜ao OpenFlow evolua, mais fabricantes de equipamentos de rede incorporem o
 padr˜ao `as suas soluc ¸˜ oes comerciais.
 4.3.2. Implementac ¸˜ oes em software
 Aimplementac¸˜ ao de referˆencia do modelo OpenFlow ´e um comutador em software, exe
cutando no espac¸o de usu´ario em uma m´ aquina Linux. Esse modelo tem sido utilizado
 como base em diversos experimentos, mas carece de um melhor desempenho. Desen
volvido para suprir essa lacuna, o Open vSwitch (OvS) ´e um switch virtual que segue a
 arquitetura OpenFlow, implementado em software, com o plano de dados dentro do kernel
 do sistema operacional Linux, enquanto o plano de controle ´e acessado a partir do espac¸o
 de usu´ario [Pfaff et al. 2009]. Em particular, essa implementac¸˜ao foi desenvolvida espe
cificamente para controlar o tr´afego de rede da camada de virtualizac¸˜ ao em ambientes
 virtualizados [Pettit et al. 2010].
 Em sua implementac ¸˜ao atual (figura 4.4), o Open vSwitch ´e composto por dois
 componentes principais: um m´ odulo presente no n´ ucleo do sistema operacional, deno
minado “Fast Path”, e um componente no n´ ıvel de usu´ario, o “Slow Path”. O fast path
 interage ativamente com o tr´afego de rede, pois ´ e respons´avel por procurar rotas na tabela
 de fluxos e encaminhar pacotes de rede. J´a o slow path ´e o componente do Open vSwitch
 onde s˜ ao implementadas as demais funcionalidades associadas ao plano de controle, como
 as interfaces de configurac ¸˜ao do switch, a l´ ogica de uma ponte com aprendizado (learning
 bridge) e as funcionalidades de gerˆ encia remota, etc. A interac¸˜ao entre os dois m´ odulos
 se d´ a prioritariamente atrav´es da manipulac ¸˜ ao da tabela de fluxos.
 Figura 4.4. Arquitetura do Open vSwitch.
 Aimplementac ¸˜ao do fast path ´e simples e seu c´ odigo ´ e composto por poucas linhas
Minicursos Livro Texto
 171
 (em torno de 3000 —umn´ umerodelinhas bempequenoquandocomparado `as 30.000 do
 slow path). Existem dois motivos para essa decis˜ao de projeto, sendo que o primeiro deles
 ´
 e o desempenho. O fast path ´ e a parte cr´ ıtica do sistema quando consideramos o tempo
 de processamento e, portanto, quanto menor o processamento realizado para cada pacote,
 maior a capacidade de processamento desse componente. Essa caracter´ ıstica torna indis
pens´avel a sua implementac¸˜ao como uma parte do sistema operacional, posicionando-o
 mais pr´ oximo ` as NICs. Al´ em disso, como a l´ ogica implementada pelo fast path ´e de
pendente das APIs do sistema operacional, manter a sua complexidade pequena facilita
 a tarefa de portar o Open vSwitch a um outro sistema operacional. O segundo motivo ´ e
 o esforc ¸o reduzido em adaptar as funcionalidades do fast path ` a acelerac ¸˜ao de hardware
 (hardware acceleration/offoading), que eventualmente pode ser oferecida pela m´aquina
 f´ ısica.
 Al´ em de oferecer as funcionalidades da arquitetura OpenFlow, o OvS, na sua
 configurac ¸˜ao padr˜ ao, opera como um switch Ethernet normal. Para simplificar a sua
 integrac ¸˜ ao com o kernel Linux, o OvS emula as interfaces de rede daquele sistema e uti
liza partes do c´ odigo fonte de seu m´ odulo bridge, que implementa o switch de rede padr˜ao
 do Linux. Como resultado dessas decis˜ oes de projeto, o Open vSwitch pode ser utilizado
 como um substituto imediato para os switches virtuais adotados pelos VMMs baseadas
 em Linux mais utilizados atualmente, como Xen, XenServer e KVM e vem sendo ado
tado como o switch padr˜ ao em diversas distribuic¸˜ oes, mesmo quando as funcionalidades
 da arquitetura OpenFlow n˜ ao s˜ ao utilizadas.
 4.3.3. Outras propostas
 Apesar do foco principal dos ambientes de Redes Definidas por Software hoje ser o mo
delo/protocolo OpenFlow e a forma como ele exp˜ oe os recursos do switch, h´a outras
 possibilidades de implementac ¸˜ao de uma interface de programac¸˜ao que atenda os obje
tivos do paradigma. O paradigma SDN n˜ ao se limita ao OpenFlow, nem o exige como
 elemento essencial.
 Aforma como comutadores MPLS podem ser programados para tratar cada fluxo
 combasenor´ otulo a ele associado mostram queessatecnologia pode ser facilmente esten
dida para a implantac¸˜ ao de uma SDN [Davie and Farrel 2008]. Uma primeira iniciativa
 nesse sentido utiliza o princ´ ıpio da interface definida por OpenFlow sobre o comporta
mento usual de roteadores MPLS [Kempf et al. 2011]. Nesse caso, os autores estendem
 o modelo da tabela de encaminhamento do plano de dados de OpenFlow para incluir a
 noc¸˜ ao de porto virtual. Esse tipo de porto virtual armazena internamente as noc¸˜ oes de en
capsulamento e desencapsulamento necess´ arios ao processamento de pacotes com MPLS.
 Umasegunda proposta ´ e o conceito de interface de rede sNICh [Ram et al. 2010].
 Originalmente, sNICh foi apresentado como uma proposta para uma nova arquitetura de
 rede para ambientes virtualizados, onde a divis˜ao do plano de dados ´e feita de forma a
 dividir as tarefas de encaminhamento entre o host e a interface de rede. Essa divis˜ao visa
 garantir a eficiˆ encia do encaminhamento entre m´ aquinas virtuais no mesmo hospedeiro e a
 rede. Por se apresentar como uma opc¸˜ ao para o uso de switches de software como o Open
 vSwitch, mantendo uma estrutura program´avel, ´e poss´ ıvel se imaginar que a interface
 definida para essa arquitetura tamb´em possa ser usada para o controle de roteamento a
172
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 partir de um m´ odulo de software como um controlador SDN.
 Finalmente, h´ a tamb´ em propostas para novas implementac¸˜ oes que alteram a di
vis˜ao de tarefas entre controlador e os switches, como no caso da arquitetura Devo
Flow [Mogul et al. 2010]. O argumento dos autores ´e que no padr˜ ao OpenFlow tradicio
nal, a necessidade de que todos os fluxos sejam acess´ ıveis para o controlador SDN imp˜ oe
 demandas sobre o hardware e limitac¸˜ oes de desempenho que podem n˜ ao ser aceit´ aveis em
 alguns casos, em particular para fluxos de alto desempenho e que podem ser definidos por
 regras simples. Dessa forma, DevoFlow reduz o n´ umero de casos em que o controlador
 precisa ser acionado, aumentando a eficiˆencia. Muitas das soluc ¸˜ oes propostas para essa
 arquitetura, inclusive, podem ser aplicadas diretamente em implementac¸˜ oes OpenFlow
 tradicionais. Um exemplo disso ´e a adoc ¸˜ ao de regras espec´ ıficas (sem o uso de coringas,
 como todos os elementos de identificac ¸˜ao do fluxo instanciados para o fluxo particular a
 ser tratado) para cada fluxo que seja identificado pelo controlador.
 4.4. Particionamento de recursos (virtualizac ¸˜ ao)
 Redes definidas por software, ao definirem uma forma flex´ ıvel de se alterar a funcionali
dade da rede, abriram espac ¸o para que pesquisadores e desenvolvedores usassem a rede
 como ambiente de testes. Entretanto, ao se conectar os elementos de comutac¸˜ ao de uma
 rede a um controlador ´ unico, a capacidade de se desenvolver e instalar novas aplicac¸˜ oes
 na rede fica restrita ao respons´ avel por aquele controlador. Mesmo que o acesso a esse
 elemento seja compartilhado entre diversos pesquisadores, ainda h´a a quest˜ ao da garantia
 de n˜ao-interferˆencia entre as diversas aplicac ¸˜ oes e a restric¸˜ ao de que todos devem utilizar
 a mesma interface, sem opc ¸˜ oes.
 Para se resolver esse problema, surgiu a demanda pela capacidade de se poder
 dividir a rede em fatias (slices) e atribuir cada fatia a um controlador diferente. Uma
 forma de se fazer esse tipo de divis˜ao de recursos de rede em contextos usuais ´e atrav´es
 do uso de VLANs(redes locais virtuais), onde um cabec ¸alho especial ´ e usado para definir
 que cada pacote pertenc¸a a uma rede virtual particular. O uso de VLANs, entretanto, tem
 suas pr´ oprias limitac ¸˜ oes e est´a amarrado em sua definic ¸˜ ao ` a tecnologia Ethernet (ou IEEE
 802.x). Essa amarrac¸˜ao torna complexo sua aplicac¸˜ao em contextos onde as fatias devem
 se estender por mais de uma tecnologia de rede.
 Considerando a analogia de que o controlador de SDN se assemelha a um sis
tema operacional da rede, uma forma de se implementar fatias na rede seria lanc ¸ando
 m˜ ao do princ´ ıpio de virtualizac ¸˜ ao. Dessa forma, os recursos da rede seriam virtuali
zados e apresentados de forma isolada para cada desenvolvedor que desejasse ter seu
 pr´ oprio controlador sobre a rede. Como no caso da virtualizac¸˜ ao de m´ aquinas f´ ısicas, a
 virtualizac ¸˜ ao tamb´ em pode ser implementada sobre a rede f´ ısica em diversos n´ ıveis, por
 exemplo, abaixo do controlador ou acima do mesmo, como nos casos de virtualizac ¸˜ ao do
 hardware ou virtualizac ¸˜ ao do sistema operacional.
 A primeira soluc¸˜ao a ganhar larga aplicac ¸˜ ao em SDNs foi a divis˜ao di
reta dos recursos OpenFlow da rede f´ ısica (virtualizac¸˜ao do hardware), atrav´es do
 FlowVisor [Sherwood et al. 2009, Sherwood et al. 2010]. Nessa soluc ¸˜ ao, o FlowVisor
 opera como um controlador de rede respons´avel apenas pela divis˜ ao do espac¸o de
 enderec ¸amento dispon´ ıvel na rede OpenFlow. Fatias da rede s˜ ao definidas pela uni˜ao,
Minicursos Livro Texto
 173
 intersec ¸˜ ao e/ou diferenc ¸a de valores dos diversos campos dispon´ ıveis para identificac ¸˜ao
 de fluxos OpenFlow, conforme ilustrado na figura 4.5. A definic¸˜ ao dessas fatias contituem
 regras, as quais definem as pol´ ıticas de processamento.
 Figure 2: We present a monitoring program that graphically displays flows in real time in their respective network slice. Slices are
 defined by union, intersection, and difference of 10 packet fields—three of which are shown here.
 Figura 4.5. FlowVisor: definic ¸˜ ao de fatias com base em trˆ es atributos de fluxos.
 Nafigura, odom´ınio bicasting handover corresponde aumconjuntodefinidopor
 uma faixa de enderec ¸os MAC e uma faixa de enderec¸os IP; mobile VMs engloba
 todos os pacotes com uma certa faixa de n´umeros de porto, exceto se contidos
 na faixa de bicasting handover; finalmente, hard handover engloba dois con
juntos com enderec¸os IP e MAC em faixas, exceto nos casos em que os portos
 correspondem ` a faixa de moble VMs.
 aspects orthogonal. This allows each technology to evolve
 independently, avoiding new forms of ossification.
 We believe that our demonstration highlights these architectural
 To visualize our four experiments, we display a custom slice
 monitoring tool running on a large screen (Figure 2). The tool
 dynamically shows in real time the test-bed topology and color
coded flows from each experiment . The monitoring tool displays
 a simultaneous view of the entire physical network topology (Fig
ure 2,bottom layer) and the virtual topology corresponding to each
 game software remain unchanged; an OpenFlow controller
 performs dynamic re-writing of the traffic so that connectiv
ity is maintained. This experiment’s slice is defined as all
 game traffic on a specific UDP port. This experiment won
 the SIGCOMM 2008 Best Demo award [1].
 Uma instˆancia de FlowVisor se coloca entre os diversos controladores e os dis
positivos f´ ısicos. Comandos dos controladores s˜ ao observados para se certificar que as
 regras por eles geradas n˜ ao excedam a definic¸˜ ao do dom´ ınio daquele controlador na rede.
 Se necess´ ario, elas s˜ao re-escritas para estender os padr˜ oes utilizados com a definic ¸˜ ao do
 dom´ ınio. Por outro lado, mensagens enviadas pelos switches OpenFlow s˜ ao inspeciona
das e direcionadas para o controlador OpenFlow apropriado em func ¸˜ao do seu dom´ ınio
 de origem. A figura 4.6 ilustra esse processo. Como um controlador, ´ e poss´ ıvel inclusive
 a construc ¸˜ao de hierarquias de FlowVisors, cada um dividindo uma sec ¸˜ ao de um dom´ ınio
 definido por uma instˆ ancia de um n´ ıvel anterior.
 Hard Handover mobility agent This OpenFlow controller man
ages apair of mobilelaptops running at Stanford. Wedemon
strate that with OpenFlow, it is possible to re-route flows dy
namically and seamlessly hand-off between an 802.11 access
 point and a WiMAX base station. Hard handover’s network
 slice is defined as the packets destined to the MAC addresses
 of the mobile laptops. To visualize the effect of the handover,
 we display a video streamed to the laptops.
 We further demonstrate that FlowVisor has flexible and fine
grained network slices control. These slices can be recursively
 delegated (Figure 1). In our demonstration, Bob delegates a net
work slice to Alice, who in turn re-delegates it to the Bicast ex
periment. Further, FlowVisor allows slices to be defined along
 any combination of ten packet header fields (Figure 2), includ
ing physical layer (switch ports), link layer (src/dst mac addresses,
 ether type), network layer (src/dst IP address, IP protocol), and
 transport layer (src/dst UDP/TCP ports). Additionally, FlowVisor
 slices can be defined with negation (“all packets but TCP packets
 with dst port 80”), unions (“ethertype is ARP or IP dst address is
 255.255.255.255”), or intersections (“netblock 192.168/16 and IP
 protocol is TCP”). We believe that such fine-grained slicing will be
 Flowvisor, entretanto, ´e apenas uma das formas poss´ ıveis de se dividir os recurso
 f´ ısicos de uma SDN. Tamb´em ´ e poss´ ıvel dotar o controlador de recurso de particiona
mento de recursos, apesar dessa soluc¸˜ao ser menos adotada at´ e o momento. Al´em disso,
 o conceito de virtualizac¸˜ao tamb´em pode ser aplicado aos elementos de rede vis´ ıveis para
 as aplicac¸˜ oes. Por exemplo, um controlador pode organizar certas portas de um con
junto de portas espalhadas por diversos comutadores da rede f´ ısica subjacente e oferecer
 a vis˜ ao para a aplicac¸˜ao SDN de um ´ unico switch, onde as diversas portas estejam “di
retamente” interligadas. Esse tipo de abstrac ¸˜ao pode ser ´ util, por exemplo, para oferecer
 dom´ ınios de isolamento de tr´afego (apenas as portas pertencentes a tal switch virtual es
tariam no mesmo dom´ ınio de broadcast Ethernet, por exemplo. Esse tipo de aplicac¸˜ ao de
 virtualizac ¸˜ ao ´ e previsto, por exemplo, para o controlador POX, apesar de ainda n˜ao estar
 Bicasting mobility agent Setup similarly to hard handover, this
 controller manages the traffic for a second pair of mobile
 laptops. In this experiment, we demonstrate the effect of
 bi-casting, i.e., duplicating packets along two independent
 links. To visualize the effects of bicasting, we display a video
 streaming to the laptops.
 4. REFERENCES
 [1] D. Erickson et al. A demonstration of virtual machine
 mobility in an OpenFlow network. In Proceedings of ACM
 SIGCOMM(Demo), page 513, Seattle, WA, Aug. 2008.
 [2] K. Greene. Special reports 10 emerging technologies 2009.
174
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 %	
&
 %
 ! " # $	!
 Figura 4.6. FlowVisor: organizac¸˜ ao do sistema e fluxo de comandos. Um co
mando de inserc ¸˜ ao de regra originado em uma aplicac ¸˜ ao do dom´ınio A passa
 pelo FlowVisor, que traduz a regra para garantir que ela se aplique apenas ao
 dom´ınio de A. Um pacote encaminhado por um switch OpenFlow para o contro
lador ´ e processado pelo demultiplexador para identificar qual o controlador do
 n´ıvel acima que ´ e repons´ avel por aquela faixa dos atributos de entrada.
 completamente implementado.
 4.5. Controladores de rede
 Nesta sec ¸˜ ao s˜ ao descritos os principais controladores SDN que existem atualmente. Apre
sentamos uma breve motivac ¸˜ao por tr´as de cada um deles, suas caracter´ ısticas principais
 e, em alguns casos, exemplos simples de programac ¸˜ao ou uma descric ¸˜ao dos elementos
 principais da API.
 4.5.1. NOX
 NOX ´ e o controlador original OpenFlow e tem como principal func¸˜ ao hoje o desenvolvi
mento de controladores eficientes em C++. Ele opera sobre o conceito de fluxos de dados.
 Ele checa o primeiro pacote de cada fluxo e procura na tabela de fluxos para determinar
 a pol´ ıtica a ser aplicada. O controlador gerencia o conjunto de regras instaladas nos swit
ches da rede reagindo a eventos de rede. Atualmente a maioria dos projetos de pesquisa na
 ´ area s˜ ao baseados no NOX, que ´e um sistema operacional simples para redes e que provˆ e
 primitivas para o gerenciamento de eventos bem como as func ¸˜ oes para a comunicac¸˜ao
 com os switches [Gude et al. 2008].
 NOXdefine uma s´erie de eventos:
 • packet in(switch; port; packet), acionado quando o switch envia um pacote recebido
 por uma porta f´ ısica para o controlador.
 • stats in(switch; xid; pattern; packets; bytes) acionado quando o switch retorna os
 contadores de pacotes e bytes em resposta a um pedido pelas estat´ ısticas associadas
Minicursos Livro Texto
 175
 ` as regras contidas no padr˜ ao pattern. O parˆametro xid representa um identificador
 para o pedido.
 • flow removed(switch; pattern; packets; bytes) acionado quando uma regra com
 padr˜ao pattern supera o seu tempo limite e ´e removido da tabela de fluxo do switch.
 Os parˆametros packets e bytes contˆ em os valores dos contadores para a regra.
 • switch join(switch) acionado quando o switch entra na rede.
 • switch exit(switch) acionado quando o switch sai da rede.
 • port change(switch; port; up), acionado quando o enlace ligado a uma dada porta
 f´ ısica ´ e ligado ou desligado. O parˆametro up representa o novo status do enlace.
 NOXtamb´em provˆ e funcionalidades para enviar mensagens aos switches:
 • install (switch; pattern; priority; timeout; actions) insere uma regra com o dado
 padr˜ao, prioridade, tempo limite e ac ¸˜ oes na tabela de fluxos do switch.
 • uninstall (switch; pattern) remove a regra contida em padr˜ ao da tabela de fluxos
 do switch.
 • send(switch; packet; action) envia o dado pacote para o switch e aplica a ac ¸˜ ao l´ a.
 • query stats(switch; pattern) gera um pedido para estat´ ısticas de uma regra contida
 no padr˜ ao no switch e retorna um identificador de requisic ¸˜ ao xid que pode ser usado
 para mapear uma resposta ass´ ıncrona do swtich.
 Figura 4.7. Topologia simples
 O programa em execuc ¸˜ao no controlador define um manipulador para cada um
 dos eventos constru´ ıdos dentro do NOX, mas pode ser estruturado como um programa
 arbitr´ario. Exemplo: para ilustrar o uso de OpenFlow, considere um programa controlador
 escrito em Python que implementa um hub repetidor simples. Suponha que a rede tem
 um ´ unico switch ligado a um conjunto de hosts internos no porto 1 e uma rede ampla
 no porto 2, como mostrado na figura 4.7. O manipulador switch join abaixo invoca o
176
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 repetidor quando o switch se junta ` a rede. A func¸˜ ao repetidor instala regras no switch
 que o instruem a enviar pacotes da porta 1 para a porta 2 e vice-versa. As regras s˜ao
 permanentes (prioridade DEFAULT e tempo limite None).
 def switch_join(switch):
 repeater(switch)
 def repeater(switch):
 pat1 = {in_port:1}
 pat2 = {in_port:2}
 install(switch,pat1,DEFAULT,None,[output(2)])
 install(switch,pat2,DEFAULT,None,[output(1)])
 NOX obteve uma grande aceitac ¸˜ ao entre os pesquisadores da ´ area de SDN. A
 existˆencia de duas interfaces, C++ e Python, permite que o mesmo ambiente seja utilizado
 em situac ¸˜ oes que exigem alto desempenho e em casos onde a capacidade de express˜ao
 de Python agilizam o desenvolvimento e simplificam o c´ odigo resultante. Como ser´ a
 discutido mais tarde, POX foi desenvolvido com base no modelo de NOX, mas com a
 premissa de ser completamente escrito em Python, resultando em uma interface mais
 elegante e simples dentro daquela linguagem. Os desenvolvedores de POX acreditam que
 este seja adequado para substituir NOX nos casos em que Python ´ e utilizado, enquanto
 NOX ainda permanece como um ambiente adequado para implementac ¸˜ oes que tenham
 demandas mais elevadas em termos de desempenho.
 4.5.2. Trema
 Trema [tre 2012] ´e uma implementac¸˜ ao OpenFlow para desenvolvimento de controla
dores usando as linguagens de programac ¸˜ ao Ruby e C. O escopo de Trema ´e ajudar os
 desenvolvedores a criar facilmente seus pr´ oprios controladores OpenFlow. N˜ ao tem como
 objetivo fornecer uma implementac ¸˜ao espec´ ıfica de um controlador OpenFlow.
 Controladores Trema OpenFlow s˜ao simples scripts escritos em Ruby. ´ E poss´ ıvel
 escrever seu pr´ oprio controlador adicionando manipuladores de mensagem para sua classe
 controller. Com um arquivo de configurac¸˜ao ´ e poss´ ıvel descrever a topologia da rede na
 qual o controlador ´e executado e pass´a-lo para execuc ¸˜ ao pelo trema. Um exemplo de
 arquivo de configurac ¸˜ao ´ e apresentado a seguir.
 class MyController < Controller
 # packet_in handler
 def packet_in dpid, msg
 send_flow_mod_add(
 dpid,
 :match => ExactMatch.from(msg),
 :buffer_id => msg.buffer_id,
 :actions => ActionOutput.new(msg.in_port+1)
 )
 end
 end
Minicursos Livro Texto
 177
 Trema tem um emulador de rede OpenFlow integrado. N˜ ao ´ e preciso preparar
 switches OpenFlow ehosts para testar aplicac ¸˜ oes de controlador. O c´ odigo a seguir mostra
 umexemplo de arquivo de configurac ¸˜ ao de rede que cria dois switches virtuais.
 # network.conf
 vswitch { dpid ‘‘0xabc’’ }
 vhost ‘‘host1’’
 vhost ‘‘host2’’
 link ‘‘0xabc’’, ‘‘host1’’
 link ‘‘0xabc’’, ‘‘host2’’
 Aexecuc¸˜ao ´e feita com a seguinte linha de comando:
 ./trema run mycontroller.rb-c network.conf
 4.5.3. Maestro
 Maestro ´e uma plataforma escal´avel de controladores para switches OpenFlow em
 Java [Cai et al. 2010].
 Maestro ´ e um sistema operacional de rede desenvolvido para orquestrar aplicac¸˜ oes
 de controle no modelo SDN. O sistema fornece interfaces para implementac ¸˜ ao modula
res de aplicac ¸˜ oes de controladores de rede para acessar e modificar o estado da rede e
 coordenar suas interac ¸˜ oes. O modelo de programac ¸˜ ao do Maestro fornece interfaces para:
 • Introduc ¸˜ ao de novas func ¸˜ oes de controle personalizadas, adicionando componentes
 de controle modular.
 • Manutenc ¸˜ ao do estado da rede em nome dos componentes de controle.
 • Composic ¸˜ao de componentes de controle, especificando a sequˆ encia de execuc ¸˜ ao e
 o estado dos componentes da rede compartilhada.
 Emparticular, Maestro j´a inclui m´ odulos de descoberta de recursos f´ ısicos da rede,
 utilizado para contruir sua vis˜ao global da estrutura da rede, e m´ odulos para implementar
 protocolos de roteamento usuais sobre essa estrutura.
 Al´ em disso, Maestro tenta explorar o paralelismo dentro de uma ´ unica m´aquina
 para melhorar o desempenho do sistema de transferˆencia. A caracter´ ıstica fundamental
 de uma rede OpenFlow ´ e que o controlador ´e respons´avel pela criac ¸˜ ao inicial de cada
 f
 luxo entrando em contato com switches relacionados. O desempenho do controlador
 pode ser o gargalo. No projeto do Maestro tentou-se exigir o menor esforc ¸o poss´ ıvel dos
 programadores para conseguir gerenciar a paralelizac ¸˜ ao. Maestro lida com a maior parte
 do trabalho tedioso e complicado de gerir distribuic¸˜ao de carga de trabalho e agendamento
 de threads.
 No Maestro, os programadores podem alterar a funcionalidade do plano de con
trole escrevendo programas single-threaded. Maestro incorpora um conjunto de mode
los e t´ecnicas que abordam a especificac ¸˜ao de requisitos do OpenFlow e explora parale
lismo em nome dos programadores. Para maximizar o rendimento do sistema, a carga
178
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 de trabalho tem de ser uniformemente distribu´ ıda entre as threads em Maestro, de modo
 que nenhum n´ ucleo do processamento fique ocioso, enquanto h´a trabalho a fazer. Isto ´ e
 alcanc ¸ado fazendo com que todas as threads compartilhem a fila de tarefas de pacotes. O
 projeto
 4.5.4. Beacon
 Beacon ´ e outro controlador baseado em Java que suporta tanto a operac ¸˜ ao baseada em
 eventos quanto em threads [bea 2012].
 O projeto vem sendo desenvolvido j´ a h´ a um ano e meio, sendo considerado
 est´ avel. Seu registro de operac ¸˜ao inclui a gerˆencia de uma rede com 100 switches virtuais,
 20 switches f´ ısicos em um datacenter experimental. O sistema tem uma estrutura modular
 que permite que o controlador seja atualizadom em tempo de execuc¸˜ ao sem interromper
 outras atividades de encaminhamento de pacotes. O pacote opcionalmente incorpora o
 servidor web Jetty e um arcabouc¸o extens´ ıvel para o desenvolvimento de interfaces de
 usu´ario personalizadas.
 4.5.5. FML
 A linguagem FML (Flow Management Language) ´e uma linguagem declarativa de alto
 n´ ıvel que permite especificar pol´ ıticas de gerˆ encia e seguranc ¸a em redes OpenFlow. FML
 foi desenvolvida para substituir os mecanismos tradicionais de configurac¸˜ ao de redes para
 reforc¸ar as pol´ ıticas dentro das redes de empresas [Hinrichs et al. 2009]. A linguagem ´ e
 simples e pode ser usada para expressar muitas configurac ¸˜ oes comuns usadas em redes
 atualmente. FML foi projetado para admitir uma implementac ¸˜ ao eficiente, adequada para
 grandes redes corporativas.
 FML opera sobre fluxos unidirecionais. Isso significa que a pol´ ıtica resultante ´ a
 aplicada igualmente em todos os pacotes dentro do mesmo fluxo, e pol´ ıticas podem ser
 constru´ ıdas que tratam cada fluxo diferentemente.
 O sistema resultante permite a especificac ¸˜ ao de alto n´ ıvel de v´ arias tarefas de
 gerenciamento de forma resumida e estruturada, liberando os administradores de rede
 do trabalho penoso de configurar regras de controle de acesso em roteadores, firewalls,
 servidores de NAT e VLANs para alcanc¸ar pol´ ıticas de uso de rede simples. A natureza
 declarativa da FML permite que os administradores se concentrem sobre a pol´ ıtica de
 decis˜ oes, em vez de detalhes de implementac ¸˜ao.
 Uma pol´ ıtica FML ´ e um conjunto de regras n˜ ao-recursivas. Por exemplo, as trˆes
 afirmac ¸˜ oes seguintes dizem que Todd e Michelle s˜ao superusu´arios e um superusu´ario n˜ ao
 tem restric ¸˜ oes de comunicac ¸˜ ao.
 allow(Us;Hs;As;Ut;Ht;At;Prot;Req) <= superuser(Us)
 superuser(Todd)
 superuser(Michelle)
 Os argumentos para allow s˜ao s´ ımbolos que correspondem a oito campos de um
 f
 luxo dentro do sistema. S˜ao eles: usu´ ario, host e ponto de acesso fonte (Us;Hs;As),
Minicursos Livro Texto
 179
 usu´ario, host e ponto de acesso alvo (Ut;Ht;At;), protocolo (Prot) e se o fluxo ´ e uma
 requisic ¸˜ao (Req).
 Al´ em de allow , h´a outras palavras chaves para o controle de acesso, como deny,
 waypoint, avoid e ratelimit.
 Para qualidade de servic¸os, FML possui trˆ es palavras chaves latency, jitter, band
 que podem ser usadas para configurar diferentes requisitos para diferentes fluxos.
 FML tamb´em permite a inclus˜ ao de referˆencia a fontes externas, como consultas
 SQLemumabase de dados ou procedimentos remotos .
 4.5.6. Frenetic
 Frenetic ´ e um sistema baseado em linguagem funcional desenvolvido para programar re
des OpenFlow [Foster et al. 2010]. Frenetic permite que o operador da rede, ao inv´ es de
 manualmente configurar cada equipamento da rede, programe a rede como um todo. Fre
netic ´ e implementado sobre NOX, em Python, e foi projetada para resolver problemas de
 programac ¸˜ ao com o OpenFlow/NOX. Frenetic introduz abstrac ¸˜ oes funcionais para permi
tir programas modulares e a composic ¸˜ao desses programas.
 Frenetic ´e composto de duas sublinguagens integradas: uma linguagem declara
tiva de consultas para classificar e agregar tr´ afego da rede e uma biblioteca reativa funci
onal para descrever pol´ ıticas de envio de pacotes em alto n´ ıvel.
 Figura 4.8. Sintaxe de Consulta do Frenetic
 Afigura 4.8 mostra a sintaxe das consultas em Frenetic. Cada cl´ausula ´e opcional,
 exceto Select, no qual identifica qual o tipo de evento retornado pela consulta: evento
 contendo pacotes, contador de bytes ou contador de pacotes. O operador ∗ ´ e usado para
 combinar cl´ausulas.
 A cl´ ausula Select(a) agrega os resultados retornados pela consulta a. A cl´ ausula
 where(fp) filtra os resultados, mantendo apenas aqueles pacotes que satisfazem o
 f
 iltro de padr˜ ao fp. Os padr˜ oes de consultam podem usar os campo de cabec¸alho
180
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 como porta (inport), enderec¸o MAC de origem (srcmac), enderec¸o MAC de destino
 (dstmac), entre outros. Filtro de padr˜ oes mais complicados podem ser constru´ ıdos
 usando operadores de conjunto como intersec¸˜ao (and fp), uni˜ao (or fp),diferenc ¸a
 (diff fp) e complemento(not fp). Cl´ ausulas GroupBy([qh1,...,qhn]) subdividem o con
junto de pacotes consultados em subconjuntos baseado nos campos de cabec¸alhos qh.
 Cl´ausulas Every(n) particionam os pacotes por tempo, agrupando pacotes que estejam
 na mesma janela de tempo. Finalmente, cl´ ausulas Limit(n) limitam o n´ umero de pacotes
 emcadasubconjunto. Um exemplo de consulta utilizando Frenetic ´ e apresentado a seguir.
 def web_query():
 return \
 (Select(sizes) *
 Where(inport_fp(2) & srcport_fp(80))) *
 Every(30))
 Aconsulta seleciona os pacotes que chegam na porta f´ ısica 2 e da porta de origem
 TCP 80. Ela soma o tamanho de todos esses pacotes a cada 30 segundos e retorna um
 evento com o resultado.
 4.5.7. Onix
 Onix ´ e um controlador desenvolvido em parceria pela Nicira, Google e NEC,
 com o objetivo de permitir o controle de redes de grandes dimens˜ oes de forma
 confi´avel [Koponen et al. 2010]. Para garantir a escalabilidade e confiabilidade do sis
tema, Onix provˆe abstrac ¸˜ oes para particionar e distribuir o estado da rede em m´ ultiplos
 controladores distribu´ ıdos, enderec ¸ando as quest˜ oes de escalabilidade e tolerˆ ancia a falha
 que surgem quando um controlador centralizado ´ e utilizado.
 Avis˜ao global da rede ´e mantida atrav´ es de uma estrutura de dados denominada
 NIB(Network Information Base), que representa um grafo com todas as entidades presen
tes na rede f´ ısica. A NIB ´e o centro do sistema e a base para o modelo de distribuic ¸˜ao de
 Onix. Aplicac¸˜ oes de controle da rede s˜ ao implementadas atrav´ es de operac ¸˜ oes de leitura
 e atualizac¸˜ao do estado da NIB; escalabilidade resiliˆ encia s˜ao obtidos particionando-se e
 replicando-se a NIB entre os servidores do sistema. A consistˆencia das atualizac˜ oes sobre
 a base distribu´ ıda ´ e controlada pela aplicac¸˜ao e utiliza dois reposit´ orios com compro
missos diferentes entre os as garantias de resiliˆencia e desempenho (uma base de dados
 transacional replicada e uma DHT baseada em mem´ oria). Para garantir a escalabilidade,
 Onix prevˆe a organizac ¸˜ ao da NIB em estruturas hier´arquicas, com concentradores e dife
rentes n´ ıveis de detalhes para os recursos do sistema.
 Os resultados apresentados atestam o bom desempenho do sistema e o artigo dis
cute em algum detalhe os compromissos adotados com relac¸˜ao `a escalabilidade e re
siliˆencia do sistema. O sistema resultante, conforme descrito, sugere um grande cui
dado com afuncionalidade e uma estrutura complexa que atende aos requisitos de projeto
 apresentados. Entretanto, Onix ´ e, pelo menos at´ e o momento, um produto fechado, pro
priet´ario.
Minicursos Livro Texto
 181
 4.5.8. Click
 O roteador modular Click [Kohler et al. 2000] ´e um projeto que expressou o objetivo
 de permitir que equipamentos de rede fossem program´ aveis bem antes do advento de
 redes definidas por software. Sendo considerado um dos projetos que influenciaram a
 definic¸˜ao de OpenFlow. O roteador Click enfatiza a modularidade, permitindo que pes
quisadores criem m´ odulos de processamento de pacotes customizados. Entretanto, Click
 foca exclusivamente em switches de software (implementado como m´ odulo do kernel
 do Linux). J´ a existe uma interface do OpenFlow para o Click, o elemento OpenFlow
Click [Mundada et al. 2009]. Esse elemento permite o contralador instalar regras para
 fazer pacotes atravessarem diferentes elementos. O OpenFlowClick permite um contro
lador central controlar v´ arios roteadores Click ao mesmo tempo. Esta interface tem o
 potencial para novas possibilidades de aplicac ¸˜ oes de processamento de tr´ afego, como eli
minar pacotes duplicados ou detecc ¸˜ ao de anomalias via inspec ¸˜ ao peri´ odica de pacotes.
 4.5.9. Floodlight
 Floodlight [flo 2012] ´ e um controlador OpenFlow para redes corporativas baseado total
mentenalinguagemJavaedistribu´ ıdo segundo a licenc ¸a Apache. O projeto se originou do
 controlador Beacon e agora ´e apoiado por uma comunidade de desenvolvedores e tamb´ em
 pela Big Switch Networks, start-up que produz controladores comerciais que suportam o
 Floodlight. O n´ ucleo e m´ odulos principais s˜ ao escritos em Java. Recentemente adicio
naram Jython, o que permite desenvolvimento na linguagem Python. Em sua arquitetura,
 todos os elementos s˜ ao m´ odulos e m´ odulos exportam servic ¸os. Toda a comunicac¸˜ ao en
tre m´ odulos ´e feita atrav´es de servic¸os. A interface ItopologyService permite descobrir a
 topologia da rede automaticamente. Permite integrar com redes n˜ao openflow e ´ e com
pat´ ıvel com a ferramenta de simulac ¸˜ao Mininet [Lantz et al. 2010].
 4.5.10. SNAC
 Simple Network Access Control(SNAC) [sna 2012] ´ e um controlador OpenFlow no qual
 se utiliza uma interface web para monitorar a rede. Ele incorpora uma linguagem de
 definic¸˜ ao de pol´ ıticas flex´ ıvel que permite realizar buscas utilizando padr˜ oes de alto n´ ıvel
 para especificar pol´ ıticas de controle de acesso. SNAC tamb´em provˆe uma ferramenta
 de monitamento gr´afico, mas n˜ao ´e um ambiente de programac¸˜ ao gen´erica, como outros
 controladores discutidos aqui.
 4.5.11. NEC Programmable Flow
 Na parte de produtos comerciais, temos a fam´ ılia de produtos do NEC Programmable
 Flow [nec 2012]. A fam´ ılia provˆ e tanto componentes de software como tamb´ em de hard
ware. Em software, temos o ProgrammableFlow Management Console, que ´ e uma ferra
menta para monitoramento que provˆe um ponto de controle centralizado. Em hardware,
 temos o controlador ProgrammableFlowController que permite virtualizac¸˜ ao em n´ ıvel de
 rede e ´e ´ util, por exemplo, para data center pois permite monitorar e controlar redes com
 v´arios n´ ıveis de gerˆencia. Dentre os switches, podemos citar o PF5420 e o PF5820 que
 s˜ao compat´ ıveis com OpenFlow e reduzem o custo de operac ¸˜ao da rede j´ a que n˜ ao preci
samexecutar algoritmos dsitribu´ ıdos tradicionais como arvor´e geradora, j´a que funcionam
 com umcontrolador centralizado.
182
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 4.5.12. Mininet
 Apesar de n˜ao se tratar de um controlador propriamente dito, na parte de emuladores
 e simuladores, ´e importante mencionar o Mininet [Lantz et al. 2010], uma ferramenta
 de simulac¸˜ ao de Redes Definidas por Software. ´ E um sistema que permite a r´apida
 prototipac ¸˜ao de grandes redes utilizando apenas um computador. Mininet cria Redes
 Definidas por Software escal´ aveis utilizando primitivas de virtualizac ¸˜ao do Sistema Ope
racional, como processos e namespaces de rede. Com essa primitivas, ele permite rapida
mente criar, interagir e customizar prot´ otipos de Redes Definidas por Software.
 4.6. Aplicac ¸˜ oes
 Pela flexibilidade que Redes Definidas por Software oferecem para a estruturac¸˜ ao de sis
temas em rede, o princ´ ıpio estruturador oferecido por esse paradigma pode ser ´ util em
 praticamente todas as ´areas de aplicac ¸˜ ao de Redes de Computadores. A estruturac¸˜ ao da
 rede com comutadores program´aveis e uma vis˜ao (l´ ogica) centralizada da rede podem ser
 de grande valia no desenvolvimento de novas funcionalidades em um grande n´ umero de
 ambientes. Nesta sec ¸˜ao, discutimos primeiramente os principais contextos j´ a identifica
dos que podem se beneficiar da aplicac¸˜ ao de SDN. Em seguida, identificamos alguns dos
 principais projetos de pesquisa em andamento que se valem do paradigma para avanc¸ar a
 fronteira do conhecimento em suas ´areas, no Brasil e no mundo.
 4.6.1. Contextos de aplicac ¸˜ ao
 Se considerarmos que SDN define uma nova forma de estrutura um sistema em rede,
 podemos considerar que ela seja aplic´ avel a qualquer tipo de aplicac¸˜ao de Redes de Com
putadores que possa se beneficar de um maior grau de organizac¸˜ao das funcionalidades
 oferecidas em torno de uma vis˜ ao completa da rede. Entretanto, alguns dom´ ınios de
 aplicac ¸˜ao j´a foram identificados e vˆ em sendo tratados por diferentes projetos de pesquisa.
 Controle de acesso
 Pela natureza da interface de programac ¸˜ ao de OpenFlow, onde o tratamento ´e definido
 pelos padr˜ oes que identificam fluxos, a sua aplicac¸˜ ao ao problema de controle de acesso ´ e
 bastante direta. A vis˜ao global da rede oferecida pelo controlador SDN permite que regras
 de acesso sejam desenvolvidas com base em informac¸˜ oes abrangentes e n˜ao apenas o que
 seria poss´ ıvel com o uso de um firewall em um enlace espec´ ıfico da rede. De fato, como
 mencionado anteriormente, um dos projetos precursores de OpenFlow foi exatamente
 Ethane, um sistema de controle de acesso distribu´ ıdo, baseado no conceito de uma vis˜ ao
 global das pol´ ıticas de controle e do estado da rede [Casado et al. 2009].
 O poder de express˜ ao dispon´ ıvel ao se adotar uma vis˜ao global permite a
 implementac ¸˜ao de regras que levem em conta n˜ ao apenas tipos de protocolo e pontos
 de origem/destino, mas a relac ¸˜ao entre estes e a identidade do usu´ario de forma simples.
 Al´ em disso, a facilidade de se definir qual rota adotar para cada fluxo viabiliza inclusive a
 utilizac ¸˜ ao de filtros especiais de tr´afego (middle-boxes), como dispositivos de inspec¸˜ao de
 pacotes (DPI) e proxies. Um exemplo do que pode ser feito nesse caso ´ e o sistema SpSb,
 um honeypot de alta interatividade que est´a sendo desenvolvido no DCC/UFMG para
Minicursos Livro Texto
 183
 o estudo do comportamento de bots, especialmente aqueles usados para a distribuic ¸˜ao
 de spam [Silva et al. 2011]. Uma m´aquina ´e interposta entre o computador infectado e
 o restante da Internet com um comutador Open vSwitch e um controlador POX. Cada
 f
 luxo iniciado pela m´ aquina infectada ´e inspecionado pelo controlador, que pode decidir
 entre bloque´a-lo, permitir sua passagem para o restante da rede ou redirecion´a-lo para
 um conjunto se servidores desenvolvidos para emular servic¸os importantes que permi
tam ao sistema controlar o comportamento do bot. Por exemplo, um servidor de DNS
 especialmente configurado pode ser programado para registrar as consultas efetuadas e
 redirecionar acessos quando necess´ario. Um tipo de acesso que seria sempre redirecio
nado seria qualquer tentativa de contato a um servidor de correio eletrˆ onico por SMTP,
 que seria enviado para um servidor especialmente configurado para emular qualquer ser
vidor de correio e armazenar as mensagens recebidas, sem entretanto repass´a-las para o
 restante da rede.
 Gerˆ encia de Redes
 Umdos argumentos sempre utilizados com relac ¸˜ ao a SDNs ´ e que a vis˜ao global da rede
 simplifica as ac¸˜ oes de configurac¸˜ao e gerˆ encia de rede, enquanto os contadores associados
 aos fluxos permitem uma monitorac¸˜ao clara dos fluxos de interesse. Entretanto, ainda n˜ao
 est´ a claro como essas funcionalidades podem ser melhor integradas a pr´ aticas de gerˆ encia
 habituais. Uma forma de integrac ¸˜ ao interessante ´ e certamente a integrac¸˜ao direta de swit
ches OpenFlow a sistemas de gerˆencia tradicionais, como os que utilizam o protocolos
 SNMP[Farias et al. 2011].
 Outros projetos, como OMNI [Mattos et al. 2011], oferecem opc¸˜ oes para simpli
f
 icar o processo de administrac¸˜ ao de redes OpenFlow pela inclus˜ao de uma interface de
 controle baseada em uma arquitetura orientada servic ¸os. Al´ em disso, OMNI inclui uma
 plataforma orientada a agentes para simplificar a express˜ao de comportamentos que de
vem ser monitorados e sobre os quais o sistema deve atuar.
 Tamb´ em utilizando uma arquitetura multi-agentes, pesquisadores da UFAM tˆ em
 estudado a integrac¸˜ ao de t´ecnicas de Inteligˆencia Artificial a redes definidas por soft
ware. A vis˜ ao global da rede provida pelos controladores oferece um ponto focal so
bre o qual t´ ecnicas de detecc¸˜ ao de anomalias ou padr˜ oes frequentes podem ser apli
cadas para se detectar diversos tipos de comportamento, como ataque de negac¸˜ao de
 servic ¸o [Braga et al. 2010].
 Redes domiciliares
 Redes dom´esticas tˆ em sido apontadas como um dos grandes desafios para a ind´ ustria de
 redes, especialmente no que se refere a dotar o usu´ario dessas redes de recursos eficientes
 para sua gerˆencia e configurac¸˜ ao [Dixon et al. 2010]. Vencer esse desafio exigir´a tanto o
 investimento em soluc¸˜ oes para os problemas de interac¸˜ ao dos usu´ arios com os dispositivos
 de rede, quanto em novas soluc ¸˜ oes para automac ¸˜ ao de configurac ¸˜ ao e implementac ¸˜ ao de
 pol´ ıticas de seguranc ¸a para o lar.
184
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 Umaforma de aplicar os princ´ ıpios de SDN nesse contexto ´e utilizar um roteador
 dom´ estico com recursos OpenFlow e transferir para o provedor de acesso a responsabi
lidade de controlar a rede atrav´ es de um controlador SDN. Dessa forma, esse sistema
 operacional de rede seria capaz de programar cada roteador dom´estico com as regras de
 acesso apropriadas para cada usu´ario e ter uma vis˜ao global de todo o tr´afego que atra
vessa o enlace de acesso a cada residˆ encia, construindo dessa forma uma vis˜ao agregada
 do que pode ser considerado tr´ afego l´ ıcito e quais padr˜ oes de tr´ afego podem indicar a
 ac¸˜ ao de atacantes ou c´ odigo malicioso. Esse enfoque tem sido adotado por pesquisadores
 da Georgia Tech [Feamster 2010, Calvert et al. 2011].
 Por outro lado, outra soluc ¸˜ao interessante pode ser a implementac ¸˜ ao de um contro
lador de rede interno `a rede dom´ estica. Essa soluc ¸˜ ao se torna atraente especialmente frente
 ao aumento da complexidade dessas redes, que contam hoje com um n´ umero crescente
 de dispositivos ativos, como smartphones e consoles de jogos, al´em dos computadores
 usuais, al´ em de poderem contar hoje com mais de um elemento de comutac¸˜ ao, tanto para
 enlaces cabeados quanto para enlaces sem fio. Um controlador dom´estico poderia acom
panhar todo o tr´ afego interno da rede, potencialmente tornando mais simples a detecc ¸˜ao
 de m´aquinas comprometidas por malware (cujo tr´afego de disseminac¸˜ao seria mais facil
mente identificdo contra o padr˜ ao usual do tr´afego do lar) e a configurac ¸˜ ao de servic ¸os da
 rede, como impressoras e novos dispositivos de acesso.
 Gerˆ encia de energia
 O interesse em soluc ¸˜ oes que conservem energia em sistemas de computac ¸˜ ao vem cres
cendo. Em ambientes corporativos e grandes datacenters, onde os recursos de rede as
sumem dimens˜ oes significativas, reduzir o consumo de energia consumida pelo meio de
 comunicac ¸˜ao se torna uma possibilidade interessante. Ac¸˜ oes como a reduc¸˜ao da taxa de
 transmiss˜ ao de enlaces sub-utilizados ou seu desligamento completo (e de dispositivos de
 rede, da mesma forma) se tornam vi´ aveis a partir do momento em que uma rede definida
 por software oferece uma vis˜ ao global do estado da rede, que simplifica a identificac ¸˜ao
 desses elementos ociosos e mesmo a redefinic¸˜ ao de rotas a fim de desviar tr´ afego de
 elementos pass´ ıveis de desligamento. Al´ em disso, o controle das rotas e decis˜ oes de en
caminhamento permite a implantac ¸˜ao de pontos de controle (proxies) que interceptem
 tr´afego “ruidoso” na rede, evitando que pacotes de menor importˆ ancia atinjam m´aquinas
 que podemoperar emummodelodewake-on-lan, evitando queas mesmassejamativadas
 desnecessariamente.
 Comutador virtual distribu´ ıdo
 Ambientes virtualizados, comuns hoje em redes corporativas e grandes datacenters, usu
almente implicam no uso de switches implementadas por software no hypervisor insta
lado em cada m´aquina f´ ısica a fim de prover a conectividade exigida por cada m´aquina
 virtual (VM). Um exemplo de tal switch ´e o Open vSwitch, discutido anteriormente. A
 facilidade de se mover as m´ aquinas virtuais entre os hospedeiros f´ ısicos, um recurso bas
tante valorizado nesses ambiente, torna o processo de configurac¸˜ao e monitorac ¸˜ao dessas
Minicursos Livro Texto
 185
 m´ aquinas um desafio que complica a gerˆencia dos switches virtuais. Uma forma de re
duzir essa complexidade seria oferecer a vis˜ ao de um switch ´ unico, virtual, ao qual todas
 as VMs estariam conectadas. Dessa forma, migrac¸˜ oes de VMs teriam impacto m´ ınimo
 nas configurac ¸˜ oes da rede virtual, uma vez que elas continuariam ligadas a uma porta
 do ´ unico switch vis´ ıvel para a rede. Essa abstrac¸˜ao pode ser facilmente implementada
 atrav´ es de um controlador de rede, j´ a que ele pode inserir automaticamente as regras de
 encaminhamento de tr´ afego entre as portas dos diversos switches de software para criar
 o efeito desejado. Com o uso de switches f´ ısicos que tamb´ em implementem o protocolo
 OpenFlow, mesmo m´ aquinas f´ ısicas n˜ao virtualizadas podem fazer parte dessa rede.
 Roteador expans´ ıvel de alta capacidade
 Grandes datacenters e as bordas das redes de acesso de grandes provedores, bem como
 das suas redes de longa distˆancia, possuem demandas de conectividade elevadas. Nesses
 casos, usualmente um roteador de grande porte ´e usualmente a ´ unica soluc ¸˜ao vi´avel, a um
 custo bastante elevado. Utilizando-se uma rede definida por software, pode ser poss´ ıvel
 substituir esse roteador de grande porte por um banco de switches de porte m´ edio, como
 as utilizadas internamente em um cluster, desde que dotadas de interfaces OpenFlow. De
 forma semelhante ao que ocorre no caso do comutador virtual distribu´ ıdo, um controla
dor SDNpodepreencher as tabelas de roteamento de cada switch com as rotas necess´ arias
 para interligar o tr´afego entre duas portas de switches diferentes que sejam vistas como
 fazendo parte do mesmo roteador. Uma malha de interconex˜ ao do tipo fat-tree garantiria
 uma banda de interconex˜ao suficiente entre os comutadores, de forma que o controlador
 n˜ao teria que lidar com gargalos inesperados entre portas do roteador. As informac ¸˜ oes de
 roteamento seriam distribu´ ıdas entre os switches em func¸˜ao das demandas identificadas
 pelo controlador. Os algoritmos de roteamento necess´ arios ao funcionamento do roteador
 poderiam ser executados tamb´em pelo controlador, que se encarregaria de manter a inter
face com os demais roteadores com os quais o roteador virtual tenha que se comunicar.
 Datacenters multi-usu´ arios
 Em ambientes onde aplicac¸˜ os de v´arios usu´arios necessitem coexistir, como em data
centers p´ ublicos (multi-tenant), uma demanda sempre presente ´ e o isolamento de tr´ afego
 entre os diversos usu´arios. Uma forma de se obter esse isolamento com dispositivos atuais
 ´
 e atrav´es da configurac¸˜ ao de VLANs individuais para cada cliente. Assim, tr´afego de cada
 usu´ario ´ e transportado apenas dentro da sua VLAN, garantindo o isolamento necess´ ario
 para fins de seguranc¸a e privacidade. Entretanto, o recurso de VLANs ´ e limitado pelo
 tamanho dos campos usados para identific´ a-las, tornando invi´avel sua utilizac¸˜ao quando
 o n´ umero de usu´ arios da rede cresce. Al´em disso, as interfaces de configurac¸˜ao desse tipo
 de soluc¸˜ ao tendem a ser limitadas, tornando a gerˆ encia de configurac ¸˜ao desse tipo de rede
 uma tarefa bastante complexa. A soluc¸˜ao para esse problema pode ser constru´ ıda dire
tamente sobre a abstrac ¸˜ ao do comutador virtual distribu´ ıdo mencionado anteriormente: a
 cada usu´ ario ´e fornecido um switch virtual que interliga suas m´ aquinas, independente da
 localizac ¸˜ ao das mesmas na rede f´ ısica. O controlador de rede ´e respons´avel por definir as
 rotas entre as portas dos diversos comutadores que comp˜ oem o comutador virtual e por
186
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 garantir a alocac¸˜ ao de recursos suficientes em cada caso. Como cada cliente ´e conectado
 a umswitch diferente, o isolamento de tr´ afego ´e obtido diretamente pela implementac ¸˜ ao.
 Al´ em de garantir o isolamento de tr´ afego de forma eficaz, essa soluc¸˜ ao tem a van
tagem de permitir que se oferec¸a a cada usu´ ario o controle direto de sua rede. Quaisquer
 configurac ¸˜ oes que estejam dispon´ ıveis para o switch virtual podem ser controladas pelo
 usu´ario que controla a rede, uma vez que a mesmaest´ a isolada das demais. Soluc ¸˜ oes como
 balanceamento de carga, estabelecimento de n´ ıveis de qualidade de servic¸o e redundˆ ancia
 de rotas podem ser colocadas sob o controle do usu´ ario, desde que o controlador de rede
 garanta sua implementac ¸˜ ao no n´ ıvel do switch virtual distribu´ ıdo.
 4.6.2. Alguns projetos de pesquisa
 Pela caracter´ ıstica recente do tema, diversos projetos de pesquisa ainda focam o desen
volvimento de controladores de rede que preencham as caracter´ ısticas de um sistema ope
racional de rede, na definic ¸˜ ao de SDN. Esses projetos j´a foram discutidos na sec ¸˜ao 4.5.
 Aqui discutimos projetos principalmente focados em aplicac ¸˜ oes do paradigma em alguns
 dos contextos mencionados anteriormente. Diversos s˜ ao os que abordam problemas que
 afetam um ou mais dom´ ınios mencionados anteriormente. A lista a seguir n˜ao tem a
 intenc ¸˜ ao de ser exaustiva, dado o n´ umero de iniciativas, mas pretende ilustrar alguns des
ses projetos.
 Ripcord
 Odatacenter foi identificado rapidamente como um dos principais contextos onde SDN
 poderia ser aplicado com sucesso. Isso pode ser observado na identificac ¸˜ao de aplicac¸˜ oes
 como o comutador virtual distribu´ ıdo e o ambiente multi-usu´ ario. Um ponto importante
 dos datacenters hoje ´ e a demanda por novas topologias de rede que permitam a construc¸˜ ao
 de infraestruturas de comunicac¸˜ ao eficiente e robustas. Nesse contexto, Ripcord foi con
cebido como um sistema que aplicaria os conceitos de SDN na construc¸˜ao de um sistema
 de rede quepudesse ser configurado para diferentes topologias e diferentes soluc ¸˜ oes de ro
teamento, a fim de permitir a escolha da soluc ¸˜ao mais adequada para diferentes condic¸˜ oes
 de contorno [Heller et al. 2010a, Casado et al. 2010a].
 Al´ em das caracter´ ısticas de modularidade, escalabilidade e operac¸˜ ao com
 m´ ultiplos usu´arios, Ripcord tamb´ em tinha como metas definir um mecanismo de
 migrac ¸˜ ao de VMs de forma transparente e com recursos de balanceamento de carga para o
 tr´afego de rede. O prot´ otipo desenvolvido foi implementado sobre o NOX, com diferentes
 m´ odulos para implementar cada func ¸˜ ao identificada como essencial `a sua operac¸˜ ao. Entre
 os m´ odulos (engines) principais, destaca-se o de topologia, que mant´ em a vis˜ ao da rede
 f´ ısica, o de aplicac ¸˜ao, que controla a vis˜ao de cada usu´ ario (tenant) sobre a rede, e o de
 roteamento, que implementa o mecanismo de roteamento com balanceamento de carga
 escolhida. O sistema foi testado com trˆ es pol´ ıticas de roteamento com diferentes graus de
 complexidade e apresentou bom desempenho.
Minicursos Livro Texto
 187
 RouteFlow
 No contexto de redes de longa distˆancia, a implementac¸˜ao de protocolos de roteamento
 ´
 e uma preocupac ¸˜ ao frequente. Uma rede definida por software que pretenda operar de
 maneira eficiente com outras redes a seu redor deve implementar pol´ ıticas de roteamento
 bem definidas e, mais que isso, deve ser capaz de trocar informac¸˜ oes sobre suas rotas
 com elementos vizinhos. RouteFlow oferece uma soluc ¸˜ao distribu´ ıda para que se possa
 aplicar protocolos de roteamento bem definidos sobre uma rede definida por software,
 permitindo a implantac¸˜ ao imediata de protocolos de roteamento j´ a definidos e ofere
cendo um arcabouc ¸o extens´ ıvel sobre o qual novos protocolos podem ser implementa
dos [Nascimento et al. 2011].
 RouteFlow executa como uma aplicac¸˜ao sobre NOX que controla a comunicac ¸˜ao
 com os comutadores OpenFlow da rede e o servidor RouteFlow, que mant´em a vis˜ao
 das rotas na rede. Os protocolos de roteamento propriamente ditos s˜ao executados por
 m´ aquinas virtuais que executam vers˜ oes do(s) protocolo(s) de roteamento escolhido(s)
 em um ambiente virtualizado. Essas vers˜ oes dos protocolos s˜ao obtidos normalmente
 do Quagga routing engine. Cada roteador definido na vis˜ao de rede definida executa
 como uma m´ aquina virtual, trocando mensagens dentro do ambiente virtualizado com os
 demais roteadores da rede, de acordo com o protocolo escolhido. Se a especificac¸˜ ao da
 rede prevˆe a existˆencia de roteadores adicionais que n˜ao fazem parte da rede definida por
 software, as mensagens dos protocolos de roteamento que devem ser trocadas entre os
 roteadores virtualizados e esse roteadores reais s˜ ao injetadas e retiradas da rede atrav´es
 dos comutadores OpenFlow.
 Elastic Tree
 Com foco na quest˜ao de gerˆencia (e economia) de energia, o objetivo de Elastic Tree
 ´
 e controlar a topologia da rede f´ ısica de um datacenter para reduzir o consumo devido
 a canais sub-utilizados [Heller et al. 2010b]. O princ´ ıpio de operac ¸˜ao nesse caso ´e que,
 em situac¸˜ oes de carga reduzida, o n´ ıvel de replicac ¸˜ ao de recursos encontrado em uma
 rede de datacenter bem provisionada pode levar a um consumo de energia desnecess´ ario.
 Em uma topologia fat-tree, por exemplo, h´ a diversos n´ ıveis de switches interligando os
 servidores da rede; o n´ umero de enlaces e switches a cada n´ ıvel ´ e definido de forma
 que haja diversas rotas entre cada par de servidores, a fim de evitar gargalos na rede.
 Emcondic ¸˜ oes de carga baixa, entretanto, muitos desses caminhos redundantes se tornam
 desnecess´arios e poderiam ser removidos para reduzir o consumo de energia.
 Elastic Tree monitora continuamente o tr´afego da rede e decide, com base nos
 objetivos de economia de energia e disponibilidade expressos pelo administrador, quais
 enlaces e switches precisam permanecer ativos e quais podem ser desligados. A vis˜ao
 global do tr´afego e da topologia s˜ ao providos pelo controlador SDN adotado (NOX, no
 prot´ otipo implementado). Diversos algoritmos de otimizac¸˜ao foram implementados para
 oferecer diferents pol´ ıticas de controle, refletindo diferentes compromissos entre econo
mia e disponibilidade. Em casos onde o padr˜ ao de tr´ afego se limitava em sua maioria
 a servidores pr´ oximos na topologia, a energia consumida chegava a ser apenas 40% da
188
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 energia consumida com a topologia original, sem controle. Os ganhos se reduzem caso o
 padr˜ao de tr´ afego exija a comunicac¸˜ao entre servidores distantes na topologia (exigindo
 maior conectividade nos n´ ıveis superiores da hiearquia de switches), mas s˜ ao ainda signi
f
 icativos para uma ampla gama de valores.
 Gatekeeper-ng
 Ainda no contexto de redes para datacenters, um outro aspecto que tem recebido grande
 atenc¸˜ ao ´e a quest˜ao de se estabelecer garantias de alocac¸˜ ao de tr´afego para diferents
 usu´arios com suas aplicac ¸˜ oes. Gatekeeper ´ e uma soluc¸˜ao proposta para esse fim que
 se baseia em uma vis˜ao abstrata onde cada usu´ ario receberia garantias equivalentes `as
 providas caso sua aplicac¸˜ ao executasse em um conjunto de m´ aquinas conectadas por
 um switch privativo, sem compartilhamento com outras aplicac ¸˜ oes. As garantias de de
sempenho seriam determinadas pela banda alocada para o enlace de conex˜ ao de cada
 m´ aquina, que poderia ser escolhida pelo usu´ario em um modelo com custos associa
dos [Rodrigues et al. 2011b, Rodrigues et al. 2011a].
 Aabstrac ¸˜ ao oferecida por Gatekeeper se encaixa precisamente ao modelo de co
mutador virtual distribu´ ıdo discutido anteriormente. Considerando-se que o ambiente
 alvo do sistema s˜ ao datacenters virtualizados, onde a conex˜ ao de cada m´ aquina virtual ` a
 rede se d´a atrav´es de switches de software (Open vSwitch), a extens˜ao do modelo para uti
lizar uma rede definida por software que realmente implemente a abstrac¸˜ ao de um switch
 virtual distribu´ ıdo pode ser feita de forma simples [Pettit et al. 2010]. Al´em disso, ao se
 integrar esse modelo ao ambiente Open Stack, que tamb´em se baseia na noc ¸˜ ao de uma
 rede privada assinalada para cada usu´ ario [ope 2012], o processo de configurac¸˜ao, disparo
 de m´ aquinas virtuais e reconfigurac¸˜ ao no caso de migrac ¸˜ ao de VMs pode ser totalmente
 integrado, dando origem ao ambiente Gatekeeper-ng, atualmente em desenvolvimento.
 POXatHome
 Esse projeto aborda o desenvolvimento de uma aplicac ¸˜ ao SDN para gerˆencia de redes
 dom´esticas. Inicialmente denominado NOX at home, foi recentemente adaptado para
 utilizar o controlador POX. O princ´ ıpio por tr´ as do projeto ´ e que, dadas as velocidades de
 acesso dispon´ ıveis para usu´ arios residenciais, a capacidade de processamento dispon´ ıvel
 em roteadores dom´ esticos ´ e suficiente para inspecionar cada fluxo que atravessa o enlace
 de acesso.
 Aaplicac ¸˜ ao POX nesse caso implementa um analisador de protocolos que acom
panha cada novo fluxo observado na rede local e reconstr´ oi o fluxo de aplicac¸˜ao para
 protocolos identificados como relevantes, como SMTP, HTTP e DNS. Essa reconstruc ¸˜ao
 continua at´e que o controlador tenha informac ¸˜ao suficiente para se avaliar a conformi
dade do tr´ afego em relac ¸˜ao a um conjunto de regras de acesso e aplicar um algoritmo de
 detecc ¸˜ ao de anomalias para determinar a natureza do tr´ afego [Mehdi et al. 2011]. Nesse
 momento, uma regra ´e emitida para incluir uma rota direta para o restante do fluxo, ou
 para descart´ a-lo, caso seja julgado inadequado. H´ a tamb´em a possibilidade de se confi
gurar a travessia de um middle-box caso algum tipo de p´ os-processamento do fluxo seja
Minicursos Livro Texto
 189
 necess´ario
 4.7. Desenvolvimento de sistemas utilizando POX
 POXvemsendo desenvolvido como um sucessor natural de NOX para iniciativas de pes
quisa e ensido. O objetivo dos desenvolvedores ´ e que ele venha a substituir NOX nos
 casos onde desempenho n˜ao seja um requisito cr´ ıtico — essencialmente, nos casos onde a
 interface Python ´ e utilizada. Nesse aspecto, POX traz uma interface mais moderna e uma
 pilha SDN mais elegante, al´em de oferecer melhor desempenho que NOX com Python,
 como pode ser visto na figura 4.9.
 Figura 4.9. Comparac ¸˜ ao de desempenho entre POX e NOX, com suas duas in
terfaces (C++ e Python). Figura publicada por Murphy McCauley no site
 http://www.noxrepo.org/2012/03/introducing-pox/.
 NOXeoutros controladores de primeira gerac ¸˜ ao s˜ao constru´ ıdos ao redor do con
ceito de mensagens OpenFlow como primitivas b´asicas. Assim sendo, as aplicac ¸˜ oes ser
 organizam ao redor de ciclos de recebimento/tratamento/gerac¸˜ ao de mensagens. POX est´ a
 sendo organizado ao redor da noc ¸˜ ao de vis˜ao global da rede: aplicac ¸˜ oes n˜ao necessitar˜ao
 necessariamente receber e enviar mensagens diretamente, mas poder˜ ao consultar a vis˜ao
 corrente da rede e atuar diretamente sobre ela para obter seus objetivos (os recursos para
 esse fim ainda est˜ ao em desenvolvimento). Outros elementos que fazem parte do contexto
 de projeto de POX incluem a previs˜ ao de recursos para a distribuic ¸˜ ao dessa vis˜ao global
 e para a depurac ¸˜ ao de aplicac ¸˜ oes desenvolvidas sobre essa vis˜ao.
 4.7.1. Instalac ¸˜ ao e execuc ¸˜ ao
 POX1 exige Python 2.7 (ou superior) para executar. Ele deve ser compat´ ıvel com Python
 3.x, mas nenhuma verificac ¸˜ ao cuidadosa foi feita a esse respeito. N˜ ao h´a registro de
 elementos que sejam espec´ ıficos de uma plataforma particular e ele pode ser executado
 no Linux, Mac OS ou Windows. Para um melhor desempenho, recomenda-se o uso da
 implementac ¸˜ao no ambiente PyPy 2.
 1O conte´ udo dessa sec ¸˜ ao ´ e diretamente derivado de notas de utilizac¸˜ ao dispon´ ıveis no site http:
 //www.noxathome.org/wiki/POXConcepts.
 2http://pypy.org/
190
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 Obtenc ¸˜ ao do c´ odigo
 Originalmente, POX era distribu´ ıdo o controle de vers˜ ao Mercurial (hg), mas no momento
 da escrita deste material ele estava sendo movido para o controlador Git e deve ser em
 breve disponibilizado no GitHub 3.
 In´ ıcio da execuc ¸˜ ao e o mecanismo launch()
 POX ´e iniciado ao se executar o m´ odulo pox.py. Ele recebe como argumentos a lista
 de nomes de m´ odulos que devem ser instanciados durante a execuc ¸˜ao. Cada m´ odulo
 identificado ´ e localizado e a func ¸˜ ao lauch() de cada m´ odulo ´ e executada, se existir.
 Em seguida, POX abra a interface de comandos de Python para uso interativo. M´ odulos
 s˜ao procurados na hierarquia de diret´ orios usual de Python e nos diret´ orios pox e ext do
 pacote. Assim sendo, para se disparar o m´ odulo que implementa switches Ethernet com
 aprendizado, utiliza-se o comando
 ./pox.py dumb
 l2
 switch
 Cada m´ odulo pode receber argmentos atrav´es de opc¸˜ oes de execuc¸˜ao indicadas
 ap´ os o nome do m´ odulo. Essas opc ¸˜ oes s˜ ao passadas como parˆ ametros para a func ¸˜ao
 launch() do m´ odulo.
 Em particular, as opc¸˜ oes de configurac¸˜ao de OpenFlow s˜ ao ´ uteis ao se iniciar a
 execuc¸˜ ao de POX associada a um ambiente de rede criado com o arcabouc ¸o Mininet.
 Como mencionado na sec¸˜ao 4.5.12, Mininet cria uma rede virtual de comutadores Open
Flow executando em uma m´aquina virtual disparada na m´ aquina local. Os comutadores
 e hosts na rede virtual podem ser configurados para se comunicar com uma instˆ ancia
 de POX executando no computador hospedeiro. Para isso, POX deve ser iniciado da
 seguinte forma:
 ./pox.py openflow.of
 01--address=10.1.1.1--port=6634
 Emseguida, no terminal Mininet, dispara-se a rede virtual com o comando:
 sudo mn--controller=remote--ip=10.1.1.1--port=6634
 Para que isso seja poss´ ıvel, a classe of
 na forma:
 01foidefinida comom´ etodolaunch()
 def launch (port=6633, address = ‘‘0.0.0.0’’):
 ‘‘‘Operac¸˜ oes a serem executadas ao se iniciar o
 m´ odulo’’’
 Omesmorecurso pode se utilizado por qualquer m´ odulo desenvolvido no sistema.
 Al´ em disso, pox.py reconhece algumas opc¸˜ oes pr´ oprias, que devem ser listadas
 primeiro:--verbose exibe stack traces para excec¸˜ oes durante a
 inicializac¸˜ ao--no-cli n˜ ao inicia a interface interativa de comandos--no-openflow n˜ ao inicia o m´ odulo openflow automaticamente
 3https://github.com/
Minicursos Livro Texto
 191
 Testes e depurac ¸˜ ao
 No momento, n˜ ao h´a ainda uma rotina de testes completamente definida, mas h´ a um
 primeiro esboc ¸o de como se construir um arcabouc ¸o para testes de unidade e integrac ¸˜ao
 no sub-diret´ orio test/.
 Um dos objetivos maiores de POX ´e dotar o ambiente SDN de mecanismos de
 depurac¸˜ ao sofisticados que integrem as diversas camadas de uma rede definida por soft
ware. Em sua vers˜ao atual, entretanto, h´a apenas um sistema de depurac¸˜ao que aumenta
 os n´ ıveis de avisos e de gerac¸˜ao de logs, habilita a detecc ¸˜ao de deadlocks e outras me
didas ´ uteis. Esse sistema ´e iniciado ao se executar ./pox.debu.py ao inv´ es do co
mando original. Al´em disso, pode ser ´ util se incluir nos m´ odulos desenvolvidos recursos
 de execuc¸˜ ao passo-a-passo, o que pode ser feito ao se executar a linha import pdb;
 pdb.set
 trace(), que iniciar´a a execuc ¸˜ ao passo-a-passo.
 Registro no pox.core
 Aoexecutar, o objeto pox.core ´e criado e oferece a funcionalidade de se registrar obje
tos arbitr´arios, que passam a ser acess´ ıveis para os m´ odulos do sistema. Por exemplo, vocˆ e
 pode escrever o c´ odigo de um tipo de comutador de rede, que pode ent˜ao ser registrado
 como pox.core.switch em tempo de execuc¸˜ao. Uma vantagem disso ´ e que outros
 podemposteriormente implementar um comutador totalmente diferente que implemente a
 mesma interface de programac¸˜ao e registr´ a-lo como pox.core.switch, por sua vez.
 Outras aplicac¸˜ oes que utilizem a interface do comutador podem continuar a funcionar,
 sem modificac¸˜ oes. Uma vantagem desse mecanismo ´ e que ele depende menos do uso de
 comandos import do Python, reduzindo o c´ odigo de inicializac¸˜ ao. Como exemplo, o
 c´ odigo a seguir, do m´ odulo of
 01, cria um objeto respons´ avel pelas tarefas de controle
 do protocolo OpenFlow e registra-o para que o mesmo seja facilmente referenciado por
 outros objetos:
 def launch (port = 6633, address = ‘‘0.0.0.0’’):
 if core.hasComponent(’of_01’):
 return None
 l = OpenFlow_01_Task(port = int(port), address = address)
 core.register(‘‘of_01’’, l)
 return l
 Orientac ¸˜ ao a eventos
 POX usa eventos frequentemente. O sistema de controle de eventos ´e implementado na
 biblioteca revent. O princ´ ıpio geral da implementac ¸˜ao ´e que objetos se tornam eventos,
 n˜ao apenas uma colec¸˜ao de campos e m´etodos. Um objeto pode disparar eventos e outros
 podem esperar por eventos gerados por aquele objeto registrando um tratador (handler)
 com ele. Tratadores de eventos executam de forma n˜ ao preemptiva, at´e o seu fim.
 Um objeto se torna uma fonte potencial de eventos ao herdar de EventMixin
 (apesar dessa classe ter sido projetada com o objetivo de ser adequada para a combinac ¸˜ao
192
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 em tempo de execuc ¸˜ ao de classes e objetos, n˜ao h´a suporte a isso no momento e a ´ unica
 forma de uso apoiada no momento ´ e herdando-se dela). Tal objeto normalmente espe
cificar´a quais tipos de eventos ele pode disparar, apesar disso n˜ ao ser obrigat´ orio. Os
 eventos propriamente ditos s˜ao normalmente classes que estendem Event e passam a
 possuir certas caracter´ ısticas, mas na pr´atica podem ser qualquer coisa. Qualquer objeto
 interessado em um evento pode registrar um tratador para ele.
 ´
 E poss´ ıvel tamb´ em registrar o interesse em todos os eventos disparados por
 um objeto de forma impl´ ıcita com m´ etodos como EventMixin.listenTo().
 Nesse caso, se Foo e Bar herdam ambos de EventMixin e Bar dispara even
tos timeout, newMsg e linkFailure e Foo define m´etodos handle
 timeout,
 handle
 newMsg e handle
 linkFailure, Foo pode associar todos esses trata
dores diretamente aos eventos apropriados de Bar simplesmente executando o m´ etodo
 self.listenTo(someBarObject). Essa forma ´e usualmente mais simples que
 registrar cada tratador para um n´ umero de eventos.
 4.7.2. Modelo de threads
 Na maioria das vezes o modelo de eventos n˜ao levanta a necessidade da preocupac ¸˜ao
 do uso de threads, por´ em, caso um componente precise utilizar alguma forma de con
corrˆ encia pode ser interessante entender o modelo de threads usado no POX.
 Omodelo de threads do POX ´ e programado como a biblioteca de nome recoco
 para poder criar um ambiente de threads cooperativas, que em um modelo no qual as
 pr´ oprias threads delegam o processamento entre si, ao contr´ario do modelo preemptivo
 no qual o sistema operacional ativamente interrompe o processamento e o delega a outra
 thread.
 As threads cooperativas precisam ser criadas criando uma classe que estenda
 recoco.Taskeimplementeumm´etodo run. Ap´ os a criac ¸˜ ao a thread precisa ser esca
lonada e quando for escolhida para executar, ela pode considerar que executar´a atomica
mente at´ e terminar ou at´ e entregar o processamento (atrav´ es de func¸˜ oes como o Sleep,
 por exemplo).
 Portanto ´e importante ficar atento que qualquer operac¸˜ao blocante ir´a bloquear o
 funcionamento do sistema por completo.
 Nada impede que sejam escritos componentes que usam o modelo preemptivo
 padr˜ao do python, por´ em ´e importante atentar que o modelo preemptivo ir´ a funcionar em
 paralelo com o modelo cooperativo, o que pode causar problemas no desenho de alguns
 componentes e dados inconsistentes.
 Alguns dos problemas causados por esse tipo de interac¸˜ ao podem ser corrigidos
 com as seguintes ac ¸˜ oes:
 1. Se somente ´ e desejado que uma thread normal se comunique com uma task coope
rativa do recoco, isso pode ser feito utilizando locks normais e estruturas threadsafe
 como odequeuedoPython. (comcuidado para que os locks inseridos n˜ ao travem
 o processamento das outras tasks por muito tempo)
 2. Se uma thread s´ o precisa se comunicar com eventos usando a biblioteca
Minicursos Livro Texto
 193
 revent, ela pode usar a func ¸˜ao POX.deferedRaise() no lugar de
 self.raiseEvent(). A primeira func¸˜ ao ir´a levantar um evento de dentro de
 uma task, fazendo isso de modo seguro.
 3. Uma thread normal pode executar c´ odigo dentro de um bloco com
 recoco.scheduler.synchronized():. Ao executar dentro de um bloco
 com essa marcac¸˜ ao, a thread nativa ir´ a esperar por uma oportunidade de parar as
 threads cooperativas. E assim, executar´a o c´ odigo dentro do bloco antes de permitir
 que as outras threads cooperativas executem novamente.
 Outra funcionalidade que a biblioteca recoco implementa ´ e um Timer simples
 para funcionar com esse modelo de threads cooperativas. Ele funciona de forma similar
 ao Timer comum do Python, como no exemplo a seguir:
 from pox.lib.recoco import Timer
 self._timer = Timer(30.0, self._timerHandler, recurring=True)
 Esse trecho de c´ odigo chama o timer a cada 30 segundos para executar a
 func¸˜ao timerHandler definida no pr´ oprio m´ odulo de forma recorrente. Os demais
 parˆametros definidos para o construtor da classe Timer s˜ao os seguintes:
 timeToWake
 callback
 absoluteTime
 recurring
 args, kw
 scheduler
 started
 tempo a esperar antes de chamar o callback (segundos)
 funcao a ser chamada quando o timer expirar
 uma hora especifica para executar (usa time.time())
 chama o timer repetidamente ou somente uma vez
 argumentos para a funcao de callback
 escalonador recoco a usar (None escolhe o default)
 se False, precisa chamar .start() para iniciar o timer
 selfStoppable se True, callback pode retornar False para parar o timer
 def __init__ (self, timeToWake, callback, absoluteTime = False,
 recurring = False, args = (), kw = {}, scheduler = None,
 started = True, selfStoppable = True):
 4.7.3. Organizac ¸˜ ao do c´ odigo
 Em sua vers˜ ao atual, o c´ odigo fonte do POX est´a dividido em um conjunto de diret´ orios
 que compreende tanto m´ odulos essenciais para seu funcionamento b´asico quanto compo
nentes adicionais que oferecem funcionalidades adicionais ´ uteis.
 4.7.4. Componentes
 Componente no POX ´e o nome dado ` as aplicac ¸˜ oes que s˜ao programadas para executar
 sobre ele, utilizando a sua interface para realizar uma determinada tarefa sobre a rede
 controlada. Essas aplicac¸˜ oes podem ser inclu´ ıdas pelo desenvolvedor para aproveitar as
 funcionalidades j´a implementadas.
 Os seguintes diret´ orios contˆ em um ou mais componentes com suas determinadas
 func¸˜ oes:
194
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 • gui backend: Tem a finalidade de oferecer informac¸˜ oes para o plugin de interface
 gr´afica do POX. Ele monitora as informac¸˜ oes que passam pelo controlador para
 reunir dados necess´ arios para a interface gr´ afica.
 • host tracker: Mant´em informac¸˜ oes sobre as m´aquinas conectadas `a rede, em ter
mos de emqual porta de qual switch OpenFlow elas est˜ ao conectadas e como est˜ao
 configuradas (enderec ¸o MAC e IP, quando dispoon´ ıvel). Essa informac ¸˜ ao pode ser
 usada, por exemplo, para implementar um servic ¸o de ARP diretamente no n´ ucleo
 da rede. Futuramente essa informac ¸˜ ao pode ser integrada com os componentes de
 topologia.
 • messenger: Este componente possibilita a comunicac ¸˜ ao entre o POX e aplicac ¸˜ oes
 externas atrav´es de mensagens codificadas em JSON. Dessa forma ´e poss´ ıvel reu
nir informac ¸˜ oes no controlador e se comunicar com o mundo exterior de diversas
 formas independentes do protocolo de comunicac ¸˜ ao.
 • misc: Componentes diversos. No momento possui dois componentes, dnsspy
 e recocospy, que apresentam apenas informac¸˜ oes para depurac¸˜ao do protocolo
 DNSedabiblioteca de threads adotada.
 • samples: Pacote de componentes simples que servem como exemplo de
 programac ¸˜ ao do POX. No momento possui 4 exemplos simples de diferentes ti
pos de componentes que utilizam diferentes partes do sistema a fim de servir como
 base para a construc ¸˜ ao de componentes mais complexos.
 • topology: Reune informac¸˜ oes da topologia da rede populada por demais compo
nentes.
 • web: Pacote de componentes que permitem a criac¸˜ ao de um servidor web para
 interagir com o mundo exterior. No momento possui um componente de framework
 web e uma interface para exibir mensagens do componente messenger em um
 servidor web.
 • forwarding: Conjunto de componentes que trata do encaminhamento de pacotes.
 Possui diversas implementac¸˜ oes que simulam switches (n´ ıveis 2 e 3) com compor
tamento diferenciado para o ambiente openflow.
 4.7.5. M´ odulos de funcionamento
 Os m´ odulos de funcionamento incluem o n´ ucleo do POX e bibliotecas auxiliares.
 • log: Controla o n´ ıvel e a formatac ¸˜ ao dos logs do POX.
 • lib: Bibliotecas auxiliares, como implementac¸˜ oes de pol´ ıticas de threads,
 manipulac ¸˜ao de enderec¸os, eventos, pacotes e outras bibliotecas que s˜ ao utilizadas
 pelos componentes.
 • openflow: Implementac ¸˜ ao do protocolo Openflow. Possui n˜ao s´ o uma interface
 para a criac ¸˜ ao e tratamento de pacotes OpenFlow como alguns componentes de
 exemplo que utilizam essa interface.
Minicursos Livro Texto
 195
 • core.py: N´ ucleo do POX, possui func¸˜ oes base para criac¸˜ao de componentes, como
 func¸˜ oes de registrar componentes, eventos, etc.
 •
 init .py: Construtor do POX.
 • license.py: Listagem da licenc ¸a GPL.
 De interesse particular, s˜ ao o m´ odulo openflow, o m´ odulo packet, e a bibli
oteca revent, que ´e a respons´avel por gerar os eventos do POX, j´a discutidos anterior
mente.
 Biblioteca openflow
 A biblioteca openflow implementa facilidades para a comunicac ¸˜ ao com comutadores
 OpenFlow e para a recepc ¸˜ ao e gerac¸˜ ao de pacotes do protocolo OpenFlow. Cada vez que
 um comutador OpenFlow se torna ativo no sistema, ele estabelece uma conex˜ao com o
 controlador. Essa conex˜ao ´ e representada por um objeto no sistema que ´ e tamb´ em um
 evento e pode ser observado por elementos que se interessem pelo surgimento de novos
 comutadores, como o m´ odulo que mant´ em a vis˜ ao da topologia da rede.
 Por exemplo, pacotes oriundos dos comutadores OpenFlow s˜ ao recebidos pelo
 m´ odulo openflow e geram um evento PacketIn, que pode ser observado por qualquer
 objeto que esteja interessado na chegada de um pacote. Esse evento pode ser observado
 ao se registrar um tratador com o controlador propriamente dito, ou pode ser observado
 diretamente no objeto representando a conex˜ ao de um comutador em particular.
 Para criar uma ac¸˜ ao de output, existe a func¸˜ao ofp
 action
 output que ao
 receber uma porta do switch j´ a cria uma estrutura de dados de ac ¸˜ ao para ser concatenada
 a uma mensagem criada com a func ¸˜ ao ofp
 packet
 out atrav´ es da func¸˜ ao append
 presente no objeto actions e depois ser enviada para o switch. Todo esse processo
 pode ser ilustrado pelos seguintes comandos:
 msg = of.ofp_packet_out()
 msg.actions.append(of.ofp_action_output(port = of.OFPP_FLOOD))
 self.connection.send(msg)
 Biblioteca packet
 Abiblioteca packet possibilita que se acesse detalhes do pacote sendo manipulado. Por
 exemplo, umpacote recebido por umevento PacketIn, ap´ ossertraduzido comafunc¸˜ao
 parsepossuioscampossrcedstquecorrespondemaosenderec¸osEthernetdopacote
 identificado. Tamb´ em ´e interessante considerar o campo next que possui informac ¸˜ oes
 sobre o pr´ oximo cabec ¸alho do pacote, como qual protocolo ele segue (IP, ARP, etc). Por
 exemplo, um pacote IP possui informac¸˜ oes do IP de origem e destino atrav´es dos campos
 next.protosrc e next.protodst. A utilizac¸˜ao desses campos ficar´a mais clara
 no exemplo de componente que ser´a comentado posteriormente.
196
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 Mais detalhes sobre as func ¸˜ oes presentes duas bibliotecas podem ser encontrados
 nos links http://www.noxathome.org/doc/pox/pox.openflow.libopenflow_
 01.html e http://www.noxathome.org/doc/pox/pox.lib.revent.revent.
 html.
 4.7.6. Exemplo de programac ¸˜ ao de um componente POX
 Umcomponente no POX ´ e uma implementac¸˜ao de uma aplicac ¸˜ ao que usa o Framework
 para escutar e levantar eventos. No POX ´e bem simples criar e levantar um componente.
 Primeiro ser´a tratada a parte de criac¸˜ ao de um componente e depois como execut´ a-lo e
 test´a-lo.
 4.7.7. Criac ¸˜ ao de um componente m´ ınimo
 OPOXfacilita muito a criac ¸˜ao de componentes. Primeiro ´e necess´ario criar um diret´ orio
 dentro do diret´ orio pox ou ext, que s˜ ao os diret´ orios comuns para a pesquisa de compo
nentes. Por exemplo, ser´a criado o diret´ orio ext/foo.
 Dentro deste diret´ orio ser´a criado o construtor init
 .py eom´ odulo do com
ponente foo.py. O construtor ´e necess´ario somente se o componente for chamado pelo
 nomedodiret´ orio, caso contr´ ario o componente pode ser chamado pelo nome do diret´ orio
 seguido por um ponto seguido pelo nome do arquivo (por exemplo, foo.foo). Caso seja
 interessante chamar o componente pelo nome do diret´ orio, o m´ etodo launch deve estar
 listado no construtor, caso contr´ario no arquivo que ser´a chamado (no nosso exemplo, o
 foo.py).
 Om´etodo launch ´e executado assim que o POX chama o componente. Ele tem
 como finalidade registrar um m´ odulo como componente no n´ ucleo do POX. Em nosso
 exemplo o m´ etodo launch localizado no construtor que chama a classe classe Foo no
 arquivo foo.py seria o seguinte:
 def launch (number, food = "spam"):
 from foo import Foo
 from pox.core import core
 core.registerNew(foo.Foo)
 Note que dois argumentos s˜ao necess´ arios, number e food, sendo que food ´ e
 automaticamente colocado com o valor “spam” caso nenhum argumento seja passado. A
 chamada do POX para esse novo componente criado com os parˆ ametros utilizados deve
 ser da seguinte forma:
 ./pox.py foo--food=eggs--number=42
 No arquivo foo.py ´ e necess´ario que a classe Foo herde a classe EventMixIn
 para que seja possibilitada de levantar eventos e que utilize a func ¸˜ ao herdada listenTo
 para poder escutar os eventos levantados. Por exemplo:
 class Foo (EventMixin):
 def __init__ (self):
 self.listenTo(core.openflow)
Minicursos Livro Texto
 197
 Agora o componente Foo j´a escuta a eventos, mas tamb´em ´ e necess´ ario criar
 func¸˜ oes para tratar certos eventos. Para tratar o evento ConnectionUp, levantado toda
 vez que o POX detecta uma nova conex˜ao, ´ e necess´ario que a classe Foo possua um
 m´ etodo handle
 ConnectionUp (em outros eventos bastaria mudar o nome de Con
nectionUp para o evento desejado). Esse m´etodo recebe como parˆametro o pr´ oprio evento
 e pode realizar qualquer computac ¸˜ ao com ele.
 def _handle_ConnectionUp (self, event):
 log.debug("Connection %s" % (event.connection,))
 ...
 4.7.8. Um componente mais realista: Switch L2
 Para exemplificar melhor o funcionamento de um componente, vamos usar o exemplo de
 um componente que simula um switch L2 com aprendizado a partir de um comutador
 OpenFlow. O comportamento desse switch ´ e simplificado e segue o padr˜ ao a seguir:
 Para cada novo fluxo PacketIn:
 1) Use enderec¸o/porta de origem p/ atualizar tabela enderec¸o/porta
 2) O tipo do pacote Ethernet ´ e LLDP?
 Sim:
 2a) Descarte o pacote-- LLDP nunca ´ e encaminhado
 FIM
 3) O destino ´ e multicast?
 3a) Envie o pacote por todas as portas
 FIM
 4) O enderec¸o de destino N˜ AO est´ a na tabela enderec¸o/porta?
 4a) Envie o pacote por todas as portes
 FIM
 5) A porta de sa´ ıda ´ e a mesma de entrada?
 5a) Descarte o pacote e seus similares por um tempo
 6) Instale uma entrada na tabela de fluxos do switch
 para que este fluxo siga para a porta apropriada
 6a) Envia os dados do pacote para a porta apropriada
 FIM
 Os passos do processamento descrito devem ser facilmente entendidos em face do
 comportamento usual de switches Ethernet com aprendizado. O passo 2, entretanto, trata
 umaspecto particular de funcionamento de redes OpenFlow. Cada comutador OpenFlow
 pode executar o protocolo de descoberta de enlaces, LLDP. Esse protocolo permite, por
 exemplo, que cada comutador identifique seus vizinhos; dessa forma, ele poderia ser
 utilizado para a construc¸˜ ao de um mecanismo de composic ¸˜ ao da vis˜ao global da rede
 mencionada anteriormente. Neste exemplo, esses pacotes s˜ao apenas descartados.
 Oc´ odigo completo ´ e apresentado nas figuras 4.10 e 4.11. Elementos importantes
 do c´ odigo s˜ ao discutidos a seguir. Comando de log s˜ ao utilizados de forma simplificada
 para reduzir o tamanho do c´ odigo. Posteriormente discutimos o uso de mensagens de log
 mais elaboradas usando recursos de Python.
198
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 1
 2
 3
 4
 5
 6
 7
 8
 9
 10
 11
 12
 13
 14
 f actory (EventMixin ):
 class l2
 ”””
 Espera por conexoes de switches OpenFlow e cria o objeto para
 t ransform´ a−los em switches L2 com aprendizado .
 ”””
 def
 i n i t
 ( self ):
 s elf . listenTo ( core . openflow )
 def
 handle ConnectionUp ( self , event ):
 l og . debug(”Connection %s” % ( event . connection ,))
 LearningSwitch ( event . connection )
 def launch ():
 core . registerNew ( l2
 f actory )
 Figura 4.10. C´ odigo geral para registro de switches L2 com aprendizado no POX
 O c´ odigo da figura 4.11 define a classe LearningSwitch, que implementa
 o switch propriamente dito. Antes de analisarmos esse c´ odigo, entretanto, devemos
 observar que o c´ odigo da figura 4.10 define outra classe derivada de EventMixin,
 l2
 factory. Essa ´ ultima classe age como uma f´abrica de switches: seu construtor
 (linhas 6–7) se registra com o componente openflow do core, de forma que o tratador
 de eventos para novas conex˜ oes (novos comutadores) ´e instalado (linhas 9–11). Ao de
tectar uma conex˜ao de um novo comutador um objeto da classe LearningSwitch ´ e
 criado e associado `a conex˜ ao. As linhas 13–14 definem a func¸˜ao launch() para esse
 m´ odulo: ela registra um objeto da classe construtora junto ao core do POX.
 J´a na figura 4.11, encontramos a definic ¸˜ao do comportamento dos switches com
 aprendizado, como discutido anteriormente. A classe LearningSwitch tamb´em herda
 de EventMixin para ser capaz de tratar eventos de chegada de pacotes. Objetos
 dessa classe comec ¸am (construtor, linhas 2–5) identificando a conex˜ ao de controle do
 comutador OpenFlow, criando um dicion´ ario para registrar os enderec¸os MAC conheci
dos e registrando-se para receber eventos gerados pelo comutador — nesse caso, even
tos de PacketIn. O restante do c´ odigo corresponde `a implementac ¸˜ ao do algoritmo
 discutido anteriormente, onde os passos s˜ao identificados pela numerac ¸˜ ao apresentada
 nos coment´arios. As func ¸˜ oes drop() e flood() foram ocultadas assim como as
 importac ¸˜ oes de pacotes para simplificar o c´ odigo.
 Alguns detalhes de implementac¸˜ao que merecem destaque s˜ao o processamento do
 pacote para identificac¸˜ao dos cabec¸alhos dos diversos protocolos que o comp˜ oem (linha
 12), o preenchimento da tabela de enderec¸os (linha 13) e o acesso a diversas informac ¸˜ oes
 derivadas do processamento do pacote (linhas 15, 19, 23), o uso de func ¸˜ oes de log para
 registrar a evoluc¸˜ ao do c´ odigo. Finalmente, as linhas de 35 a 41 comp˜ oem a mensagem
 OpenFlow usada para registrar o fluxo no comutador, com a regra para encaminhar o
 pacote para a porta de sa´ ıda identificada pela tabela de enderec ¸os MAC.
MinicursosLivroTexto 199
 1 class LearningSwitch (EventMixin):
 2 def init (self , connection):
 3 self .connection = connection # Switch que ser´a controlada
 4 self .macToPort = {} # Tabela interna
 5 self . listenTo(connection) # Para ouvir eventos PacketIn
 6
 7 def handle PacketIn (self , event ):
 8 ”””
 9 Trata os pacotes das mensagens do switch para o algoritmo.
 10 Metodos auxiliares flood() e drop( ) seriam definidas aqui .
 11 ”””
 12 packet = event .parse()
 13 self .macToPort[packet . src] = event .port # 1
 14
 15 if packet . type == packet .LLDPTYPE: # 2
 16 drop()
 17 return
 18
 19 if packet .dst . isMulticast (): # 3
 20 flood() # 3a
 21 return
 22
 23 if packet .dst not in self .macToPort: # 4
 24 log.debug(”Port for %s unknown− flooding”% (packet .dst ,))
 25 flood() # 4a
 26 return
 27
 28 port = self .macToPort[packet .dst]
 29 if port == event .port : # 5
 30 log.warning(”Same port . Drop.”)
 31 drop(10) # 5a
 32 return
 33
 34 log.debug(”installing flow”)
 35 msg = of .ofp flowmod() # 6
 36 msg.match = of .ofpmatch. from packet(packet)
 37 msg. idle timeout = 10
 38 msg.hard timeout = 30
 39 msg.actions .append(of .ofp action output (port = port ))
 40 msg.buffer id = event .ofp.buffer id # 6a
 41 self .connection.send(msg)
 Figura4.11.C´ odigoparaimplementac ¸˜ aodeumswitchL2comaprendizadonoPOX
 4.7.9. Exemplodelevantamentodeevento:componentedetopologia
 Al´ emdepoderescutarereagiraeventos,podeserinteressantelevantarumeventopara
 ser tratadoporoutroscomponentes. Essetipodeinterfacesimplificaaamarrac ¸˜aoentre
200
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 diferentes m´ odulos.
 Primeiro, ´ e necess´ ario identificar o tipo de eventos que o componente pode levan
tar. No componente de topologia isso ´ e feito da seguinte forma:
 class Topology (EventMixin):
 _eventMixin_events = [
 SwitchJoin,
 SwitchLeave,
 HostJoin,
 HostLeave,
 EntityJoin,
 EntityLeave,
 Update
 ]
 Al´ em de herdar a classe EventMixinparapoderlevantareventos, comodescrito
 anteriormente, a lista eventMixin
 events ´e alimentada com a lista dos eventos que
 o m´ odulo pode levantar. Cada um desses eventos ´ e uma classe definida anteriormente que
 herda alguma classe de eventos e pode ser levantado utilizando a func ¸˜ ao raiseEvent
 da classe EventMixin. No caso do componente de topologia, essa func¸˜ao ´ e reescrita
 para adicionar um tratamento especial ao evento de Update, mas logo em seguida a
 func¸˜ao da superclasse ´ e chamada normalmente:
 def raiseEvent (self, event, *args, **kw):
 """
 Sempre que um evento for levantado, um evento de Update tambem
 sera levantado, por isso reescrevemos o metodo do EventMixin
 """
 rv = EventMixin.raiseEvent(self, event, *args, **kw)
 if type(event) is not Update:
 EventMixin.raiseEvent(self, Update(event))
 return rv
 No caso, a func¸˜ao da superclasse recebe, al´em do objeto do pr´ oprio componente,
 um objeto do tipo do evento a ser levantado, como ´ e mostrado com o evento Update.
 Ap´ os essa ac ¸˜ ao de levantamento de eventos, todos os componentes que possu´ ırem uma
 func¸˜ ao de tratamento para esses eventos (como por exemplo, handle
 HostJoin) po
der˜ao trat´ a-los normalmente como qualquer outro evento do POX.
 4.7.10. Utilizac ¸˜ ao do componente de log
 O POX tem uma funcionalidade de logging facilmente utilizada e configur´avel em di
versos n´ ıveis. Para ter acesso a essa ferramenta, basta utilizar a func¸˜ao getLogger
 da biblioteca core, passando o nome do componente registrado que vocˆe deseja aces
sar (caso nenhum nome seja passado, o log retornado utilizar´a o nome do componente
 corrente).
 Portanto, basta recuperar o log do componente corrente com a linha:
Minicursos Livro Texto
 201
 log = core.getLogger()
 Essa operac ¸˜ao foi ocultada no c´ odigo da figura 4.11 por quest˜ oes de espac ¸o.
 A classe de log do POX utiliza o logging padr˜ao do python, portanto utiliza o
 mesmo formato de m´ etodos e string para poder exibir as mensagens, como os seguintes
 m´ etodos:
 Logger.info(msg, *args, **kwargs)
 Logger.warning(msg, *args, **kwargs)
 Logger.error(msg, *args, **kwargs)
 Logger.critical(msg, *args, **kwargs)
 Logger.log(lvl, msg, *args, **kwargs)
 Logger.exception(msg, *args)
 Grac¸as aos recursos de manipulac¸˜ ao de strings de Python, ´e poss´ ıvel construir-se
 mensagens bastante informativas sem que as func ¸˜ oes de logging precisem manipular um
 grande n´ umero de argumentos. Por exemplo, uma mensagem de registro mais completa
 para registrar a instalac ¸˜ao de um novo fluxo no comutador (linha 34) na figura 4.11 poderia
 ser re-escrita como:
 log.debug("installing flow for %s.%i-> %s.%i" %
 (packet.src, event.port, packet.dst, port))
 Mais detalhes sobre a classe logging do python podem ser encontrados em http:
 //docs.python.org/library/logging.html.
 Al´ em disso, o POX permite que sejam declarados diferentes n´ ıveis para o log
 de cada componente durante a inicializac¸˜ ao atrav´es de parˆ ametros para o launch do
 componente de log. Por exemplo, para carregar o componente web.webcore com um
 n´ ıvel de log somente de INFO enquanto os outros componentes mantˆ em o n´ ıvel de log
 padr˜ ao, o POX dever´ a ser chamado da seguinte forma:
 ./pox.py web.webcore log.level--web.webcore=INFO
 Esse comando chama o componente web.webcore e o componente
 log.level, passando para o ´ ultimo o parˆametro web.webcore=INFO, o que de
f
 inir´ a o n´ ıvel de INFO para o log do componente web.webcore.
 4.7.11. Testando seu componente com o Mininet
 O Mininet ´ e um simulador de rede OpenFlow que consiste em criar um conjunto de
 m´ aquinas virtuais conectadas por switches OpenFlow utilizando uma interface simples
 para configurar, monitorar e modificar esta rede. Com o Mininet ´e poss´ ıvel simular uma
 rede com v´ arios n´ os para testar um componente em um ambiente mais simplificado e de
 f´ acil manipulac ¸˜ao.
 No momento o Mininet oferece uma imagem de m´aquina virtual j´ a instalada e
 configurada com a aplicac¸˜ao compilada e funcional. Para utiliz´a-la basta utilizar um
202
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 monitor de m´aquinas virtuais (a imagem disponibilizada ´e do VirtualBox em http:
 //www.openflow.org/downloads/OpenFlowTutorial-101311.zip ).
 Aolevantar a imagem disponibilizada em um monitor de m´aquinas virtuais, basta
 logar na m´ aquina (usu´ario: openflow senha: openflow) e configurar o Mininet para usar o
 POXcomocontrolador.
 Por exemplo, em uma m´ aquina que o IP da m´aquina executando o POX seja
 10.1.1.1 e ´e interessante que ele seja levantado no porto 6634 (o padr˜ ao ´e 6633), na
 m´ aquina controladora deve ser levantado o POX:
 ./pox.py <componente>--address=10.1.1.1--port=6634
 J´a na m´aquina virtual do Mininet ´ e necess´ ario apontar para o controlador levan
tado:
 sudo mn--controller=remote--ip=10.1.1.1--port=6634
 Mais informac ¸˜ oes sobre como configurar e utilizar o Mininet podem ser encon
tradas nos links http://yuba.stanford.edu/foswiki/bin/view/OpenFlow/
 MininetGettingStarted, http://yuba.stanford.edu/foswiki/bin/view/
 OpenFlow/MininetVMSetupNotes e http://yuba.stanford.edu/foswiki/
 bin/view/OpenFlow/MininetWalkthrough .
 4.8. Desafios de pesquisa
 O paradigma de Redes Definidas por Software abre uma grande gama de novas possi
bilidades para a pesquisa em Redes de Computadores. A sec¸˜ao 4.6 discutiu diversos
 contextos de aplicac¸˜ao em que a aplicac¸˜ao de SDN pode oferecer novas possibilidades de
 evoluc ¸˜ ao e novos enfoques. Al´em deles, certamente outras formas de aplicac ¸˜ ao do para
digma ainda est˜ ao por ser identificados e desenvolvidos em modelos de pesquisa consoli
dados.
 Umponto importante a considerar ´e que o conceito de Redes Definidas por Soft
ware em si ainda ´e algo novo e muito h´ a para se fazer no sentido de consolidar o para
digma. Nesse sentido, diversos desafios de pesquisa ainda se apresentam para aqueles
 que desejem avaliar os princ´ ıpios norteadores dessa nova ´area. Quest˜ oes como qual a
 abstrac ¸˜ao de programac ¸˜ ao mais adequada, como implementar mecanismos de depurac¸˜ao,
 como lidar com quest˜ oes como distribuic¸˜ ao do controlador para lidar com aspectos de
 desempenho e confiabilidade, se apresentam como ´ areas abertas para a pesquisa.
 Vis˜ ao da rede
 Um dos elementos chave do conceito de SDN ´ e a noc¸˜ao da vis˜ ao geral da rede dis
pon´ ıvel atrav´ es do controlador da rede. Os controladores atuais ainda n˜ ao apresentam
 essa vis˜ao como um elemento estrutural b´asico, apesar dela poder ser constru´ ıda com
 base nas informac ¸˜ oes derivadas das mensagens recebidas. H´ a uma expectativa de que
Minicursos Livro Texto
 203
 POX oferec ¸a essa vis˜ao como um elemento arquitetˆ onico b´ asico, atrav´es da noc¸˜ ao do
 “Modelo de Objetos da Rede”, o Network Object Model (NOM). Essa abstrac¸˜ao permi
tir´ a ao desenvolvedor de aplicac¸˜ oes SDN exprimir suas demandas e as ac¸˜ oes esperadas em
 func¸˜ao do grafo de rede e n˜ao mais como c´ odigo reativo organizado ao redor dos eventos
 de chegada de mensagens OpenFlow.
 Em um primeiro n´ ıvel, o NOM deve refletir uma vis˜ ao bastante clara da infra
estrutura que constitui a rede f´ ısica e principais elementos de software relacionados, como
 switches Open vSwitch. Os objetos dessa representac ¸˜ao devem exportar interfaces que
 permitam ao desenvolvedor representar ac¸˜ oes como a chamada de m´etodos implementa
dos por esses objetos. Esses m´ etodos, por sua vez, se responsabilizariam pela emiss˜ao
 de mensagens OpenFlow ou de qualquer padr˜ao de controle dos elementos de rede que
 esteja dispon´ ıvel.
 Sobre essa vis˜ao da rede f´ ısica, pode-se construir novas vis˜ oes que representem
 a vis˜ ao do usu´ario/desenvolvedor para uma aplicac ¸˜ao espec´ ıfica. Essa vis˜ ao pode n˜ao
 conter todos os n´ os da rede f´ ısica, incluir enlaces que n˜ ao existem na rede subjacente,
 mas que podem ser implementados como t´ uneis sobre a mesma, ou ainda elementos de
 rede virtualizados, como comutadores virtuais distribu´ ıdos.
 Sistema operacional da rede
 Em diversos pontos deste curso nos referimos `a noc¸˜ ao de Sistema Operacional da Rede,
 como o ambiente de execuc¸˜ao que estabelece a ligac¸˜ao entre as aplicac¸˜ oes SDN e o subs
trato da rede f´ ısica. O Professor Scott Shenker, em suas palestras, tem chamado a atenc ¸˜ao
 para o fato de que esse conceito pode abrir o caminho para uma nova forma de se ver
 e pensar Redes de Computadores, n˜ao mais em termos de artefatos tecnol´ ogicos mas de
 princ´ ıpios organizacionais abstratos, como ocorre com a ´area de Sistemas Operacionais
 propriamente dita: pesquisadores podem utilizar noc¸˜ oes com escalonamento de proces
sos, algoritmos de sincronizac˜ao e estruturas de dados para mem´ oria virtual para pen
sar sobre os princ´ ıpios b´ asicos da ´ area. Com esse enfoque, um desafio importante ´e a
 identificac ¸˜ao de quais seriam os blocos arquitetˆ onicos essenciais para a ´area de Redes de
 Computadores que seriam adicionados ao ambiente de tempo de execuc¸˜ ao de um con
trolador SDN, para compor soluc¸˜ oes como as poss´ ıveis em outras ´areas da Ciˆencia da
 Computac ¸˜ao, como Sistemas Operacionais ou Bancos de Dados, que j´a se organizaram
 em torno desses conceitos b´ asicos.
 Virtualizac ¸˜ ao de rede
 Continuando a aplicac¸˜ao da noc¸˜ ao de Sistema Operacional de Rede, chega-se rapidamente
 ao princ´ ıpio de virtualizac¸˜ao de redes. Esse conceito, bastante em voga recentemente em
 projetos como o GENI, prop˜ oe uma nova forma de se organizar as redes f´ ısicas, de forma
 a permitir a coexistˆ encia de diferentes aplicac ¸˜ oes, redes l´ ogicas e mesmo arquiteturas de
 rede. Em sua origem, a partir da rede PlanetLab, a id´ eia de se utilizar m´aquinas virtuais
 para representar roteadores virtuais tem sido bastante discutida. Entretanto, esse tipo de
 virtualizac ¸˜ ao enfrenta o desafio de vencer a barreira entre essas m´ aquinas virtuais e uma
204
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 implementac ¸˜ao eficiente do plano de dados nesse roteadores, uma vez que nas redes atuais
 a otimizac¸˜ao do hardware de encaminhamento de pacotes atingiu patamares significativos
 que s˜ao dif´ ıceis de se equiparar em software.
 O fato de Redes Definidas por Software darem acesso ` as tabelas de encaminha
mento de forma program´avel oferece uma nova forma de se virtualizar a rede: n˜ ao mais
 com m´aquinas virtuais independentes para cada elemento da rede virtual, mas com o
 particionamento dos espac¸os de enderec ¸amento dessas tabelas. Assim, vis˜ oes abstratas
 da rede, como grafos virtuais, podem ser oferecidos a cada pesquisador/desenvolvedor
 que deseje implantar um novo servic¸o/arquitetura sobre a rede f´ ısica. Como discutido na
 sec¸˜ao 4.4, FlowVisor oferece exatamente essa funcionalidade. Entretanto, continuando
 o paralelo com a ´ area de Sistemas Operacionais, essa seria apenas uma das dimens˜ oes
 poss´ ıveis sobre a qual se organizar uma camada de virtualizac¸˜ ao. Assim como monito
res de m´aquinas virtuais podem se organizar diretamente sobre o hardware, ou sobre a
 interface do Sistema Operacional, ou ainda como uma m´aquina virtual Java, tamb´ em no
 contexto de SDNpodemhaverdiferentes formas de se expressar a noc¸˜ ao de redes virtuais,
 comdiferentes compromissos em termos de desempenho, poder de express˜ ao e facilidade
 de uso. A extens˜ ao do NOM em POX para incluir elementos virtualizados sobre a vis˜ ao
 direta da rede f´ ısica ´e um caminho poss´ ıvel, mas que ainda precisa ser melhor compreen
dido e melhor definido. Outros podem existir; por exemplo, o que seria o equivalente do
 recurso de para-virtualizac ¸˜ao no contexto de Sistemas Operacionais de Rede?
 Abstrac ¸˜ oes de encaminhamento
 Apesar de OpenFlow ter ganhado larga aceitac¸˜ ao como a interface primordial de acesso
 aos mecanismos de encaminhamento de cada comutador da rede, a ´ area de SDN n˜ ao
 deveria se restringir a ela. Como mencionado anteriormente, outras soluc ¸˜ oes s˜ ao poss´ ıveis
 e um controlador SDN deveria oferecer acesso a elas. N˜ ao s´ o isso, mas uma soluc ¸˜ ao
 para Redes Definidas por Software deveria oferecer uma interface de encaminhamento
 pela malha da rede, independente da interface particular de cada elemento de rede. Dessa
 forma, aplicac ¸˜ oes poderiam se concentrar em suas caracter´ ısticas espec´ ıficas, fazendo uso
 de primitivas de encaminhamento fim-a-fim na malha.
 Umapossibilidade, considerada em diferentes cen´ arios, ´ e que uma funcionalidade
 de programac ¸˜ ao como OpenFlow esteja dispon´ ıvel apenas nas bordas da rede, enquanto a
 estrutura interna da mesma n˜ao seja diretamente vis´ ıvel para o desenvolvedor. Isso daria
 espac ¸o para os desenvolvedores de dispositivos de rede incluirem outras funcionalidades
 que n˜ ao se casem facilmente com o modelo OpenFlow. Um exemplo de funcionalidade
 desse tipo seriam soluc¸˜ oes para recuperac¸˜ ao r´ apida de falhas de roteamento, dif´ ıceis de
 serem implementadas de forma eficiente no contexto de SDN.
 Especificac ¸˜ ao de aplicac ¸˜ oes
 Controladores de rede como Frenetic e FML j´a demonstram que aplicac ¸˜ oes para Redes
 Definidas por Software n˜ ao necessariamente ser˜ao desenvolvidas utilizando-se lingua
gens imperativas. Sistemas como OMNI utilizam arcabouc¸os de sistemas multi-agentes
Minicursos Livro Texto
 205
 para organizar suas aplicac ¸˜ oes e expressar as regras de controle que devem ser implemen
tadas sobre a rede. Um dos desafios da ´ area ´ e certamente identificar quais paradigmas
 de programac¸˜ao e quais conjuntos de abstrac ¸˜ oes (“bibliotecas”) se prestam melhor aos
 objetivos de diferentes cen´arios.
 Aintegrac ¸˜ao de controladores SDN a outros ambientes, como sistemas orientados
 para problemas de inteligˆencia artificial ou minerac ¸˜ao de dados pode levar a novas for
mas de se descrever a interac ¸˜ao entre os componentes de rede. Nesse sentido, o tipo de
 aplicac ¸˜ao alvo e seu contexto de definic ¸˜ao podem guiar o desenvolvimento das abstrac ¸˜ oes
 de programac ¸˜ao da rede em direc ¸˜ oes at´e agora n˜ ao imaginadas.
 Depurac ¸˜ ao
 A inclus˜ao de diversos n´ ıveis de abstrac ¸˜ao entre a aplicac ¸˜ao de rede e a infra-estrutura
 f´ ısica cria a necessidade de regras de traduc ¸˜ao entre o que ´ e expressado na linguage/in
terface da aplicac¸˜ao e como os conceitos associados s˜ao colocados em pr´atica na na rede
 f´ ısica. Nesse processo, existe a possibilidade de que a configurac¸˜ao da rede f´ ısica n˜ao re
presente exatamente o que era desejado no n´ ıvel superior. Determinar quando isso acon
tece e, se poss´ ıvel, identificar as causas dessas inconsistˆencias exige que sejam definidas
 t´ecnicas de depurac ¸˜ ao (debugging) adequadas.
 Como no caso do item anterior, as abstrac ¸˜ oes adotadas pelo controlador SDN,
 pela linguagem de programac ¸˜ao associada determinar˜ ao o tipo de recursos de depurac ¸˜ao
 que podem ser oferecidos. Qualquer soluc ¸˜ ao adotada, entretanto, deve se pautar pelo
 acompanhamento das regras de transformac¸˜ao ao longo dos n´ ıveis de abstrac¸˜ ao, de forma
 a permitir que se estabelec¸am paralelos entre cada abstrac¸˜ ao de alto n´ ıvel e as regras de
 controle por ela geradas na rede f´ ısica. Por exemplo, Frenetic se vale de sua natureza
 funcional para facilitar a depurac ¸˜ ao das regras de controle [Reitblatt et al. 2011].
 Distribuic ¸˜ ao
 ´
 E sempre importante relembrar que a noc ¸˜ao da vis˜ ao global da rede como algo cen
tralizado em SDN ´e uma vis˜ ao l´ ogica. N˜ao h´a nenhuma exigˆencia no paradigma
 que determine que essa vis˜ao deve ser obrigatoriamente implementada de forma cen
tralizada. Requisitos de desempenho ou de tolerˆancia a falhas podem levar a uma
 decis˜ao de distribuic¸˜ao dessa vis˜ ao global. As decis˜ oes de projeto que levaram ao
 modelo do sistema Onix, por exemplo, mostram um caminho onde a distribuic ¸˜ao
 em algum n´ ıvel foi considerada essencial para a soluc ¸˜ao final. Outros sistemas,
 comoHyperflow[Tootoonchian and Ganjali 2010] apresentam outros caminhos para essa
 distribuic ¸˜ ao. Certamente, em func ¸˜ao das diferentes abstrac¸˜ oes de programac¸˜ao que podem
 vir a surgir em controladores SDN e das diferentes linguagens/interfaces de programac ¸˜ao
 poss´ ıveis, muitas linhas de ac ¸˜ao podem ser exploradas nesse contexto.
206
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 4.9. Considerac ¸˜ oes finais
 O potencial do paradigma de Redes Definidas por Software apenas comec ¸a a ser explo
rado, mas j´ a ´e grande o interesse pela ´area entre pesquisadores e empresas da ´area. O
 fato de j´a estarem no mercado os primeiros dispositivos comerciais baseados no padr˜ao
 OpenFlow confirmam o momento positivo dessa iniciativa. Al´em disso, ´e claro interesse
 de diversas grandes empresas da ´ area de dispositivos de rede e o surgimento de diversas
 novas empresas de tecnologia (start-ups) ao redor desses conceitos.
 Nesse cen´ ario, neste trabalho buscamos apresentar uma vis˜ao dos aspectos
 te´ oricos e pr´ aticos envolvidos no desenvolvimento de pesquisas em SDN. Em particu
lar, apresentamos os elementos que devem ser considerados ao se iniciar um trabalho na
 ´ area, com ˆ enfase no controlador de rede. Esse elemento tem papel essencial em qualquer
 iniciativa sobre SDN, uma vez que o software que define esses sistemas deve ser desen
volvido com base nos recursos de express˜ ao oferencidos pelo controlador. As diversas
 opc¸˜ oes de controladores dispon´ ıveis foram descritas e os aspectos pr´ aticos de desenvol
vimento de aplicac¸˜ oes SDN foram discutidos `a luz do controlador POX, recentemente
 lanc¸ado e especialmente desenvolvido para o ambiente de pesquisa e ensino.
 Considerando-se o sucesso do paradigma e os desafios identificados neste texto,
 consideramos que existe um campo amplo para o desenvolvimento de novos projetos de
 pesquisa enfocando Redes Definidas por Software, seja como ferramenta para o desenvol
vimento de novos servic ¸os e aplicac ¸˜ oes de redes, seja como alvo de estudos sobre novas
 abstrac ¸˜ oes e soluc ¸˜ oes de implementac¸˜ao. Certamente, os trabalhos mais interessantes na
 ´ area ainda est˜ ao por vir.
 Al´ em das referˆencias apresentadas a seguir, alguns s´ ıtios concentram
 grande parte das discuss˜ oes sobre os conceitos aqui apresentados.
 Os in
teressados na ´area devem acompanhar as atividades dos desenvolvedores em
 s´ ıtios como noxathome.org, noxrepo.org, openflow.org, openwrt.org,
 openvswitch.org, opennetworking.org, opennetsummit.org, entre ou
tros.
 Agradecimentos
 Este trabalho foi parcialmente financiado pelo Instituto Nacional de Ciˆencia e Tecnolo
gia para a Web (InWeb), pelo CNPq, FAPEMIG, HP Brasil, pelo programa UOL Bolsa
 Pesquisa (www.uol.com.br) e pelo Programa de Visitas Brasil-ICSI do Movimento Brasil
 Colaborativo/ABDI. Murphy McCauley ´e o desenvolvedor principal do POX e colaborou
 com diversas informac ¸˜ oes utilizadas aqui. Muitos dos elementos apresentados sobre de
safios de pesquisa na ´ area de controladores SDN foram derivados de discuss˜ oes com o
 Prof. Scott Shenker.
 Referˆ encias
 [bea 2012] (2012). Thebeaconcontroller. https://openflow.stanford.edu/display/Beacon/Home.
 [flo 2012] (2012). Floodlight. http://floodlight.openflowhub.org/.
 [nec 2012] (2012). Nec programmable flow. http://www.necam.com/pflow/.
Minicursos Livro Texto
 207
 [ope 2012] (2012). Openstack:open source software for building private and public
 clouds. http://openstack.org/.
 [sna 2012] (2012). Simple network access control. http://www.openflow.org/wp/snac/.
 [tre 2012] (2012).
 Trema: Full-stack openflow framework for ruby and c.
 http://trema.github.com/trema/.
 [Braga et al. 2010] Braga, R. B., Mota, E. M., and Passito, A. P. (2010). Lightweight
 ddos flooding attack detection using nox/openflow. In Proceedings of the Annual IEEE
 Conference on Local Computer Networks, pages 408–415, Los Alamitos, CA, USA.
 IEEE Computer Society.
 [Cai et al. 2010] Cai, Z., Cox, A. L., and Ng, T. S. E. (2010). Maestro: A system for
 scalable openflow control. Technical Report TR10-08, Rice University.
 [Calvert et al. 2011] Calvert, K. L., Edwards, W. K., Feamster, N., Grinter, R. E., Deng,
 Y., and Zhou, X. (2011). Instrumenting home networks. SIGCOMM Comput. Com
mun. Rev., 41(1):84–89.
 [Casado et al. 2010a] Casado, M., Erickson, D., Ganichev, I. A., Griffith, R., Heller, B.,
 Mckeown, N., Moon, D., Koponen, T., Shenker, S., and Zarifis, K. (2010a). Ripcord:
 A modular platform for data center networking. EECS Department Technical Report
 UCB/EECS-2010-93, University of California, Berkeley.
 [Casado et al. 2009] Casado, M., Freedman, M. J., Pettit, J., Luo, J., Gude, N., McKe
own, N., and Shenker, S. (2009). Rethinking enterprise network control. IEEE/ACM
 Transactions on Networking, 17(4):1270–1283.
 [Casado et al. 2010b] Casado, M., Koponen, T., Ramanathan, R., and Shenker, S.
 (2010b). Virtualizing the network forwarding plane. In Proceedings of the Workshop
 on Programmable Routers for Extensible Services of Tomorrow, PRESTO ’10, pages
 8:1–8:6, New York, NY.
 [Davie and Farrel 2008] Davie, B. S. and Farrel, A. (2008). MPLS: Next Steps: Next
 Steps. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
 [Dixon et al. 2010] Dixon, C., Mahajan, R., Agarwal, S., Brush, A. J., Lee, B., Saroiu,
 S., and Bahl, V. (2010). The home needs an operating system (and an app store).
 In Proceedings of the Ninth ACM SIGCOMM Workshop on Hot Topics in Networks,
 Hotnets ’10, pages 18:1–18:6, New York, NY, USA. ACM.
 [Elliott and Falk 2009] Elliott, C. and Falk, A. (2009). An update on the geni project.
 SIGCOMMComput. Commun. Rev., 39(3):28–34.
 [Farias et al. 2011] Farias, F. N. N., Salvatti, J. J., Dias, J. M., Toda, H. S., Cerqueira,
 E., and Abel´em, A. J. G. (2011). Implementac¸˜ao de um novo datapath openflow em
 ambientes de switches legados. In Anais do II Workshop de Pesquisa Experimental em
 Internet do Futuro, pages 15–18. SBC.
208
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 [Feamster 2010] Feamster, N. (2010). Outsourcing home network security. In Proce
edings of the 2010 ACM SIGCOMM workshop on Home networks, HomeNets ’10,
 pages 37–42, New York, NY, USA. ACM.
 [Foster et al. 2010] Foster, N., Freedman, M. J., Harrison, R., Rexford, J., Meola, M. L.,
 and Walker, D. (2010). Frenetic: a high-level language for openflow networks. In
 Proceedings of the Workshop on Programmable Routers for Extensible Services of
 Tomorrow, PRESTO ’10, pages 6:1–6:6, New York, NY.
 [Gude et al. 2008] Gude, N., Koponen, T., Pettit, J., Pfaff, B., Casado, M., McKeown, N.,
 and Shenker, S. (2008). Nox: towards an operating system for networks. SIGCOMM
 Comput. Commun. Rev., 38:105–110.
 [Heller et al. 2010a] Heller, B., Erickson, D., McKeown, N., Griffith, R., Ganichev, I.,
 Whyte, S., Zarifis, K., Moon, D., Shenker, S., and Stuart, S. (2010a). Ripcord: a
 modular platform for data center networking. SIGCOMM Comput. Commun. Rev.,
 40:457–458.
 [Heller et al. 2010b] Heller, B., Seetharaman, S., Mahadevan, P., Yiakoumis, Y., Sharma,
 P., Banerjee, S., and Mckeown, N. (2010b). Elastictree: Saving energy in data center
 networks. In Proceedings of the 7th Usenix Symposium on Networked Systems Design
 and Implementation (NSDI).
 [Hinrichs et al. 2009] Hinrichs, T. L., Gude, N. S., Casado, M., Mitchell, J. C., and Shen
ker, S. (2009). Practical declarative network management. In Proceedings of the 1st
 ACMworkshop on Research on enterprise networking, WREN ’09, pages 1–10, New
 York, NY.
 [Kempf et al. 2011] Kempf, J., Whyte, S., Ellithorpe, J., Kazemian, P., Haitjema, M.,
 Beheshti, N., Stuart, S., and Green, H. (2011). Openflow mpls and the open source
 label switched router. In Proceedings of the 23rd International Teletraffic Congress,
 ITC ’11, pages 8–14. ITCP.
 [Kohler et al. 2000] Kohler, E., Morris, R., Chen, B., Jannotti, J., and Kaashoek, M. F.
 (2000). The click modular router. ACM Trans. Comput. Syst., 18(3):263–297.
 [Koponen et al. 2010] Koponen, T., Casado, M., Gude, N., Stribling, J., Poutievski, L.,
 Zhu, M., Ramanathan, R., Iwata, Y., Inoue, H., Hama, T., and Shenker, S. (2010).
 Onix: a distributed control platform for large-scale production networks. In Procee
dings of the 9th USENIX conference on Operating systems design and implementation,
 OSDI’10, pages 1–6, Berkeley, CA. USENIX Association.
 [Lantz et al. 2010] Lantz, B., Heller, B., and McKeown, N. (2010). A network in a lap
top: rapid prototyping for software-defined networks. In Proceedings of the Ninth
 ACMSIGCOMMWorkshoponHotTopics in Networks, Hotnets ’10, pages 19:1–19:6,
 New York, NY, USA. ACM.
 [Mattos et al. 2011] Mattos, D. M. F., Fernandes, N. C., da Costa, V. T., Cardoso, L. P.,
 Campista, M. E. M., Costa, L. H. M. K., and Duarte, O. C. M. B. (2011). Omni:
Minicursos Livro Texto
 209
 Openflow management infrastructure. In Proceedings of the 2nd IFIP International
 Conference Network of the Future- NoF’2011, pages 1–5. IFIP.
 [McKeown et al. 2008] McKeown, N., Anderson, T., Balakrishnan, H., Parulkar, G., Pe
terson, L., Rexford, J., Shenker, S., and Turner, J. (2008). Openflow: enabling innova
tion in campus networks. SIGCOMM Comput. Commun. Rev., 38:69–74.
 [Mehdi et al. 2011] Mehdi, S. A., Khalid, J., and Khayam, S. A. (2011). Revisiting traffic
 anomaly detection using software defined networking. In Proceedings of the 14th
 International Symposium on Recent Advances in Intrusion Detection (RAID), pages
 161–180.
 [Mogul et al. 2010] Mogul, J. C., Tourrilhes, J., Yalagandula, P., Sharma, P., Curtis,
 A. R., and Banerjee, S. (2010). Devoflow: cost-effective flow management for high
 performance enterprise networks. In Proceedings of the Ninth ACM SIGCOMM
 Workshop on Hot Topics in Networks, Hotnets ’10, pages 1:1–1:6, New York, NY,
 USA. ACM.
 [Mundada et al. 2009] Mundada, Y., Sherwood, R., and Feamster, N. (2009). An open
f
 low switch element for click. In Proceedinds on the Symposium on Click Modular
 Router.
 [Nascimento et al. 2011] Nascimento, M. R., Rothenberg, C. E., Salvador, M. R., Corrˆ ea,
 C. N. A., De Lucena, S. C., and Magalh˜ aes, M. F. (2011). Virtual routers as a service:
 The routeflow approach leveraging software-defined networks. In Proceedings of the
 6th International Conference on Future Internet Technologies (CFI), pages 0–3.
 [Peterson and Roscoe 2006] Peterson, L. and Roscoe, T. (2006). The design principles
 of planetlab. SIGOPS Oper. Syst. Rev., 40(1):11–16.
 [Pettit et al. 2010] Pettit, J., Gross, J., Pfaff, B., Casado, M., and Crosby, S. (2010). Vir
tual switching in an era of advanced edges. In Proceedings of the 2nd Workshop on
 Data Center- Converged and Virtual Ethernet Switching (DC CAVES), DC CAVES,
 pages 1–7, Amsterdam, The Netherlands. ITC.
 [Pfaff et al. 2009] Pfaff, B., Pettit, J., Amidon, K., Casado, M., Koponen, T., and Shen
ker, S. (2009). Extending networking into the virtualization layer. In Proceedings of
 the Eighth ACM Workshop on Hot Topics in Networks (HotNets-VIII).
 [Ram et al. 2010] Ram, K. K., Mudigonda, J., Cox, A. L., Rixner, S., Ranganathan, P.,
 and Santos, J. R. (2010). snich: efficient last hop networking in the data center. In
 Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and
 Communications Systems, ANCS ’10, pages 26:1–26:12, New York, NY, USA. ACM.
 [Reitblatt et al. 2011] Reitblatt, M., Foster, N., Rexford, J., and Walker, D. (2011). Con
sistent updates for software-defined networks: Change you can believe in. In Pro
ceedings of ACM SIGCOMM Workshop on Hot Topics in Networks (HotNets), pages
 1–6.
210
 XXXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ ıdos- SBRC 2012
 [Rodrigues et al. 2011a] Rodrigues, H., Santos, J. R., Turner, Y., Soares, P., and Guedes,
 D. (2011a). Gatekeeper: Supporting bandwidth guarantees for multi-tenant datacenter
 networks. In Proceedings of the 3rd Usenix Workshop on I/O Virtualization (WIOV
 ’11), Portland, OR. Usenix.
 [Rodrigues et al. 2011b] Rodrigues, H., Soares, P. V., Santos, J. R., Turner, Y., and Gue
des, D. (2011b). Isolamento de tr´afego eficiente em ambientes virtualizados. In
 Anais do XXIXSimp´osio Brasileiro de Redes de Computadores e Sistemas Distribu´ıdos
 (SBRC), pages 1–14. SBC.
 [Sherwood et al. 2010] Sherwood, R. et al. (2010). Carving research slices out of your
 production networks with openflow. SIGCOMM Comput. Commun. Rev., 40:129–130.
 [Sherwood et al. 2009] Sherwood, R., Gibb, G., Yap, K.-K., Apenzeller, G., Casado, M.,
 McKeown, N., and Parulkar, G. (2009). Flowvisor: A network virtualization layer.
 Tech. Rep. OPENFLOWTR-2009-1, OpenFlowSwitch.org.
 [Silva et al. 2011] Silva, G., Arantes, A., Steding-Jessen, K., Hoepers, C., Chaves, M.,
 Jr., W. M., and Guedes, D. (2011). SpSb: um ambiente seguro para o estudo de spam
bots. In Anais do Simp´osio Brasileiro de Seguranc ¸a, pages 1–5, Bras´ ılia, DF. SBC.
 [Tennenhouse and Wetherall 2007] Tennenhouse, D. L. and Wetherall, D. J. (2007).
 Towards an active network architecture.
 SIGCOMM Comput. Commun. Rev.,
 37(5):81–94.
 [Tootoonchian and Ganjali 2010] Tootoonchian, A. and Ganjali, Y. (2010). Hyperflow:
 a distributed control plane for openflow. In Proceedings of the 2010 internet network
 management conference on Research on enterprise networking, INM/WREN’10, pa
ges 3–3, Berkeley, CA. USENIX Association.
 [Turner 2006] Turner, J. S. (2006). A proposed architecture for the geni backbone plat
form. In Proceedings of the 2006 ACM/IEEE symposium on Architecture for networ
king and communications systems, ANCS ’06, pages 1–10, New York, NY, USA.
 ACM.
 View publication stats