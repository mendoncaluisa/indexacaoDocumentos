ARTIGO
2965-6931 10.35699/2965-6931.2023.47996 CC BY 4.0
O impacto da intelig√™ncia artificial nas ci√™ncias
da vida atrav√©s da bioinform√°tica
Lucas Moraes dos Santos
Universidade Federal de Minas Gerais (UFMG)
https://orcid.org/0000-0003-4214-1576
moraes.lsantos@gmail.com
Diego Mariano
Universidade Federal de Minas Gerais (UFMG)
https://orcid.org/0000-0002-5899-2052
dcbmariano@gmail.com
Raquel Cardoso de Melo-Minardi
Universidade Federal de Minas Gerais (UFMG)
https://orcid.org/0000-0001-5190-100X
raquelcm@dcc.ufmg.br
RESUMO
Nos √∫ltimos anos, as ci√™ncias da vida testemunharam uma profunda
transforma√ß√£o, impulsionada pelos not√°veis avan√ßos na intelig√™ncia
artificial (IA). Esta transforma√ß√£o tornou-se poss√≠vel atrav√©s da
converg√™ncia de novos m√©todos e tecnologias que possibilitaram a
gera√ß√£o de dados biol√≥gicos em larga escala e de alta qualidade.
Al√©m disso, a bioinform√°tica tem desempenhado um papel
fundamental viabilizando a modelagem e resolu√ß√£o de problemas
biol√≥gicos complexos, criando assim um terreno f√©rtil √† aplica√ß√£o do
aprendizado de m√°quina e, consequentemente, catalisando insights e
perspectivas inovadoras na √°rea. Neste trabalho, discorremos sobre o
profundo impacto da IA nas ci√™ncias da vida, com particular √™nfase
naqueles mediados pela bioinform√°tica, na evolu√ß√£o cont√≠nua dos
algoritmos de IA e nas implica√ß√µes de longo alcance √† pesquisa nas
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
ci√™ncias da vida. Al√©m disso, procuramos elucidar aspectos
arquitet√¥nicos inerentes √†s redes convolucionais e aos modelos
generativos, demonstrando o motivo pelo qual cada t√©cnica √©
aplicada a diferentes problemas biol√≥gicos.
Palavras-chave: bioinform√°tica; intelig√™ncia artificial; aprendizagem
de m√°quina.
The impact of artificial intelligence in life sciences
through bioinformatics
ABSTRACT
En los √∫ltimos a√±os, las ciencias de la vida han sido testigos de una
profunda transformaci√≥n, impulsada por avances notables en la
inteligencia artificial (IA). Esta transformaci√≥n fue posible gracias a la
convergencia de nuevos m√©todos y tecnolog√≠as que permitieron la
generaci√≥n de datos biol√≥gicos a gran escala y de alta calidad.
Adem√°s, la bioinform√°tica ha jugado un papel fundamental al
permitir el modelado y la resoluci√≥n de problemas biol√≥gicos
complejos, creando as√≠ un terreno f√©rtil para la aplicaci√≥n del
aprendizaje autom√°tico y, en consecuencia, catalizando
conocimientos y perspectivas innovadoras en el √°rea. En este trabajo,
analizamos el profundo impacto de la IA en las ciencias de la vida,
con especial √©nfasis en aquellas mediadas por la bioinform√°tica, la
evoluci√≥n continua de los algoritmos de IA y las implicaciones de
gran alcance para la investigaci√≥n en ciencias de la vida. Adem√°s,
buscamos dilucidar aspectos arquitect√≥nicos inherentes a las redes
convolucionales y modelos generativos, demostrando por qu√© cada
t√©cnica se aplica a diferentes problemas biol√≥gicos.
Keywords: bioinform√°tica; inteligencia artificial; aprendizaje
autom√°tico.
Submiss√£o em: 06/09/2023 | Aprova√ß√£o em: 16/10/2023
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
1. INTRODU√á√ÉO
Nos √∫ltimos anos, novas tecnologias, como sequenciadores de pr√≥xima gera√ß√£o ou
equipamentos para realiza√ß√£o de crio-microscopia eletr√¥nica (Crio-ME), t√™m permitido a
produ√ß√£o de uma imensa quantidade de dados biol√≥gicos. Al√©m disso, diversas
evolu√ß√µes metodol√≥gicas e tecnol√≥gicas t√™m proporcionado um aumento expressivo do
volume e da qualidade de bases de dados relacionados √†s biomol√©culas. Nesse contexto,
surge a bioinform√°tica, uma √°rea de pesquisa que envolve o uso e desenvolvimento de
t√©cnicas computacionais para an√°lises de dados biol√≥gicos (Mariano, Ferreira, et al., 2020;
Mishra, Das, et al., 2023).
A priori, estudos em bioinform√°tica concentraram-se principalmente na an√°lise de
sequ√™ncias de DNA, RNA e prote√≠nas. No entanto, as pesquisas em bioinform√°tica n√£o se
limitam a isso. Por exemplo, o interesse no estudo de estruturas tridimensionais de
macromol√©culas fomentou o surgimento de uma sub√°rea conhecida como bioinform√°tica
estrutural. A bioinform√°tica estrutural se baseia no uso de metodologias da qu√≠mica
computacional em combina√ß√£o com t√©cnicas de modelagem molecular para lidar com
quest√µes biol√≥gicas de um ponto de vista tridimensional (Verli, 2014).
Recentemente, an√°lises de bioinform√°tica combinadas a algoritmos baseados em
intelig√™ncia artificial (IA) t√™m possibilitado a pesquisadores obter novas percep√ß√µes na
abordagem de problemas por anos sem solu√ß√£o. A t√≠tulo de exemplo, o problema do
enovelamento de prote√≠nas, um desafio que havia sido estudado por mais de 50 anos
(Dill e Maccallum, 2012), teve avan√ßos significativos nos √∫ltimos anos com novas
solu√ß√µes envolvendo IA. Em 2021, pesquisadores do Google DeepMind propuseram uma
nova arquitetura de redes neurais profundas denominada AlphaFold para predi√ß√£o de
estruturas de prote√≠nas a partir da estrutura prim√°ria de amino√°cidos. Um artigo recente
na revista Nature (Method of the Year 2021: Protein structure prediction, 2022) o indicou
como ‚Äúo m√©todo do ano de 2021‚Äù e previu ainda que seus resultados causariam um
impacto duradouro e de longo alcance.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
Figura 1 - Papel da bioinform√°tica e das t√©cnicas de intelig√™ncia artificial para obten√ß√£o de novas
descobertas a partir de dados biol√≥gicos.
Fonte: autoria pr√≥pria.
A Figura 1 apresenta um pipeline comum na pesquisa em bioinform√°tica baseada
em IA. Dado que a coleta de amostras de diversos organismos tem se tornado mais
acess√≠vel, avan√ßos recentes na tecnologia de sequenciamento de pr√≥xima gera√ß√£o
(Next-Generation Sequencing, NGS) e t√©cnicas para determina√ß√£o de estruturas
tridimensionais de prote√≠nas por Crio-ME, t√™m possibilitado a obten√ß√£o r√°pida e eficiente
de grandes volumes de informa√ß√µes biol√≥gicas (Gao, Mahajan, et al., 2020). Em paralelo,
o desenvolvimento da tecnologia da informa√ß√£o viabilizou uma capacidade ainda maior
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
de processamento das bases de dados biol√≥gicas em larga escala. Al√©m disso,
metodologias de modelagem computacional t√™m permitido a prepara√ß√£o e representa√ß√£o
dos dados (e.g., one-hot encoding, mapas de dist√¢ncias, grafos) para sua utiliza√ß√£o em
algoritmos de IA (Defresne, Barbe e Schiex, 2021). Assim, √© poss√≠vel aplicar t√©cnicas de
aprendizado de m√°quina, viabilizando a descoberta de conhecimento.
Nesse sentido, revis√µes acerca da aprendizagem profunda aplicada √†
bioinform√°tica t√™m abordado diferentes pipelines que possibilitam da predi√ß√£o de
estrutura at√© a gera√ß√£o de novo de sequ√™ncias de prote√≠nas. Em dos principais e
predecessores trabalhos na √°rea, Min et al. (2017) desenvolveram uma revis√£o
abrangente, na qual descrevem sobre aplica√ß√µes categorizadas por dom√≠nio na
bioinform√°tica (√¥micas e processamento de imagens ou sinais biom√©dicos) e arquitetura
de aprendizagem profunda (perceptron multicamadas, redes neurais convolucionais e
recorrentes). Contudo, com o desenvolvimento da IA generativa, modelos generativos
v√™m sobrepondo arquiteturas como as redes recorrentes, na predi√ß√£o e modelagem de
mol√©culas baseada em estrutura, sequ√™ncia ou propriedades f√≠sico-qu√≠micas, aparecendo
majoritariamente em revis√µes recentes (Huang, Boyken e Baker, 2016; Gao, Mahajan, et
al., 2020; Torrisi, Pollastri e Le, 2020; Bai, Liu, et al., 2021; Defresne, Barbe e Schiex, 2021;
Abbasi,, Santos, et al., 2022).
Neste trabalho, ser√£o discutidos os impactos da IA na bioinform√°tica e nas
ci√™ncias da vida. Nas se√ß√µes seguintes, ser√£o apresentadas t√©cnicas de aprendizagem
profunda tradicionais como as redes neurais convolucionais, autoencoders variacionais,
redes advers√°rias generativas e as redes neurais recorrentes, al√©m de arquiteturas
recentes como os modelos largos de linguagem (tamb√©m conhecidos como modelos de
linguagem baseados em transformer) e os modelos de difus√£o, dentre outros t√≥picos que
ser√£o descritos a partir de aplica√ß√µes na bioinform√°tica e ci√™ncias da vida.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
2. APRENDIZAGEM PROFUNDA
Nos √∫ltimos anos, o principal desafio √† intelig√™ncia artificial envolveu a resolu√ß√£o
de problemas que s√£o inerentemente simples para humanos resolverem intuitivamente,
mas que se tornam complexos quando √© necess√°ria uma descri√ß√£o formal. Isso foi
poss√≠vel por meio de uma abordagem conhecida como hierarquia de conceitos que permite
ao computador compreender conceitos complexos, construindo-os a partir de
componentes mais elementares. Nesse sentido, ao relacionarmos esses conceitos atrav√©s
de um grafo, este ser√° profundo (ou seja, composto por muitas camadas). Por esse
motivo essa abordagem √© conhecida como aprendizagem profunda em IA (Goodfellow,
Bengio e Courville, 2016).
Em outras palavras, a solu√ß√£o dos problemas se d√° pela extra√ß√£o de conhecimento
(ou padr√µes n√£o triviais) de bancos de dados atrav√©s de algoritmos de aprendizado de
m√°quina. No campo da Bioinform√°tica, a IA tem sido empregada h√° mais de uma d√©cada
impulsionada pelo crescente volume de dados biol√≥gicos advindos das √¥micas
(gen√¥mica, transcript√¥mica, prote√¥mica, entre outras) ou ainda, de imagens e outros
tipos de sinais biom√©dicos (Min, Lee e Yoon, 2017).
Contudo, o desempenho desses m√©todos ainda √© dependente da representa√ß√£o
dos dados (Goodfellow, Bengio e Courville, 2016). Para contornar esse desafio, tem sido
utilizada uma abordagem alternativa ‚Äì utilizar o aprendizado de m√°quina na descoberta
de representa√ß√µes que podem ser expressas a partir de componentes mais simples (Duda,
Hart e Stork, 2001). A necessidade de interven√ß√£o humana no processo de prepara√ß√£o
dos dados pode ser significativamente diminu√≠da com essa abordagem que √© conhecida
como aprendizado de representa√ß√£o (Bengio, Courville e Vincent, 2013). Dentre as diversas
metodologias para aprender representa√ß√µes tem-se destacado a aprendizagem profunda
(deep learning, DL), ou seja, um tipo especializado de aprendizado de m√°quina que
alcan√ßa grande poder e flexibilidade aprendendo a representar o mundo a partir de uma
hierarquia aninhada de conceitos (Goodfellow, Bengio e Courville, 2016).
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
Uma caracter√≠stica particular das arquiteturas baseadas em aprendizagem
profunda √© o uso de m√∫ltiplas camadas transforma√ß√µes n√£o lineares, representadas por
redes neurais, nas quais a sa√≠da de um n√≥ √© conectada a entrada de cada n√≥ da camada
seguinte (Bai, Liu et al., 2021). Esse arranjo das unidades neuronais forma camadas
ocultas e densas, constituindo uma rede totalmente conectada (Gonzalez e Woods, 2008,
p. 945). Consequentemente, os neur√¥nios ocultos possibilitam √† rede extrair
progressivamente as caracter√≠sticas mais significativas dos padr√µes de entrada, devido √†
profundidade das camadas (Haykin, 1999). Por esse motivo, essas redes neurais tamb√©m
s√£o denominadas redes neurais profundas (deep neural networks, DNN).
Dessa forma, atrav√©s de grandes volumes de dados sobre biomol√©culas (DNA,
RNA, prote√≠nas, metab√≥litos, etc) e das redes neurais profundas, capazes de abstrair
conceitos complexos compreendidos nos dados, muitos problemas t√™m sido resolvidos
com maior precis√£o que se comparado a abordagens baseadas no desenvolvimento de
programas cl√°ssicos, como fazia a bioinform√°tica tradicionalmente.
Contudo, ainda que realizem predi√ß√µes com precis√£o igual ou superior ao
desempenho humano, a maioria dos modelos baseados em aprendizagem profunda s√£o
incapazes de fornecer resultados interpret√°veis, frequentemente sendo comparados a
uma ‚Äúcaixa preta‚Äù (Bai, Liu , et al., 2021). Isso ocorre porque as redes neurais profundas
s√£o capazes de mapear a entrada para representa√ß√µes internas de alta dimensionalidade,
cujos padr√µes aprendidos encontram-se distribu√≠dos nas camadas ocultas (Goodfellow,
Bengio e Courville, 2016). Assim, torna-se dif√≠cil compreender diretamente algumas
decis√µes espec√≠ficas tomadas pela rede, limitando sua aplica√ß√£o em sistemas
biomoleculares (Li, Liu, et al., 2022). Visando contornar esse problema, um novo campo
denominado aprendizado de m√°quina interpret√°vel (interpretable machine learning, IML)
tem alcan√ßado interesse e popularidade. A partir do uso de t√©cnicas como visualiza√ß√£o
de recursos, maximiza√ß√£o de ativa√ß√£o e mecanismos de aten√ß√£o, tornou-se poss√≠vel obter
insights sobre o que o modelo aprendeu (Molnar, 2022).
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
Vamos introduzir a seguir alguns dos principais tipos de redes neurais profundas
que t√™m sido amplamente empregadas em bioinform√°tica com significativa relev√¢ncia.
2.1 REDES CONVOLUCIONAIS
As redes neurais convolucionais (convolutional neural networks, CNN) s√£o uma
classe de rede neural profunda (LECUN, BOSER, et al., 1989), especializada no
processamento de dados que possuem uma topologia em grade/matriz (Goodfellow,
Bengio e Courville, 2016, p. 330). Essas arquiteturas s√£o inspiradas na hierarquia do
c√≥rtex visual humano, na qual os neur√¥nios iniciais respondem a padr√µes elementares
em sub-regi√µes espec√≠ficas de est√≠mulos visuais, enquanto neur√¥nios de n√≠vel superior
sintetizam as informa√ß√µes dessas c√©lulas mais simples, identificando padr√µes mais
complexos (Min, Lee e Yoon, 2017).
Em alus√£o ao seu nome, a CNN realiza uma opera√ß√£o linear denominada
convolu√ß√£o que pode ser assimilada a um produto escalar de duas matrizes. Uma matriz
contendo o conjunto de par√¢metros aprendidos, conhecida como filtro, desliza pela
imagem, convolvendo uma outra matriz que representa uma regi√£o local da entrada
(Goodfellow, Bengio e Courville, 2016). Nesse caso, as camadas convolucionais n√£o
aprendem a entrada globalmente de uma √∫nica vez, mas concentram-se no padr√£o local
do campo receptivo (Bian e Xie, 2021). Essa caracter√≠stica possibilita as CNNs
aprenderem de padr√µes elementares (e.g., bordas, texturas) a caracter√≠sticas e conceitos
abstratos (e.g., faces, objetos). Isso se destaca como um exemplo de como princ√≠pios
neurocient√≠ficos influenciam a aprendizagem profunda (Molnar, 2022).
No contexto da bioinform√°tica estrutural, em que se estuda a estrutura 3D de
prote√≠nas e sua intera√ß√£o com outras biomol√©culas, as CNNs t√™m sido amplamente
utilizadas na predi√ß√£o de estrutura ou fun√ß√£o de prote√≠nas (Gao, Mahajan, et al., 2020;
Torrisi, Pollastri e Le, 2020). Isto tem sido poss√≠vel pois as CNNs se beneficiam das
simetrias das representa√ß√µes estruturais em duas dimens√µes, como por exemplo dos
mapas de dist√¢ncias que s√£o representa√ß√µes em imagens das dist√¢ncias entre todos os
pares de √°tomos de uma prote√≠na (Defresne, Barbe e Schiex, 2021).
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
O exemplo mais not√≥rio √© a primeira vers√£o do AlphaFold1
(Alquraishi, 2019;
Senior, Evans, et al., 2020), cujo componente central √© uma rede residual convolucional
treinada com estruturas do PDB para prever distogramas2 de prote√≠nas, com base em
sequ√™ncias de amino√°cidos. Al√©m disso, as CNNs demonstraram ser relevantes na
identifica√ß√£o dos estados funcionais de prote√≠nas e pept√≠deos est√°ticos (Santos e
Melo-Minardi, 2022; Santos et al., 2023), bem como daqueles simulados atrav√©s da
din√¢mica molecular (Han, Lee, et al., 2022), usando uma representa√ß√£o por mapas de
dist√¢ncias (Figura 2), ou pixels (Plante, Shore, et al., 2019; Li, Liu, et al., 2022), e na
modelagem ab initio de prote√≠nas (Anishchenko, Pellock, et al., 2021).
Figura 2 ‚Äì Mapas de dist√¢ncias. A) Estrutura tridimensional de uma mioglobina (PDB ID: 1TES). B)
Mapa de dist√¢ncias correspondente a mioglobina. C) Estrutura tridimensional de uma tripsina (PDB ID:
1SGT). D) Mapa de dist√¢ncias correspondente a tripsina.
Fonte: autoria pr√≥pria.
2 Representa√ß√£o 2D na qual cada pixel corresponde distribui√ß√£o de probabilidade do qu√£o pr√≥ximo encontram-se os
pares de res√≠duos no mapa de dist√¢ncias (SENIOR, EVANS, et al., 2020).
1
 AlphaFold. Dispon√≠vel em: https://alphafold.ebi.ac.uk/.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
3. INTELIG√äNCIA ARTIFICIAL GENERATIVA
Os modelos baseados em IA generativa, tamb√©m conhecidos como modelos
generativos, t√™m o objetivo de modelar uma distribui√ß√£o a partir dos dados de
treinamento e, posteriormente, produzir resultados semelhantes (Sanchez-Lengeling e
Aspuru-Guzik, 2018; Zeng, Wang, et al., 2022). Um exemplo bastante simples √© treinar a
rede com fotos de faces de seres humanos e depois utilizar o modelo generativo para
produzir faces nunca vistas. Essa abordagem tem se mostrado promissora ao desenho de
novas mol√©culas (inclusive prote√≠nas), atrav√©s da explora√ß√£o n√£o apenas do espa√ßo de
sequ√™ncia, mas tamb√©m de propriedades estruturais e funcionais (Huang, Boyken e
Baker, 2016; Tong, Liu, et al., 2021). Isso se deve ao fato de que cada mol√©cula possui uma
representa√ß√£o √∫nica em um espa√ßo latente multidimensional, que codifica suas
caracter√≠sticas. Por exemplo, considere uma mol√©cula composta por tr√™s √°tomos A, B e C.
Nesse caso, cada √°tomo poderia ser descrito por caracter√≠sticas, como seu elemento
qu√≠mico (e.g., carbono, hidrog√™nio, oxig√™nio), carga (positiva, neutra e negativa),
polaridade (apolar e polar) e suas coordenadas espaciais (x, y, z), por exemplo. Assim, a
combina√ß√£o dessas caracter√≠sticas resulta em potenciais mol√©culas em um espa√ßo de
possibilidades ‚Äí referido como espa√ßo latente ‚Äí nesse caso 4D (elemento, carga, polaridade,
posi√ß√£o).
Os modelos generativos exploram esse espa√ßo vari√°vel, gerando vetores de
caracter√≠sticas (ou latentes) a partir de uma distribui√ß√£o de probabilidade
(Sanchez-Lengeling e Aspuru-Guzik, 2018). Pesquisadores t√™m constatado que esses
modelos treinados com sequ√™ncias e estruturas de prote√≠nas nativas, t√™m grande
potencial na gera√ß√£o de mol√©culas de novo (do zero) (Callaway, 2023). Essas redes neurais
t√™m transformado o desenho e a otimiza√ß√£o de pequenas mol√©culas e macromol√©culas,
apresentando novos candidatos parcialmente otimizados, em alguns casos em um tempo
inferior ao normalmente executado por abordagens convencionais (Zeng, Wang, et al.,
2022; Thomas, Bender e Graaf, 2023). O desempenho desses modelos na qu√≠mica
generativa se deve ao grande volume de dados dispon√≠veis em bases de dados (Min, Lee
e Yoon, 2017, Bian e Xie, 2021).
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
3.1 AUTOENCODERS VARIACIONAIS
Um autoencoder √© uma rede neural treinada para tentar reconstruir a entrada em
sua sa√≠da, com a maior precis√£o poss√≠vel (Goodfellow, Bengio e Courville, 2016, p. 499).
O aprendizado nessa arquitetura baseia-se em uma fun√ß√£o, denominada codificadora,
que transforma os dados em alta dimensionalidade (entrada) para uma representa√ß√£o de
baixa dimensionalidade em um espa√ßo latente, e um decodificador que reconstr√≥i a
entrada original a partir dessa representa√ß√£o ((Goodfellow, Bengio e Courville, 2016;
Tong, Liu, et al., 2021). No entanto, no contexto de aplica√ß√µes generativas, √© mais
frequente encontrar uma variante desse modelo conhecida como autoencoder variacional
(variational autoencoder, Vae), sendo a entrada representada como uma distribui√ß√£o de
probabilidade no espa√ßo latente (Kingma e Welling, 2013; Sousa, Correia, et al., 2021).
Essas arquiteturas t√™m sido amplamente empregadas no desenho de novas
mol√©culas (Chenthamarakshan, Hoffman, et al., 2023), uma vez que possibilitam a
explora√ß√£o de regi√µes desconhecidas do espa√ßo de design qu√≠mico a partir de
representa√ß√µes latentes de baixa dimensionalidade (Anstine e Isayev, 2023). Nesse caso, o
codificador mapeia a mol√©cula em um embedding cont√≠nuo, ou seja, um vetor latente com
dimensionalidade inferior √† representa√ß√£o da entrada (Bian e Xie, 2021), enquanto o
decodificador tenta recuperar a mol√©cula a partir do embedding aprendido. Assim, o
objetivo no treinamento de VAEs √© minimizar o erro de reconstru√ß√£o, ou seja, a diferen√ßa
entre a representa√ß√£o de entrada fornecida ao codificador e a sa√≠da do decodificador
(Anstine e Isayev, 2023).
3.2 REDES ADVERS√ÅRIAS GENERATIVAS
As redes advers√°rias generativas (generative adversarial networks, GAN) s√£o
arquiteturas de redes neurais profundas compostas por dois m√≥dulos concorrentes:
gerador e discriminador (Goodfellow, Pouget-Abadie, et al., 2014). O aprendizado em
GANs pode ser compreendido como um jogo de soma zero, onde o gerador aprende a
distribui√ß√£o dos dados de treinamento criando inst√¢ncias sint√©ticas para classifica√ß√£o
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
pelo discriminador. Conforme o treinamento avan√ßa, o gerador melhora, produzindo
resultados cada vez mais realistas para enganar o discriminador e classific√°-los como
amostras aut√™nticas. Simultaneamente, o discriminador se torna mais eficiente em
distinguir inst√¢ncias reais das falsas. Eventualmente, as amostras do gerador tornam-se
indistingu√≠veis dos dados reais, tornando o discriminador desnecess√°rio √† medida que o
treinamento converge (Goodfellow, Bengio e Courville, 2016, p. 702), condi√ß√£o conhecida
como Equil√≠brio de Nash (Nash, 1950).
Esses modelos podem ser conceitualmente simples de compreender a partir de um
exemplo de gera√ß√£o de mol√©culas. O discriminador visa maximizar a taxa de erro das
mol√©culas sint√©ticas do gerador, enquanto este, por sua vez, tenta minimizar o erro a
partir da cria√ß√£o de mol√©culas suficientemente realistas, capazes de enganar o
discriminador (Bilodeau, Jin, et al., 2022; Zeng, Wang, et al., 2022). Ou seja, mesmo um
discriminador bem treinado pode classificar inst√¢ncias geradas como reais, mostrando a
capacidade do gerador em criar compostos promissores a partir de uma entrada aleat√≥ria
latente (Bian e XIE, 2021). Assim, esses modelos t√™m sido adaptados para lidar com
diversos desafios na qu√≠mica generativa, abrangendo a cria√ß√£o de mol√©culas de novo
(Anand e Huang, 2018; Surana, Arora, et al., 2023; Xie, Valiente e Kim, 2023), predi√ß√£o da
estrutura de prote√≠nas (Ding e Gong, 2020) e modelagem de loop (Li, Nguyen, et al., 2017).
3.3 REDES NEURAIS RECORRENTES
As redes recorrentes (recurrent neural networks, RNN) s√£o uma fam√≠lia de redes
neurais para processamento de dados sequenciais (Rumelhart, Hinton e Williams, 1986;
Goodfellow, Bengio e Courville, 2016). Essas arquiteturas apresentam loops internos, nos
quais as sa√≠das das camadas no estado anterior s√£o transferidas para o estado atual
(Mitchell, 1997). Dessa forma, elas conseguem processar a entrada consecutivamente, ao
inv√©s de uma √∫nica etapa (Bian e Xie, 2021). Contudo, o aumento das etapas na RNN
pode ocasionar o desaparecimento de gradientes na retropropaga√ß√£o, dificultando o
aprendizado de depend√™ncia a longo prazo. A inclus√£o de unidades LSTM (Long
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
Short-Term Memory) contorna esse problema, introduzindo par√¢metros aprend√≠veis para
controlar o fluxo de informa√ß√µes (Sousa, Correia, et al., 2021).
Essas arquiteturas t√™m sido empregadas em tarefas de modelagem de sistemas
que possuem um componente sequencial, como a gera√ß√£o de mol√©culas a partir da
sequ√™ncia prim√°ria (Min, Lee e Yoon, 2017; Zeng, Wang, et al., 2022). Neste contexto, √©
comum ser utilizada uma nota√ß√£o conhecida como Smiles (Simplified Molecular Input Line
Entry System), ou seja, codifica√ß√µes textuais simplificadas, como tokens, para descrever
estruturas moleculares, tornando-o uma escolha predominante para representar
pequenas mol√©culas (Sousa, Correia, et al., 2021). Ap√≥s treinar a RNN com muitas strings
Smiles, seria poss√≠vel prever novas sequ√™ncias v√°lidas n√£o presentes no conjunto de
dados inicial (Tong, Liu, et al., 2021). Por exemplo, a partir de uma sequ√™ncia inicial (e.g.,
‚ÄúCC‚Äù), a RNN atribui probabilidades a caracteres subsequentes. Neste caso, ‚Äú1‚Äù (um)
corresponderia a alta probabilidade, podendo ser escolhido como o pr√≥ximo caractere.
‚Äú1‚Äù seria a entrada de feedback √† RNN. Este ciclo continua at√© o token final, ‚Äú\n‚Äù,
denotando o fim da sequ√™ncia (Zeng, Wang, et al., 2022).
3.4 MODELOS LARGOS DE LINGUAGEM
Modelos largos de linguagem (large language models, LLM) s√£o uma categoria
especializada de modelo de linguagem caracterizada por uma rede neural profunda
contendo um extenso n√∫mero de par√¢metros, comumente na ordem de 109
.
Recentemente, eles tornaram-se o estado da arte no processamento de linguagem natural
(Sousa, Correia, et al., 2021) uma vez que utilizam uma arquitetura denominada
transformer (Vaswani, Shazeer, et al., 2017). Esse modelo consiste em uma estrutura
codificador-decodificador, na qual um componente crucial, conhecido como mecanismo de
aten√ß√£o, permite a ele focar em partes relevantes da senten√ßa. Al√©m disso, devido ao
paralelismo do transformer, as senten√ßas s√£o processadas como um todo, prevenindo o
desaparecimento do gradiente durante o treinamento (Zhang, Fan, et al., 2023).
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
As similaridades intr√≠nsecas √†s linguagens naturais e sequ√™ncias biol√≥gicas t√™m
impulsionado a aplica√ß√£o de LLMs (e.g., Bert, GPT-3) na pesquisa em quimio e
bioinform√°tica, abrangendo da an√°lise de sequ√™ncia a modelagem de novo (Vert, 2023;
Zhang, FAN, et al., 2023). Isso, pois, dados biol√≥gicos heterog√™neos e de alta
dimensionalidade (e.g., descritores moleculares, estruturas de prote√≠nas etc.) podem ser
representados de maneira uniforme, atrav√©s de embeddings (Tong, Liu, et al., 2021; Vert,
2023). Um embedding √© um vetor cont√≠nuo no espa√ßo ùëõ-dimensional usado para codificar
padr√µes complexos a partir dos dados de entrada (e.g., texto ou imagens). Eles s√£o
estruturados de forma a posicionar conceitos semelhantes pr√≥ximos uns dos outros no
espa√ßo de embeddings, capturando rela√ß√µes sem√¢nticas. Esses vetores podem ser
alimentados diretamente nos LLMs, que extraem informa√ß√µes dependentes do contexto
biol√≥gico da correla√ß√£o de segmentos de embeddings (Zhang, Fan, et al., 2023).
Nesse sentido, tanto os transformers como os LLMs, t√™m sido o n√∫cleo de m√©todos
computacionais para predi√ß√£o de estruturas tridimensionais de prote√≠nas com alta
precis√£o, representando o estado da arte nesse campo. A partir da utiliza√ß√£o de
embeddings derivados de alinhamentos m√∫ltiplos de sequ√™ncia e um modelo baseado em
transformer, o AlphaFold 2 (Jumper, Evans, et al., 2021) obteve previs√µes de estruturas de
prote√≠nas em paridade com m√©todos experimentais, alcan√ßando uma pontua√ß√£o GDT de
92,4 no CASP143
. Outro exemplo √© o ESM-24
(Lin, Akin, et al., 2023), uma nova fam√≠lia de
modelos de linguagem de prote√≠nas baseados em transformers pr√©-treinados generativos
(generative pre-trained transformer, GPT) para inferir uma estrutura diretamente da
sequ√™ncia prim√°ria. Nesse caso, o ESM-2 aproveita informa√ß√µes de coevolu√ß√£o de
res√≠duos em sequ√™ncias para produzir previs√µes de n√≠vel at√¥mico (Lin, Akin, et al., 2023;
Zhang, Fan, et al., 2023).
4 ESM-2. Dispon√≠vel em: https://esmatlas.com/.
3 Em 2020, o AlphaFold 2 (SENIOR, EVANS, et al., 2020) alcan√ßou uma precis√£o de 92,4 (numa escala de 0 a 100) no
Teste de Dist√¢ncia Global (Global Distance Test, GDT), uma m√©trica utilizada pela Avalia√ß√£o Cr√≠tica de T√©cnicas para
Predi√ß√£o de Estrutura de Prote√≠nas (Critical Assessment of protein Structure Prediction, CASP). O resultado significa que,
em mais da metade das predi√ß√µes realizadas pelo programa, a corretude dos √°tomos na estrutura prevista encontra-se
acima de 92,4%. Esse n√≠vel de precis√£o √© compar√°vel a t√©cnicas experimentais, como a cristalografia de raios-X.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
3.5 MODELOS DE DIFUS√ÉO
Os modelos de difus√£o (diffusion models, Diff) (Sohl-Dickstein, Weiss, et al., 2015)
t√™m sido bem-sucedidos na realiza√ß√£o de tarefas como gera√ß√£o de imagens a partir de
texto, produzindo amostras de alta qualidade (Anstine e Isayev, 2023). Essas redes t√™m
como objetivo modelar uma distribui√ß√£o de probabilidade condicional dos dados, a
partir de etapas em sequ√™ncia. Nesse caso, a estrutura de entrada (e.g., imagem) √©
transformada gradualmente atrav√©s de um procedimento iterativo conhecido como
difus√£o. Esse processo envolve a introdu√ß√£o de um ru√≠do gaussiano, que desloca os dados
em dire√ß√£o a uma distribui√ß√£o alvo, onde a estrutura resultante n√£o possui qualquer
semelhan√ßa com a estrutura inicial. Durante o treinamento, a rede aprende a remover o
ru√≠do a partir de uma estimativa da m√°xima verossimilhan√ßa, na qual o modelo visa
maximizar a probabilidade de gera√ß√£o da entrada a partir dos dados ruidosos
(Sohl-Dickstein, Weiss, et al., 2015).
Recentemente, uma equipe de pesquisadores desenvolveu um programa de IA
denominado RoseTTAFold diffusion5
(RFdiffusion) (Watson, Juergens, et al., 2023), que
utiliza difus√£o guiada na cria√ß√£o de prote√≠nas personalizadas (Callaway, 2023). Nesse
caso, os autores ajustam a rede de predi√ß√£o de estrutura RoseTTAFold para o design de
prote√≠nas de acordo com restri√ß√µes espec√≠ficas de projeto durante a remo√ß√£o de ru√≠do ‚àí
processo conhecido como condicionamento (Callaway, 2023; Watson, Juergens, et al.,
2023) ‚àí alcan√ßando excelente desempenho no design de backbones de prote√≠nas. Al√©m
disso, modelos baseados em difus√£o t√™m sido aplicados na gera√ß√£o de conforma√ß√£o
molecular, onde o modelo aprende a modificar iterativamente os pares de dist√¢ncias
at√¥micas para gerar conforma√ß√µes est√°veis (Bilodeau, Jin, et al., 2022). Contudo, ainda
que representem uma abordagem promissora, os modelos de difus√£o ainda s√£o pouco
explorados (Anstine e Isayev, 2023).
5 RFdiffusion. Dispon√≠vel em: https://github.com/RosettaCommons/RFdiffusion.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
4. APRENDIZAGEM PROFUNDA APLICADA A PESQUISA EM
BIOINFORM√ÅTICA
A diversidade de arquiteturas de aprendizagem profunda tem oferecido uma
gama de alternativas √† representa√ß√£o de dados biol√≥gicos, o que tem impulsionado o
crescente e extenso volume de trabalhos em diferentes campos da bioinform√°tica (Min
Lee e Yoon, 2017). Al√©m disso, programas de IA como o trRosetta6
(Du et al., 2021) e, mais
recentemente, o AlphaFold2 (Jumper, Evans, et al., 2021) t√™m avan√ßado para al√©m da
modelagem por homologia, sendo utilizados no design de novo de mol√©culas, e
pavimentado o caminho para novas aplica√ß√µes. Um exemplo √© o AlphaFold Multimer,
uma extens√£o do AlphaFold2 que foi desenvolvida especificamente para prever
complexos prote√≠na-prote√≠na. Nesse sentido, a aprendizagem profunda e a IA generativa
t√™m auxiliado no desenvolvimento √°gil de mol√©culas personalizadas, explorando um
espa√ßo desconhecido de candidatos terap√™uticos (Callaway, 2023). Com isso, torna-se
poss√≠vel a descoberta, ou otimiza√ß√£o, de mol√©culas in silico para um determinado alvo,
ou fun√ß√£o, servindo de base para a descoberta de medicamentos e desenvolvimento de
vacinas (Vert, 2023). O apoio computacional por meio da IA torna os processos de
desenvolvimento de mol√©culas, tanto com fins biotecnol√≥gicos quanto farmacol√≥gicos,
mais √°gil, barato e promissor.
O Quadro 1 apresenta uma s√≠ntese de trabalhos recentes em diferentes campos da
bioinform√°tica, onde as t√©cnicas de aprendizagem profunda discutidas anteriormente,
foram aplicadas em objetivos espec√≠ficos com sucesso.
6
trRosetta. Dispon√≠vel em: https://yanglab.nankai.edu.cn/trRosetta/.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
Quadro 1 ‚Äì S√≠ntese de aplica√ß√µes representativas baseadas em aprendizagem profunda e IA generativa nos
diferentes campos da pesquisa em bioinform√°tica
Modelagem de prote√≠nas de novo
Arquitetura Objetivo Fonte Reposit√≥rio
CNN
Modelagem de novo de prote√≠nas
baseada em uma combina√ß√£o de
DNNs e simula√ß√µes de refinamento
estrutural, para gerar sequ√™ncias
alucinadas similares a sequ√™ncias de
prote√≠nas nativas
ANISHCHENKO
, PELLOCK, et al.,
2021
https://github.c
om/gjoni/trDesi
gn
GAN
Modelagem generativa de estruturas
de prote√≠nas, codificadas como
dist√¢ncias pareadas entre os carbonosŒ± no backbone da prote√≠na
ANAND e
HUANG, 2018
https://github.c
om/collinarnett/
protein_gan
GAN
Gera√ß√£o e otimiza√ß√£o de mol√©culas,
usando uma representa√ß√£o de SMILES
ABBASI,
SANTOS, et al.,
2022
https://github.c
om/larngroup/
GAN-Drug-Gene
rator
GAN
Gera√ß√£o de sequ√™ncias para novos
pept√≠deos antivirais
SURANA,
ARORA, et al.,
2023
https://github.c
om/thoughtwor
ks/antiviral-pept
ide-predictions-u
sing-gan/
GAN
Design de novo de Œ±-h√©lices
representadas como vetores de
sequ√™ncia e features estruturais
XIE, VALIENTE e
KIM, 2023
https://github.c
om/xxiexuezhi/
helix_gan
Modelos de
difus√£o
Gera√ß√£o de estruturas moleculares 3D
condicionadas √† forma de uma
determinada mol√©cula
CHEN, PENG, et
al., 2023
https://github.c
om/ehoogeboo
m/e3_diffusion_
for_molecules
Modelos de
linguagem
baseados em
transformer
Um modelo baseado em GPT
pr√©-treinado para gera√ß√£o de
sequ√™ncias semelhantes a prote√≠nas
naturais a partir ‚Äúdo zero‚Äù
FERRUZ,
SCHMIDT e
H√ñCKER, 2022
https://hugging
face.co/nferruz/
ProtGPT2
RNN
Descoberta de potenciais inibidores de
quinase. As mol√©culas foram
representadas por SMILES
LI, XU, et al., 2020
https://github.c
om/Xyqii/RNN
_generator
Transformer
Design racional de pept√≠deos
antimicrobiais
MAO, GUAN, et
al., 2023
https://github.c
om/AspirinCod
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
e/AMPTrans-lst
m
VAE
Design de inibidores para o dom√≠nio
ligante ao receptor (RBD
7
) da prote√≠na
spike e a principal protease do
SARS-CoV-2 (Mpro
)
CHENTHAMAR
AKSHAN,
HOFFMAN, et al.,
2023
https://zenodo.
org/records/786
3805
Previs√£o de estrutura e fun√ß√£o
Arquitetura Objetivo Fonte Reposit√≥rio
CNN
Classifica√ß√£o de estados funcionais
espec√≠ficos a ligantes de GPCRs,
usando conforma√ß√µes moleculares
codificadas em trajet√≥rias de DM
transformadas em representa√ß√µes de
pixel
PLANTE,
SHORE, et al.,
2019
-
CNN AlphaFold 1
ALQURAISHI,
2019; SENIOR,
EVANS, et al.,
2020
https://github.c
om/google-deep
mind/alphafold
CNN
Modelo DL interpret√°vel baseado em
representa√ß√£o por pixels para
identifica√ß√£o de estados funcionais em
trajet√≥rias de DM de GPCRs,
revelando res√≠duos-chave para
compreens√£o do mecanismo funcional
LI, LIU, et al.,
2022
https://github.c
om/Jane-Liu97/I
CNNMD
CNN
Reconhecimento de mudan√ßas
conformacionais relacionadas a
padr√µes espa√ßo-temporais induzidos
por ligantes de receptores Œ≤2-AR
usando mapas de dist√¢ncias
HAN, LEE, et al.,
2022
https://github.c
om/MinwooHan
84/beta2AR
GAN
Modelagem de loop
8 usando uma
representa√ß√£o de mapas de dist√¢ncias
dos carbonos-Œ± da prote√≠na
LI, NGUYEN, et
al., 2017
-
GAN
Previs√£o das dist√¢ncias inter-res√≠duos
para prote√≠nas, a partir de
informa√ß√µes de coevolu√ß√£o 1D e 2D
DING e GONG,
2020
https://github.c
om/Wenze-Code
base/DistancePr
ediction-ProteinGAN.git
8 Predi√ß√£o de regi√µes ausentes em uma estrutura de prote√≠na.
7 Receptor Binding Domain
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
Modelos de
linguagem
baseados em
transformer
ESM-1b
RIVES, MEIER, et
al., 2019; RAO,
MEIER, et al.,
2020
https://github.c
om/facebookres
earch/esm
Modelos de
linguagem
baseados em
transformer
Modelo de linguagem profunda
auto-supervisionado projetado
especificamente para prote√≠nas, o qual
captura representa√ß√µes locais e globais
de prote√≠nas de maneira natural
BRANDES,
OFER, et al., 2022
https://github.c
om/nadavbra/p
rotein_bert
Modelos de
linguagem
baseados em
transformer
ESM-2
LIN, AKIN, et al.,
2023
https://github.c
om/facebookres
earch/esm
Transformer AlphaFold 2
JUMPER,
EVANS, et al.,
2021
https://github.c
om/google-deep
mind/alphafold
Express√£o g√™nica
Arquitetura Objetivo Fonte Reposit√≥rio
VAE
Gera√ß√£o de novas mol√©culas a partir
de uma entrada constitu√≠da por
compostos representados como
SMILES e assinaturas de express√£o
g√™nica
PRAVALPHRUE
KUL,
PIRIYAJITAKON
KIJ, et al., 2023
https://github.c
om/ChemEXL/
BiCEV
Modelos de
linguagem
baseados em
transformer
Previs√£o da patogenicidade de
variantes missense no genoma humano
BRANDES,
GOLDMAN, et
al., 2023
https://github.c
om/ntranoslab/
esm-variants
Fonte: autoria pr√≥pria.
5. CONSIDERA√á√ïES FINAIS
Ao longo deste trabalho, discorremos sobre as principais t√©cnicas de um
subcampo da IA, conhecido como aprendizagem profunda, que t√™m sido amplamente
adotadas na pesquisa em bioinform√°tica. Buscamos tamb√©m elucidar aspectos
arquiteturais espec√≠ficos √†s redes convolucionais e aos modelos generativos,
demonstrando o motivo pelo qual cada t√©cnica √© aplicada em diferentes problemas
biol√≥gicos.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
A intelig√™ncia artificial tem um grande potencial para transformar a pesquisa em
biologia e √°reas afins. Estas √°reas de pesquisa t√™m sido totalmente transformadas pelo
uso de modelos computacionais nos √∫ltimos anos. H√° um volume de dados crescente
sobre os sistemas biol√≥gicos e que cresce tamb√©m em qualidade e complexidade, de
forma que tiram proveito dos novos modelos e algoritmos desenvolvidos pela
bioinform√°tica. A aplica√ß√£o, ainda incipiente, de t√©cnicas de IA nas ci√™ncias da vida por
meio da bioinform√°tica j√° trazem impactos consider√°veis em diversas √°reas de pesquisa e
na computa√ß√£o, com a demanda por novos modelos e algoritmos. O que se vislumbra
hoje √© apenas o come√ßo de um futuro brilhante desta parceria entre as ci√™ncias da vida e a
ci√™ncia da computa√ß√£o.
REFER√äNCIAS
ABBASI, Maryam et al. Designing optimized drug candidates with Generative Adversarial
Network. Journal of Cheminformatics, 14, n. 1, 2022. 40.
ALQURAISHI, Mohammed. AlphaFold at CASP13. Bioinformatics, 35, n. 22, 2019.
4862-4865.
ANAND, Namrata; HUANG, Po-Ssu. Generative modeling for protein structures.
Proceedings of the 32nd International Conference on Neural Information Processing
Systems, 31, 2018. 7505-7516.
ANISHCHENKO, Ivan. et al. De novo protein design by deep network hallucination. Nature,
600, n. 7889, 2021. 547-552.
ANSTINE, Dylan M.; ISAYEV, Olexandr. Generative Models as an Emerging Paradigm in the
Chemical Sciences. Journal of the American Chemical Society, 145, n. 16, 2023. 8736-8750.
BAI, Qifeng et al. Application advances of deep learning methods for de novo drug design and
molecular dynamics simulation. WIREs Computational Molecular Science, 12, n. 3, 2021.
e1581.
BENGIO, Yoshua; COURVILLE, Aaron; VINCENT, Pascal. Representation Learning: A
Review and New Perspectives. IEEE Transactions on Pattern Analysis and Machine
Intelligence, 35, n. 8, 2013. 1798-1828.
BIAN, Yuemin; XIE, Xiang-Qun. Generative chemistry: drug discovery with deep learning
generative models. Journal of Molecular Modeling, 27, n. 3, 2021. 71-89.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
BILODEAU, Camille et al. Generative models for molecular discovery: Recent advances and
challenges. WIREs Computational Molecular Science, 12, n. 5, 2022.
BRANDES, Nadav et al. ProteinBERT: a universal deep-learning model of protein sequence and
function. Bioinformatics, 38, n. 8, 2022. 2102-2110.
BRANDES, Nadav et al. Genome-wide prediction of disease variant effects with a deep protein
language model. Nature Genetics, 2023.
CALLAWAY, Ewen. AI tools are designing entirely new proteins that could transform medicine.
Nature, 619, n. 7969, 2023. 236-238.
CHEN, Ziqi et al. Shape-conditioned 3D Molecule Generation via Equivariant Diffusion
Models. Preprint, 2023. Dispon√≠vel em: <https://arxiv.org/abs/2308.11890>. Acesso em: 5
Setembro 2023.
CHENTHAMARAKSHAN, Vijil et al. Accelerating drug target inhibitor discovery with a deep
generative foundation model. Science Advances, 9, n. 25, 2023.
DEFRESNE, Marianne; BARBE, Sophie; SCHIEX, Thomas. Protein Design with Deep
Learning. International Journal of Molecular Sciences, 22, n. 21, 2021. 11741.
DILL, Ken A.; MACCALLUM, Justin L. The Protein-Folding Problem, 50 Years On. Science,
338, n. 6110, 2012. 1042-1046.
DING, Wenze; GONG, Haipeng. Predicting the Real-Valued Inter-Residue Distances for
Proteins. Advanced Science, 7, n. 19, 2020. 2001314.
DU, Zongyang et al. The trRosetta server for fast and accurate protein structure prediction.
Nature Protocols, 16, n. 12, 2021. 5634-5651.
DUDA, Richard O.; HART, Peter E.; STORK, David G. Pattern Classification. 2¬™. ed.
FERRUZ, Noelia; SCHMIDT, Steffen; H√ñCKER, Birte. ProtGPT2 is a deep unsupervised
language. Nature Communications, 13, n. 1, 2022. 4348.
GAO, Wenhao et al. Deep Learning in Protein Structural Modeling and Design. Patterns, 1, n.
9, 2020. 100142.
GONZALEZ, Rafael C.; WOODS, Richard E. Digital Image Processing. 4¬™. ed.
GOODFELLOW, Ian J. et al. Generative Adversarial Networks. Advances in Neural
Information Processing System, 2014. 2672-2680.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
GOODFELLOW, Ian; BENGIO, Yoshua; COURVILLE, Aaron. Deep Learning.
HAN, Minwoo et al. Recognition of the ligand-induced spatiotemporal residue pair pattern of
Œ≤2-adrenergic receptors using 3-D residual networks trained by the time series of protein distance
maps. Computational and Structural Biotechnology Journal, 20, 2022. 6360-6374.
HAYKIN, Simon. Neural Networks: A Comprehensive Foundation. 2¬™. ed.
HOLT, Charles A.; ROTH, Alvin E. The Nash equilibrium: A perspective. Proceedings of the
National Academy of Sciences, 101, n. 12, 2004. 3999-4002.
HOPFIELD, J. J. Neural networks and physical systems with emergent collective computational
abilities. Proceedings of the National Academy of Sciences, 79, n. 8, 1982. 2554-2558.
HUANG, Po-Ssu; BOYKEN, Scott E.; BAKER, David. The coming of age of de novo protein
design. Nature, 537, n. 7620, 2016. 320-327.
JUMPER, John et al. Highly accurate protein structure prediction with AlphaFold. Nature, 596,
n. 7873, 2021. 583-589.
KINGMA, Diederik P.; WELLING, Max. Auto-Encoding Variational Bayes, 2013.
LECUN, Yan et al. Backpropagation Applied to Handwritten Zip Code Recognition. Neural
Computation, 1, n. 4, 1989. 541-551.
LI, Chuan et al. An Interpretable Convolutional Neural Network Framework for Analyzing
Molecular Dynamics Trajectories: a Case Study on Functional States for G-Protein-Coupled
Receptors. Journal of Chemical Information and Modeling, 62, n. 6, 2022. 1399-1410.
LI, Xuanyi et al. Chemical space exploration based on recurrent neural networks: applications in
discovering kinase inhibitors. Journal of Cheminformatics, 12, n. 1, 2020. 42.
LI, Yuesen et al. DrugGPT: A GPT-based Strategy for Designing Potential Ligands Targeting
Specific Proteins. Preprint, 2023. Dispon√≠vel em:
<https://doi.org/10.1101/2023.06.29.543848>. Acesso em: 5 Setembro 2023.
LI, Zhaoyu et al. Protein Loop Modeling Using Deep Generative Adversarial Network. IEEE
29th International Conference on Tools with Artificial Intelligence (ICTAI), 2017.
1085-1091.
LIN, Zeming et al. Evolutionary-scale prediction of atomic-level protein structure with a
language model. Science, 379, n. 6637, 2023. 1123-1130.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
MAO, Jiashun et al. Application of a deep generative model produces novel and diverse
functional peptides against microbial resistance. Computational and Structural Biotechnology
Journal, 21, 2023. 463-471.
MARIANO, Diego et al. A Brief History of Bioinformatics Told by Data Visualization.
Advances in Bioinformatics and Computational Biology. BSB 2020. Lecture Notes in
Computer Science. Belo Horizonte: Springer, Cham. 2020. p. 235-246.
METHOD of the Year 2021: Protein structure prediction. Nature Methods, 19, n. 1, 2022.
MIN, Seonwoo; LEE, Byunghan; YOON, Sungroh. Deep learning in bioinformatics.
Briefings in Bioinformatics, 18, n. 5, 2017. 851‚Äì869.
MISHRA, Sarbani et al. Introduction to the World of Bioinformatics. A Guide to Applied
Machine Learning for Biologists, 2023. 105-126.
MITCHELL, Tom M. Machine learning.
MOLNAR, Christoph. Interpretable Machine Learning: A Guide for Making Black Box
Models Explainable. 2¬™. ed.
NASH, John F. Equilibrium points in n-person games. Proceedings of the National Academy
of Sciences, 36, n. 1, 1950. 48-49.
PLANTE, Ambrose et al. A Machine Learning Approach for the Discovery of
Ligand-Specific Functional Mechanisms of GPCRs. Molecules, 24, n. 11, 2019. 2097.
PRAVALPHRUEKUL, Nutaya et al. De Novo Design of Molecules with Multiaction Potential
from Differential Gene Expression using Variational Autoencoder. Journal of Chemical
Information and Modeling, 63, n. 13, 2023. 3999-4011.
RAO, Roshan. et al. Transformer protein language models are unsupervised structure learners.
International Conference on Learning Representations, 2020.
RIVES, Alexander. et al. Biological structure and function emerge from scaling unsupervised
learning to 250 million protein sequences. PNAS, 118, n. 15, 2019.
ROSSETTO, Allison; ZHOU, Wenjin. GANDALF: Peptide Generation for Drug Design Using
Sequential and Structural Generative Adversarial Networks. Proceedings of the 11th ACM
International Conference on Bioinformatics, Computational Biology and Health
Informatics, 2020.
RUMELHART, David E.; HINTON, Geoffrey E.; WILLIAMS, Ronald J. Learning
representations by back-propagating errors. Nature, 323, n. 6088, 1986. 533-536.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
SANCHEZ-LENGELING, Benjamin; ASPURU-GUZIK, Al√°n. Inverse molecular design
using machine learning: Generative models for matter engineering. Science, 361, n. 6400, 2018.
360-365.
SANTOS, Lucas M. D. et al. Peptide-Protein Interface Classification Using Convolutional
Neural Networks. Advances in Bioinformatics and Computational Biology. BSB 2023.
Lecture Notes in Computer Science. Curitiba: Springer, Cham.
2023. p. 112-122.
SANTOS, Lucas M. D.; MELO-MINARDI, Raquel C. D. Identifying Large Scale
Conformational Changes in Proteins Through Distance Maps and Convolutional Networks.
Advances in Bioinformatics and Computational Biology. BSB 2022. Lecture Notes in
Computer Science. B√∫zios: Springer, Cham. 2022. p. 56-67.
SENIOR, Andrew W. et al. Improved protein structure prediction using potentials from deep
learning. Nature, 577, n. 7792, 2020. 706‚Äì710.
SOHL-DICKSTEIN, Jascha et al. Deep Unsupervised Learning using Nonequilibrium
Thermodynamics. ICML'15: Proceedings of the 32nd International Conference on
International Conference on Machine Learning. Lille: [s.n.]. 2015. p. 2256‚Äì2265.
SOUSA, Tiago et al. Generative Deep Learning for Targeted Compound Design.
Journal of Chemical Information and Modeling, 61, n. 11, 2021. 5343-5361.
SURANA, Shraddha. et al. PandoraGAN: Generating antiviral peptides. SN COMPUT. SCI.,
4, n. 607, 2023.
THOMAS, Morgan; BENDER, Andreas; GRAAF, Chris D. Integrating structure-based
approaches in generative molecular design. Current Opinion in Structural Biology, 79, 2023.
102559.
TONG, Xiaochu et al. Generative Models for De Novo Drug Design. Journal of Medicinal
Chemistry, 64, n. 19, 2021. 14011-14027.
TORRISI, Mirko; POLLASTRI, Gianluca; LE, Quan. Deep learning methods in protein
structure prediction. Computational and Structural Biotechnology Journal, 18, 2020.
1301-1310.
VASWANI, Ashish et al. Attention is All you Need. Advances in Neural Information
Processing Systems, 30, 2017. 6000‚Äì6010.
VERLI, Hugo. Bioinform√°tica: da biologia √† flexibilidade molecular.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023
VERT, Jean-Philippe. How will generative AI disrupt data science in drug discovery?.
Nature Biotechnology, 41, n. 6, 2023. 750-751.
WATSON, Joseph L. et al. De novo design of protein structure and function with RFdiffusion.
Nature, 620, n. 7976, 2023. 1089-1100.
XIE, Xuezhi; VALIENTE, Pedro A.; KIM, Philip M. HelixGAN a deep-learning methodology
for conditional de novo design of Œ±-helix structures. Bioinformatics, 39, n. 1, 2023.
ZENG, Xiangxiang et al. Deep generative molecular design reshapes drug discovery.
Cell Reports Medicine, 3, n. 12, 2022. 100794.
ZHANG, Shuang et al. Applications of transformer-based language models in bioinformatics: a
survey. Bioinformatics Advances, 3, n. 1, 2023.
____________________________________________________________________________________________________
Revista da UFMG | Belo Horizonte, MG | v. 30, fluxo cont√≠nuo | e47996 | 2023