IMPACTOS DA INTELIGÊNCIA ARTIFICIAL NAS REDES SOCIAIS E OS
DESAFIOS AOS DIREITOS FUNDAMENTAIS NA ERA DIGITAL
A rápida evolução da Inteligência Artificial (IA) está transformando profundamente a
maneira como interagimos com a tecnologia e como tomamos decisões em vários setores da
sociedade. No entanto, à medida que a IA ganha um maior protagonismo, também surgem
preocupações éticas significativas sobre como essa tecnologia pode impactar as tomadas de
decisões e os direitos fundamentais dos indivíduos.
A justificativa para este trabalho de pesquisa repousa na crescente necessidade de
explorar e compreender os limites éticos associados à aplicação da IA e os riscos que ela
apresenta aos direitos fundamentais, como privacidade, não discriminação, liberdade de
expressão e igualdade.
O avanço da IA traz à tona questões complexas sobre a transparência dos processos de
tomada de decisão, o potencial de discriminação algorítmica, a invasão de privacidade e a
possibilidade de perda de controle humano sobre sistemas altamente autônomos. O impacto
dessas questões não se limita ao setor tecnológico ou a um setor específico, mas se estende às
esferas de saúde, justiça, educação, finanças e muito mais, afetando diretamente a vida das
pessoas.
A Inteligência artificial levantou preocupações ainda sobre a concentração de poder nas
mãos de poucas empresas ou governo, o que pode levar a abusos e violações dos direitos
fundamentais. A ausência de regulamentações robustas e diretrizes éticas claras para orientar o
desenvolvimento e uso da IA amplia ainda mais a necessidade de investigar essas preocupações.
A pesquisa nesta área é fundamental para garantir que o progresso tecnológico seja
acompanhado de reflexões profundas sobre os valores sociais, os princípios éticos e os direitos
fundamentais que devem ser preservados. Este trabalho contribui para a conscientização e o entendimento das implicações éticas da IA nos direitos fundamentais, fornecendo uma análise
abrangente dos desafios enfrentados.
Ao identificar e abordar questões éticas emergentes, esta pesquisa busca examinar os
desafios relacionados ao viés algorítmico e à discriminação que surge como consequência da
implementação de sistemas de IA em diferentes contextos, como recrutamento, sistema de justiça
criminal e concessão de crédito. Esta pesquisa analisa também políticas e regulamentações
existentes (ou a falta delas) relacionadas à ética da Inteligência Artificial e aos direitos
fundamentais, focando em lacunas e possíveis melhorias, identificando e analisando casos reais
em que a IA tenha levantado questões éticas e tenha impactado os direitos fundamentais, como
invasão de privacidade e discriminação, e contribuir para a formulação de políticas mais
informadas, o desenvolvimento de tecnologias mais éticas e a promoção de um uso responsável
da IA em benefício da sociedade como um todo.
2.1 INTELIGÊNCIA ARTIFICIAL E REFLEXOS NOS DIREITOS FUNDAMENTAIS
A utilização de tecnologias de inteligência artificial (IA) nas redes sociais tem
implicações éticas e legais significativas, muitas vezes refletidas diretamente nos direitos
fundamentais. Vários exemplos reais mostram como estas tecnologias podem ter impactos
danosos a direitos como a igualdade, a privacidade e a liberdade de expressão, desafiando os
limites éticos da sua utilização.
Um exemplo bastante conhecido é o sistema COMPAS, amplamente utilizado no sistema
de justiça criminal dos EUA para prever o risco de um acusado tornar a repetir o crime. Embora
não esteja diretamente relacionado com as redes sociais, a influência de tais algoritmos nas
decisões judiciais suscita preocupações que são visíveis nas plataformas digitais: viés algorítmico
e falta de transparência. Estudos têm demonstrado que o COMPAS tem um nítido preconceito
racial, superestimando o risco de reincidência para réus negros e subestimando o risco dos
brancos, um padrão que também pode ser replicado em algoritmos usados para moderar ou
promover conteúdo nas redes sociais.
O reconhecimento facial é uma tecnologia que funciona por meio de um algoritmo de IA,
capaz de analisar detalhadamente uma imagem capturada por uma câmera, definindo um padrão
individual para os rostos. Neste contexto, Costa & Kremer (2022, p. 146) relatam sobre a “reflexão e apontamentos críticos sobre a implementação da tecnologia de reconhecimento facial
no Brasil, que é um país com expressiva diversidade humana e também marcado pela violência
a grupos vulneráveis, como pessoas negras, LGBTI+ e mulheres”.
Em um contexto de implementação de uma tecnologia como o COMPAS no Brasil,
considerando as características do povo brasileiro, temos uma grande ameaça de crescimento nos
índices de descriminação. Como pontua Leal da Silva e Rodrigues da Silva (2019) qualquer
tecnologia pensada para melhorar a segurança pública, além de considerar aspectos técnicos de
funcionalidade, precisa atentar também para as variáveis de raça que perpassarão a sua utilização.
Outro exemplo é o uso de tecnologias de reconhecimento facial, implementadas por
órgãos públicos e privados. Em 2019, a cidade de São Francisco (EUA) tornou-se a primeira a
proibir o uso da tecnologia por órgãos governamentais, citando preocupações sobre violações de
privacidade e o potencial de discriminação. Estudos como os realizados pelo Núcleo de Estudos
da Violência da USP, mostram que os algoritmos de reconhecimento facial apresentam taxas de
erro mais altas para pessoas negras e mulheres, aumentando as chances de vigilância direcionada
e prisões injustas. No caso das redes sociais, esta tecnologia pode ser utilizada para rastrear
pessoas sem o seu consentimento, violando a privacidade e a liberdade de expressão.
Ainda abordando a questão de preconceito algorítmico, o notório caso do sistema de
recrutamento da Amazon mostra como os algoritmos de treinamento baseados em dados
históricos podem perpetuar o preconceito (neste caso, a discriminação de gênero e o sexismo). O
sistema da Amazon projetado para selecionar e avaliar automaticamente os candidatos foi
encerrado após descobertas de padrões misóginos, pois os mesmos possuíam moldes de
discriminação contra mulheres.
Nas redes sociais, os algoritmos que promovem anúncios ou websites de recrutamento
podem reproduzir vieses de discriminação ao excluir determinados grupos e violar o direito à
igualdade de oportunidades. Apesar do crescimento de índices de diversidade em diversas
instituições, ainda é notório como determinados setores e hierarquias são majoritariamente
compostos por homens brancos, o que apenas foi reproduzido pelos algoritmos de recrutamento
do caso em questão.
Por fim, a disseminação de notícias falsas nas redes sociais, que se tornou algo recorrente
e presente nas mais diversas esferas da sociedade, representa uma ameaça à privacidade, à
reputação e à integridade das informações. O que antes representava um grande risco e impacto na sociedade motivado pela disseminação de informações inverídicas, hoje se agrava com a
existência de inteligências artificiais capazes de criar gravações falsas de vídeo ou áudio, que são
utilizadas para difamar outras pessoas e espalhar notícias falsas, afetando a reputação das pessoas
e perturbando processos democráticos, como as eleições.
A dificuldade em distinguir o real do falso dificulta a liberdade de informação e a
confiança no ambiente digital. Debates surgem sobre a liberdade de expressão e a definição de
censura, gerando uma grande polarização e alarme na sociedade, que sente que um direito
fundamental pode estar em risco enquanto a necessidade de regulamentação torna-se cada vez
mais necessária.
Estes casos mostram que, embora a IA ofereça muitas oportunidades para melhorar
processos, melhorar a tomada de decisões, aumentar a produtividade e lucratividade nos mais
variados setores, também elucida a necessidade urgente de regulamentação e supervisão ética no
desenvolvimento e uso de tecnologias de IA. Proteger os direitos fundamentais e garantir a justiça
e a equidade são desafios cruciais que devem ser enfrentados à medida que a IA continua a
evoluir e se integrar em nossas vidas.
